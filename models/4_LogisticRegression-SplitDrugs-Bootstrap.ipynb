{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import time\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_alpha</th>\n",
       "      <th>Label_num</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Food</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>pentadecanoic acid</td>\n",
       "      <td>(123)iodine labelled beta-methyl-iodophenyl pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>2-phenylethanol</td>\n",
       "      <td>2-Phenylethanol is a widely used aroma compoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>3,4-dihydroxyphenylacetic acid</td>\n",
       "      <td>3,4-dihydroxyphenylacetic acid and 4-methylcat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>arachin</td>\n",
       "      <td>A 96-well microplate format of this method was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>diethylamine</td>\n",
       "      <td>A biochemical study was performed in order to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label_alpha  Label_num           Drug                            Food  \\\n",
       "ID                                                                          \n",
       "400     neutral          1  ACE inhibitor              pentadecanoic acid   \n",
       "333    positive          2  ACE inhibitor                 2-phenylethanol   \n",
       "77     positive          2  ACE inhibitor  3,4-dihydroxyphenylacetic acid   \n",
       "338     neutral          1  ACE inhibitor                         arachin   \n",
       "214     neutral          1  ACE inhibitor                    diethylamine   \n",
       "\n",
       "                                              sentence  \n",
       "ID                                                      \n",
       "400  (123)iodine labelled beta-methyl-iodophenyl pe...  \n",
       "333  2-Phenylethanol is a widely used aroma compoun...  \n",
       "77   3,4-dihydroxyphenylacetic acid and 4-methylcat...  \n",
       "338  A 96-well microplate format of this method was...  \n",
       "214  A biochemical study was performed in order to ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../labeled_dataAll.csv\", index_col='ID')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ACE inhibitor', 'Antacid', 'GLP-1', 'Thyroxine', 'Statin',\n",
       "       'Acetaminophen', 'Digoxin', 'Isoniazid', 'Antihistamine', 'MOAI',\n",
       "       'Analgesics', 'Bronchodialators'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Drug.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df[(df.Drug != \"Statin\") & (df.Drug != \"Isoniazid\") & (df.Drug != \"Digoxin\")]\n",
    "df_test = df[(df.Drug == \"Statin\") | (df.Drug == \"Isoniazid\") | (df.Drug == \"Digoxin\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACE inhibitor' 'Antacid' 'GLP-1' 'Thyroxine' 'Acetaminophen'\n",
      " 'Antihistamine' 'MOAI' 'Analgesics' 'Bronchodialators']\n"
     ]
    }
   ],
   "source": [
    "drugs = df_train.Drug.unique()\n",
    "print drugs\n",
    "add_dict = {}\n",
    "\n",
    "for drug in drugs:\n",
    "    \n",
    "    count_list = []\n",
    "    for i in range(3):\n",
    "        count = len(df_train[(df_train.Drug == drug) & (df_train.Label_num == i)])\n",
    "        count_list.append(count)\n",
    "        \n",
    "    max_count = max(count_list)\n",
    "    add_list = [max(0,max_count-c) for c in count_list]\n",
    "    add_dict[drug] = add_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GLP-1': [109, 0, 59], 'Thyroxine': [66, 0, 85], 'MOAI': [34, 2, 0], 'Antihistamine': [18, 0, 5], 'Analgesics': [8, 2, 0], 'Acetaminophen': [334, 0, 435], 'Antacid': [22, 0, 16], 'Bronchodialators': [12, 0, 2], 'ACE inhibitor': [272, 0, 107]}\n"
     ]
    }
   ],
   "source": [
    "print add_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829\n"
     ]
    }
   ],
   "source": [
    "original_n = len(df_train)\n",
    "print original_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3417\n"
     ]
    }
   ],
   "source": [
    "for drug in drugs:\n",
    "    for i in range(3):\n",
    "        temp = df_train[(df_train.Drug == drug) & (df_train.Label_num == i)].sample(add_dict[drug][i], replace=True)\n",
    "        df_train = df_train.append(temp)\n",
    "\n",
    "print len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3417\n"
     ]
    }
   ],
   "source": [
    "# check if equal to above number\n",
    "print sum([j for i in add_dict.values() for j in i]) + original_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Applications/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Applications/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Applications/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Randomly shuffle the data. Use same random seed to get same results every time. \n",
    "df_shuffle = df_train.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "# Separate labels\n",
    "labels = [i for i in df_shuffle.Label_num]\n",
    "labels = np.array(labels)\n",
    "n = len(labels)\n",
    "\n",
    "labels2 = [i for i in df_test.Label_num]\n",
    "labels2 = np.array(labels2)\n",
    "\n",
    "\n",
    "# Drop unecessary columns from input data\n",
    "df_shuffle.drop('Label_alpha', axis=1, inplace=True)\n",
    "df_shuffle.drop('Label_num', axis=1, inplace=True)\n",
    "df_shuffle.drop('Drug', axis=1, inplace=True)\n",
    "df_shuffle.drop('Food', axis=1, inplace=True)\n",
    "\n",
    "df_test.drop('Label_alpha', axis=1, inplace=True)\n",
    "df_test.drop('Label_num', axis=1, inplace=True)\n",
    "df_test.drop('Drug', axis=1, inplace=True)\n",
    "df_test.drop('Food', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Split the train data into training and dev datasets\n",
    "train_data =  df_shuffle[:3*n/4].sentence.tolist()\n",
    "dev_data = df_shuffle[3*n/4:].sentence.tolist()\n",
    "test_data = df_test.sentence.tolist()\n",
    "\n",
    "# Separate training and dev labels\n",
    "train_labels =  labels[:3*n/4]\n",
    "dev_labels = labels[3*n/4:]\n",
    "test_labels = labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training label shape: (2562,)\n",
      "test label shape: (642,)\n",
      "dev label shape: (855,)\n"
     ]
    }
   ],
   "source": [
    "print 'training label shape:', train_labels.shape\n",
    "print 'test label shape:', test_labels.shape\n",
    "print 'dev label shape:', dev_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['negative', 'neutral', 'positive'] # corresponding labels = 0, 1, 2\n",
    "classes_dict = {0:'negative', 1:'neutral', 2:'positive'} # corresponding labels = 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_classes(value, labels):\n",
    "    return len([i for i in labels if i == value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split among Negative, Neutral and Positive\n",
      "\n",
      "        dataset |       negative |        neutral |       positive\n",
      "          train |     834.000000 |     855.000000 |     873.000000\n",
      "            dev |     305.000000 |     284.000000 |     266.000000\n",
      "           test |      95.000000 |     446.000000 |     101.000000\n"
     ]
    }
   ],
   "source": [
    "# Check number of classes per train/dev/test dataset:\n",
    "print \"Dataset split among Negative, Neutral and Positive\"\n",
    "print \"\"\n",
    "\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"train\",count_classes(0,train_labels), \n",
    "                                                     count_classes(1,train_labels),\n",
    "                                                     count_classes(2,train_labels))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev\",count_classes(0,dev_labels), \n",
    "                                                     count_classes(1,dev_labels),\n",
    "                                                     count_classes(2,dev_labels))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test\",count_classes(0,test_labels), \n",
    "                                                     count_classes(1,test_labels),\n",
    "                                                     count_classes(2,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example 1\n",
      "Label 2 ( positive )\n",
      "Sentence:\n",
      "Among these, phellopterin activated GPR119 and increased active GLP-1 and insulin secretion in vitro and enhanced glucose tolerance in normal and db/db mice.\" \n",
      "\n",
      "\n",
      "Training example 2\n",
      "Label 2 ( positive )\n",
      "Sentence:\n",
      "Lower levels of ACE inhibition were observed with ethanol extracts of oregano (18.5 %) and lemon balm (0.5 %). \n",
      "\n",
      "\n",
      "Training example 3\n",
      "Label 2 ( positive )\n",
      "Sentence:\n",
      "All the types of honey showed some activity but chestnut honey had the highest ACE inhibitory activity. \n",
      "\n",
      "\n",
      "Training example 4\n",
      "Label 0 ( negative )\n",
      "Sentence:\n",
      "The results reveal that delayed release occurs in preparations compounded with acetaminophen (AA) as the active ingredient and erythritol (ET) and crospovidone (CP) as excipients. \n",
      "\n",
      "\n",
      "Training example 5\n",
      "Label 1 ( neutral )\n",
      "Sentence:\n",
      "We examined the angiotensin I-converting enzyme (ACE) inhibitory activity and antihypertensive effect of the hot water extract of wakame, Undaria pinnatifida.\" \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check few sentences\n",
    "\n",
    "def print_examples(num_examples=5):\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        print \"Training example\", i+1\n",
    "        print \"Label\", train_labels[i], \"(\", classes_dict[train_labels[i]],\")\"\n",
    "        print \"Sentence:\\n\", train_data[i], \"\\n\\n\"\n",
    "       \n",
    "    \n",
    "print_examples(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn the raw training text into feature vectors based on \"td-idf\"\n",
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_dev_tf = vectorizer.transform(dev_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression model ...\n",
      "Performing grid search for Logistic Regression model. It may take a few minutes ...\n",
      "Logistic Regression grid search model fitting time = 0.874567 seconds.\n",
      "As per the grid search on the training data, the optimal value of C = 50.000000.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=50.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression:\n",
    "print \"Evaluating Logistic Regression model ...\"\n",
    "\n",
    "# Create a Logistic Regression model. \n",
    "LRmodel = LogisticRegression(C=1.0)\n",
    "\n",
    "# Create a grid search.\n",
    "print \"Performing grid search for Logistic Regression model. It may take a few minutes ...\"\n",
    "Cs = {'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0]}\n",
    "CV_LRmodel = GridSearchCV(estimator=LRmodel, param_grid=Cs)\n",
    "\n",
    "# Fit the models using grid search and display the results.\n",
    "start_time = time.time()\n",
    "CV_LRmodel.fit(vocab_train_tf, train_labels)\n",
    "end_time = time.time()\n",
    "print \"Logistic Regression grid search model fitting time = %f seconds.\" % (end_time - start_time)\n",
    "\n",
    "optimal_Cs = CV_LRmodel.best_params_['C']\n",
    "print \"As per the grid search on the training data, the optimal value of C = %f.\" % optimal_Cs\n",
    "\n",
    "# Construct model with optimal C\n",
    "model_LR = LogisticRegression(C=optimal_Cs)\n",
    "model_LR.fit(vocab_train_tf, train_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev dataset with 855 sentences\n",
      "\n",
      "Data split - Negative, Neutral, Positive\n",
      "----------------------------------------\n",
      "        dataset |       negative |        neutral |       positive\n",
      "  dev_predicted |     309.000000 |     279.000000 |     267.000000\n",
      "     dev_actual |     305.000000 |     284.000000 |     266.000000\n",
      "\n",
      "Accuracy\n",
      "--------\n",
      "Accuracy (test data): 0.918\n",
      "\n",
      "Classification Report\n",
      "---------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97       305\n",
      "          1       0.89      0.88      0.88       284\n",
      "          2       0.90      0.90      0.90       266\n",
      "\n",
      "avg / total       0.92      0.92      0.92       855\n",
      "\n",
      "\n",
      "Confusion matrix for Dev data\n",
      "-----------------------------\n",
      "The most confused pair of classes is: 1 ( neutral )  incorrectly predicted as 2 ( positive )\n",
      "Number of such confusion occurences: 27\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGkCAYAAAABqz41AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4VOXZx/HfmWQCZCMLW1gkgimbIApaFF8QCxUQRRCE\ngCAFkUBlS2VLWANBRASLQKUiCgFZXKhWsVjUguIuFpTIUsK+JQECSSTrzPsHNhXFZMSZHM7J93Nd\nc10zZybP3CcMyZ37fp7nGG632y0AAAATOcwOAAAAgIQEAACYjoQEAACYjoQEAACYjoQEAACYzt+X\ng7eo396Xw6MC+mz7OrNDgI04nE6zQ4ANBYRGltt7efv37M5DW7w63i9BhQQAAJjOpxUSAADgO4Zh\nmB2C11AhAQAApqNCAgCARRmGfeoK9jkTAABgWSQkAADAdLRsAACwKIfsM6mVhAQAAItilQ0AAIAX\nUSEBAMCiHDZaZUNCAgCARdGyAQAA8CISEgAAYDpaNgAAWJRho2W/VEgAAIDpqJAAAGBRrLIBAACm\nY5UNAACAF1EhAQDAohxUSAAAALyHhAQAAJiOlg0AABZl2KiuYJ8zAQAAlkWFBAAAi7LTsl8SEgAA\nLIpVNgAAAF5EhQQAAIvi4noAAABeREICAABMR8sGAACL4mq/AADAdHZa9muf1AoAAFgWFRIAACzK\nTvuQkJAAAGBRLPsFAADwIhISAABgOlo2AABYlJ2W/drnTAAAgGVRIQEAwKLstA8JCQkAABZlp2W/\ntGwAAIDpqJAAAGBR7EMCAADgRSQkAADAdLRsAACwKFbZAAAA07HKBgAAwIuokAAAYFF2WmXjUUJS\nXFys1157TcePH1ebNm0UExOjiIgIX8cGAAAqCI9aNlOnTtXx48f10UcfKTc3VxMmTPB1XAAAoAwO\nw+HVm6nn4smLDh8+rNGjR6tSpUq68847lZ2d7eu4AABABeJRQlJcXKwzZ85IknJycuRwMBcWAAB4\nj0dzSMaOHavY2FhlZGSoT58+SkxM9HVcAACgDBVuH5KQkBBt2rRJZ86cUXh4uK2+AQAAWFWF24fk\n6aefVt++fbV582ZduHDB1zEBAIAKxqMKybPPPquMjAy9/vrrGjx4sBo2bKjk5GRfxwYAAEpR4fYh\nkaSioiIVFBTI5XLJz8/PlzEBAAAP2Kll41FCMnDgQBUUFKhXr1568cUXFRgY6Ou4AABABeJRQpKY\nmKhGjRr5OhYAAHCVKioqUkJCgo4dO6bCwkLFxcUpKipKw4YNU3R0tCQpNjZWXbp00fr167Vu3To5\nnU7FxcXpjjvuKHP8UhOSpKQkTZ06VVOnTi1ZWeN2u2UYhtauXfurTw4AAFy58lz1+sYbbyg8PFxz\n587VuXPndN999+mPf/yjBg8erEGDBpW8LjMzUykpKdqwYYPy8vIUGxurtm3byul0ljp+qQnJiBEj\nJElPPPHEJQOdO3fuV5ySPfV9qIce6H+vXC63jhw6rhkTn1TW2Sv7PoWFV1XyggRF1akpV7FLSQlP\naef2XZKku3t00kND+8jtduvChTw9Mf0ZffvNXm+eCizs729vUsra9SU/pLJzcpSekal3/vaKIsLD\nTI4OVjZ5xizFXNdQD/WPNTsUmKRLly7q3LmzJMnlcsnf31+7du1SWlqaNm/erOjoaE2aNEk7d+5U\nq1at5O/vr+DgYEVHR2vPnj26/vrrSx2/1GW/brdbBw4c0Pjx41VYWKiCggLl5eVp6tSp3jtDG2hy\nfYwGPvyA+t83Qr06D9aRQ0f16J+GXPF4CTPH6MtPd6hnp0FKGJusp5ZMV0ClANW/tq7GTBymuAGP\nqc/dQ7Vs0SotWDrTi2cCq7uny11av+J5rXtxmVYve1bVIiKU8KcxJCO4YmkHD+rh4SP1zrvvmx0K\nLsNhGF69laZKlSoKDAxUTk6ORo8erTFjxqhFixaaMGGCVq1apXr16mnRokXKyclRSEhIydcFBgZ6\ndMmZUiskO3bs0IoVK3TgwAFNmTLl4sk7HLr99ts9+T5VGN9+s0/d2veXy+VSQKUA1ahVXUcOHZO/\nv5/GTIpTq1tayOHnp9279mnOtIW68N3/9nJJenKiPv/4K/39tU2SLn5/2//uViVPXiBJ2vvtfh06\ncFRt29+ib7/ZqxkTntSZ01mSpNSv9yiyWrj8/PxUXFxc/ieOq9rylJcUERGunvd2MzsUWNjal1/T\nffd2U1RULbNDwWWU97LfEydO6NFHH9WDDz6ou+++W9nZ2SXJR8eOHTVr1izdcsstysnJKfma3Nxc\nhYaGljl2qQlJx44d1bFjR23ZskXt27f/ladhby6XS3d0aqvpT4xXQX6BFs17XoNH9FdRYZFi7xkm\nSRo57mGNnTRMs6c8/bPjhEVUlQxD57LOlxw7dTJTNaOq6/13PtTJ4+klxx+b8ke9/89tJCP4iaxz\n55Sydr3Wr3je7FBgcQnj4iVJn3z2ucmRwGyZmZkaMmSIpk6dqjZt2kiShgwZoilTpqh58+b6+OOP\n1axZMzVv3lwLFixQQUGB8vPzlZaWppiYmDLH92iVTdWqVTV16lQVFhZKktLT0/X88/yg+7F//XOb\n7vhnd/Xo01VLV81T1plzCg4J0q3tbpYkOf39dDrzrCRp1YYlcgY4FVWnpm6+taUeHNJLX33xjZYt\nTrns2K5iV8n9ypUradb8BNWoVU3DB47z/YnBcl59/e/q0O52RdWqaXYoAHyoPPchWbp0qc6fP68l\nS5Zo8eLFMgxDkyZN0uzZs+V0OlW9enUlJSUpKChIAwYMUL9+/eR2uxUfH6+AgIAyx/coIZk+fboe\nfvhhbdq0Sb/5zW9UUFDwq0/MTupeU1vVakTo3198I0n62/q3NWX2nyRJyZMX6KOtF/+yqFy5kgIq\nXfxHebDHxQnDl2vZSFJwSJBysnMlSTVrVdOpExmSpFq1a2jhstnav++gBvcZraLConI6S1jJpnff\n18Sxo8wOA4CNJCYmXvbiumvWrPnJsd69e6t3796/aHyPrmUTHh6ubt26KTg4WCNHjtSpU6d+0ZvY\nXfUakZr7zDSFVr3YR+vW4/fat+eA3n7jXcUO6il/fz8ZhqEZcydo9IRHLvlat9yXPHa5XPrgvU/U\nu9+9kqSYxg107XX19fknXym0aoheWL9Qm/+xVZNGzyIZwWWdz87W4aPHdEPz0me0A8DVxKMKicPh\n0L59+3ThwgWlpaWx7PdHvvria/31mZV6Yf1CFRUVKf1UpsYMTdTpzLOKTxiu9RuXyXA4tCf1P5o3\na8klXztt3BM/GW/2lAWa/sR4dev5e7lcLiWMmaXvci/o4T8+qBq1qut3d/2ffte53cUXu916OHas\nss/n/GQcVExHjh5T9WqRXOIBXsVV3q9Odvp3Mdxut7usF+3bt0/79u1TzZo1lZycrHvvvfeSTVB+\nTov6TISFd322fZ3ZIcBGHGVs1ARciYDQyHJ7r8G3jfDqeMs/WlL2i3zEowpJUFCQWrZsKUlatGiR\n/P39VVhYWOauawAAAJ7wKCEZNmyYTp06pWuvvVYHDx5UlSpVVFRUpHHjxql79+6+jhEAAFxGee9D\n4kseTWqtW7eu/vGPf2jdunV655131Lx5c7355ptatWqVr+MDAAA/ozx3avX5uXjyotOnTysiIkLS\nxT1JMjMzFRYWVrJEFQAA4NfwqGXTrFkzxcfHq2XLlvr3v/+tJk2aaOPGjYqMLL+JOwAAwL48Skim\nTZumd999V2lpaerevbvat2+vtLQ0dejQwdfxAQCAn2GnZb8e9VxycnK0c+dOpaWlKT8/X4cOHVKD\nBg1UpUoVX8cHAAAqAI8SkoSEBNWrV0+HDh1StWrVLrt1LAAAKF8VblJrVlaWevXqJX9/f910001y\nuVxlfxEAAICHPJpDIkn79++XJJ08eZItqQEAuArYaQ6JRwnJ5MmTlZiYqP3792v06NGaNm2ar+MC\nAABlqHAbo6WmpurcuXMKCQlRRkaGRo4c6eu4AABABeJRheS5557Ts88+q6ioKF/HAwAAKiCPEpJ6\n9eqpfv36vo4FAAD8Ag77dGw8S0gqV66shx9+WE2aNCmZQBMfH+/TwAAAQMXhUULSvn17X8cBAAB+\noQq3yqZHjx6+jgMAAPxCZm9m5k1crhcAAJjO443RAADA1cVOLRsqJAAAwHQkJAAAwHS0bAAAsCiH\njbaOJyEBAMCimEMCAADgRVRIAACwKDvtQ0JCAgCARdkoH6FlAwAAzEdCAgAATEfLBgAAi7LTHBIq\nJAAAwHRUSAAAsCiDjdEAAIDZ2BgNAADAi6iQAABgUXaa1EpCAgCARdkoH6FlAwAAzEdCAgAATEdC\nAgAATMccEgAALIpJrQAAwHR22hiNlg0AADAdFRIAACyKlg0AADCdjfIRWjYAAMB8JCQAAMB0tGwA\nALAorvYLAADgRVRIAACwKFbZAAAA09koH6FlAwAAzEeFBAAAi7JTy4YKCQAAMB0JCQAAMB0tGwAA\nLMpOV/slIQEAwKLstDEaCQkAAChTUVGREhISdOzYMRUWFiouLk7XXXedJk6cKIfDoZiYGE2bNk2S\ntH79eq1bt05Op1NxcXG64447yhyfhAQAAItylGOB5I033lB4eLjmzp2r8+fPq3v37mrcuLHi4+PV\nunVrTZs2TZs3b1bLli2VkpKiDRs2KC8vT7GxsWrbtq2cTmep45OQAABgUeXZsunSpYs6d+4sSSou\nLpafn59SU1PVunVrSVK7du20bds2ORwOtWrVSv7+/goODlZ0dLT27Nmj66+/vtTxWWUDAADKVKVK\nFQUGBionJ0ejR4/W2LFj5Xa7S54PCgpSTk6OcnNzFRISUnI8MDBQ2dnZZY5PQgIAADxy4sQJPfTQ\nQ+rRo4fuvvtuORz/SyNyc3MVGhqq4OBg5eTk/OR4WUhIAACwKMMwvHorTWZmpoYMGaJx48apR48e\nkqQmTZro888/lyRt3bpVrVq1UvPmzfXll1+qoKBA2dnZSktLU0xMTJnn4tM5JJ99ucaXw6MCGtp1\nmtkhwEYWrx5ldgiwoYDQSLND8ImlS5fq/PnzWrJkiRYvXizDMJSYmKhZs2apsLBQDRs2VOfOnWUY\nhgYMGKB+/frJ7XYrPj5eAQEBZY5vuH/YAPKyvMzjvhoaFdTQu2eYHQJshIQEvhB6XbNye68/957l\n1fFGvzzZq+P9EqyyAQDAouy0MRpzSAAAgOmokAAAYFE2KpBQIQEAAOYjIQEAAKajZQMAgEU5bNSz\noUICAABMR4UEAACLMmSfCgkJCQAAFmWjjg0tGwAAYD4qJAAAWBSTWgEAALyIhAQAAJiOlg0AABZl\np4vrkZAAAGBRNspHaNkAAADzUSEBAMCiaNkAAADTOeyTj9CyAQAA5iMhAQAApqNlAwCARdlpDgkV\nEgAAYDoqJAAAWJSNCiQkJAAAWBUX1wMAAPAiKiQAAFgUk1oBAAC8iIQEAACYjpYNAAAWZaOODQkJ\nAABWxRwSAAAAL6JCAgCARdmoQEJCAgCAVbExGgAAgBeRkAAAANORkAAAANMxhwQAAIuy0RQSEhIA\nAKyKfUgAAAC8iAoJAAAWZaMCCQkJAABWRcsGAADAi0hIAACA6WjZAABgUTbq2FAhAQAA5qNCAgCA\nRdnp4nokJAAAWJSN8hFaNgAAwHxUSAAAsCj2IQEAAPCiUiskBw4c+Nnnrr32Wq8HAwAAKqZSE5Kp\nU6de9rhhGFq5cqVPAgIAAJ6xUcem9IQkJSXlsscLCgp8EgwAAPCcneaQeDSpde3atXrhhRdUVFQk\nt9stp9OpTZs2+To2AABQQXg0qXX16tVKSUlRu3bt9Pjjj6thw4a+jgsAAJTBMLx7M5NHCUmNGjVU\no0YN5ebm6re//a2ys7N9HRcAACiDYRhevZnJo4QkJCREmzdvlmEYWrt2rbKysnwdFwAAqEA8Skhm\nzZql2rVrKz4+XgcPHtTkyZN9HRcAAKhAPJrUOmrUKC1fvlySNHHiRJ8GVNG8u+UDPbv8RTkcfgoN\nCda0ieNUt3aU2WGhnN3W+bfq2r+T3C638vMLtGr+Oh3cffiS18SO6qVb7rxJOedyJUknDp/UkinP\nX/F7BlcNUtz0PyiyVqRcxS69MGe1/vNNmsfxwL42vrdFq157XYZhqErlSvrTI0O04uXXdOTESRmG\n5HZLx0+dUqvm12veFH4nmMmMLsuOHTs0b948paSk6Ntvv9WwYcMUHR0tSYqNjVWXLl20fv16rVu3\nTk6nU3FxcbrjjjvKHNejhCQ0NFSbN2/WtddeK4fjYlGFjdF+vfz8AiXOnK1XVi5X3dpRWrXuFc1Z\nsFCLnnzc7NBQjmrVq6E+f+yhKQOTdf5stlrc2kyj58Rp7H0Jl7wupnkDLZr8nPZ/8/MbFv4SD43r\np91f7dObKxfpmpi6+tP8R/XY/ZMVWTPCo3hgT4eOHdeiF1O0auE8RYSFadsX2zU++Qn9/cW/lrwm\ndd9/NOnxeZow4hETI4UZli1bptdff11BQUGSpG+++UaDBw/WoEGDSl6TmZmplJQUbdiwQXl5eYqN\njVXbtm3ldDpLHdujhOT06dNasWJFyWM2RvOOYlexJCk7J0eS9N2FC6pcqZKZIcEEhYVFen52is6f\nvThZ/ODuwwqNCJXDzyFXsUuS5Ofvp/q/qaeu/TupZt0aOnU0XasXvKwz6Wfl5+dQn0fvV6MbY+Rw\nGDq094hSnlqn/Av5Je8xdMpDSv1ij7a9/YkkyXAYuvH25lox9yVJ0uF9R3Xy8Cm1aNNMB/ccLjMe\n2FeA01+Jo0YoIixMktTkugY6k3VORcXF8vfzU1FRkabPf0bxjwxW9cgIk6NFeU9ErV+/vhYvXqzx\n48dLknbt2qWDBw9q8+bNio6O1qRJk7Rz5061atVK/v7+Cg4OVnR0tPbs2aPrr7++1LE9SkgGDx6s\nDh06lDzeuHHjrzgd/FdglSpKfGysBg77o8KqVpXL5dKKvzxjdlgoZ6dPntHpk2dKHvcb3Vvbt+64\n5Jd/ePUw7fpit9Yt3qD0oxnq2r+Txj45QlMeSla3hzqruKhY0wbNliT1iuuuvo/21Ion1/zse4aE\nBUuGoZzzuSXHzmRkKbxGuL7cukOnT50tNR7YV1SNGoqqUaPk8YLnXlS7NjfL389PkvS3TZtVIzJC\n7dvcYlaI+IHybtl06tRJx44dK3l8ww036IEHHlDTpk21dOlSLVq0SE2aNFFISEjJawIDAz1anVtq\nQvL+++9r+/bteuutt/TVV19Jklwul95991117dr1Ss8H39uXdkB/fWGl/vbSStWJqqWXXn5N8QlT\ntX7FMrNDgwkCKjk1bNofFF49THPHLLzkucwTpzX/T4tLHm9c/U/d+4euiqwVoRvbtlCV4Cq6/rdN\nJEn+/n46d+bif/5pz0+Qv7+/IqMi1OSm36hz399p7879euPFy/9R4Xb9L+koLR7YX15evqbPX6j0\n02e0cOaUkuNrXn9Tk0eNMDEyXE06duxYknx07NhRs2bN0i233KKc7yv/kpSbm6vQ0NAyxyo1IWnc\nuLGysrJUqVKlkjkjhmHo7rvv/jXx43sfffq5WrZorjpRtSRJfe+/T/OeWaxz58+rqgf/eLCPyJrh\nGjvvjzqWdlzJw59ScVHxJc/XbVhb18TU00f/+LTkmGEYKi4qluHn0Kr56/T1p6mSLiYSzkoXe7Uz\nhjwh6fItG0mqElRZF3LzJEkR1cN0Jj3Lo3hgbyfTMxSf9Lga1K+npXOSSnr/e/YfkMvl0o3XNzU5\nQvyXw+S9Q4YMGaIpU6aoefPm+vjjj9WsWTM1b95cCxYsUEFBgfLz85WWlqaYmJgyxyo1IYmKilKP\nHj103333mb5hih01+U2M1r32N50+e1aR4eF6b8sHqlO7NslIBRMYEqjEZx/Tlr9v0+vLf65y4daD\n8Q9oz7/36fTJM/rd/e115D9HlZV5Tl9/skudendQ6he75XK59fDkgbqQm6cX5qz+39e73T8Zb8e2\nr3Vnj3Z6a9U7qnddHdWOjtK32/coKLTseGBf57NzNGziFN3T6U49HPvAJc9t/2aXWrdoblJkuBpN\nnz5dM2fOlNPpVPXq1ZWUlKSgoCANGDBA/fr1k9vtVnx8vAICAsocy3D/+CfVZdx+++0l97OyslSv\nXj29/fbbZQ6el3m8zNdUdOs3vK41r2yQ0+lU1dAQTYofrQbR9c0O66o19O4ZZofgdfc81EU9H7lH\nR/9zTPpv3u+WXnhitf4wob+mPJQsSbr19zfrnoe6yHAYOpN+VsuSV+psepacAf7qO7KXmrb6jQyH\noUN7j2r546sumdR6OaHhIRqSMEDVa1eT2+3S6qdfUeoXu382nscfXaDvsr/z3TfCBItXjzI7hKvO\nC+te0dLV63Rd9DX6728Hw5CWJM/Qs6vWqHpEuP7Qp5e5QV7lQq9rVm7v9c8Jf/HqeJ2eGO7V8X4J\njxKSHzp27JgWLVqkxx8ve2kqCQm8zY4JCcxDQgJfICG5Mh7t1PpDderUUVpami9iAQAAFZRHy37j\n4+NL5pCkp6crMjLSp0EBAICy2Wl+p0cJSd++fUvuV6pUqczNTQAAgO/ZKB/xrGXTtGlTbdu2TRs2\nbNCpU6d09OhRX8cFAAAqEI8SkoSEBNWrV0+HDh1StWrVlJiY6Ou4AABAGQyH4dWbmTxKSLKystSr\nVy/5+/vrpptuksvFFtIAAJjNMLx7M5PHq2z2798vSTp58qT8vr+mAQAAgDd4lJBMnjxZiYmJ+vbb\nbzV69GhNmjTJ13EBAIAKxKOEJDU1VefOnVNISIgyMjI0cuRIX8cFAADKYBiGV29m8mjZ73PPPadn\nn31WUVFRvo4HAABUQB4lJPXq1VP9+lxfBQCAq4nZE1G9yaOEpHLlynr44YfVpEmTkpJOfHy8TwMD\nAAClM7vN4k0eJSTt27f3dRwAAKAC8ygh6dGjh6/jAAAAv5CNCiS//Gq/AAAA3kZCAgAATOdRywYA\nAFyFbNSzISEBAMCi7LTKhpYNAAAwHRUSAAAsykYFEhISAACsynDYJyOhZQMAAExHQgIAAExHywYA\nAIuy0xwSKiQAAMB0VEgAALAo9iEBAADwIiokAABYlI0KJCQkAABYFS0bAAAALyIhAQAApqNlAwCA\nRdmoY0OFBAAAmI8KCQAAFmWnSa0kJAAAWJWN+hw2OhUAAGBVVEgAALAoO7VsqJAAAADTkZAAAADT\n0bIBAMCibNSxISEBAMCqmEMCAADgRVRIAACwKBsVSEhIAACwLBtlJLRsAACA6UhIAACA6WjZAABg\nUYaDlg0AAIDXUCEBAMCibDSnlYQEAACrYmM0AAAAL6JCAgCARdmoQEKFBAAAmI+EBAAAmI6WDQAA\nVmWjng0VEgAAYDoqJAAAWBQ7tQIAANMZhndvntixY4cGDBggSTp8+LD69eunBx98UDNmzCh5zfr1\n63X//ferb9+++te//uXRuCQkAADAI8uWLdPkyZNVWFgoSXr88ccVHx+vVatWyeVyafPmzcrMzFRK\nSorWrVunZcuW6amnnip5fWlISAAAsKpyLpHUr19fixcvLnm8a9cutW7dWpLUrl07ffTRR9q5c6da\ntWolf39/BQcHKzo6Wnv27ClzbBISAADgkU6dOsnPz6/ksdvtLrkfFBSknJwc5ebmKiQkpOR4YGCg\nsrOzyxzbp5NaDX/mzMK7lqwda3YIsJFxA5eYHQJs6NkPFpodQrlxOP5X18jNzVVoaKiCg4OVk5Pz\nk+NljuWTCAEAgM+ZMan1h5o2barPP/9ckrR161a1atVKzZs315dffqmCggJlZ2crLS1NMTExZY5F\nCQMAAIsye9nvhAkTNGXKFBUWFqphw4bq3LmzDMPQgAED1K9fP7ndbsXHxysgIKDMsQz3DxtAXpaf\nle6roVFBFZw9Y3YIsBFaNvCF8mzZ7H5hvVfHa/yHB7w63i9BhQQAAIsybLR1PAkJAABWZZ98hEmt\nAADAfCQkAADAdLRsAACwKDvNIaFCAgAATEeFBAAAi7JThYSEBAAAq7JRn8NGpwIAAKyKCgkAABZl\np5YNFRIAAGA6EhIAAGA6WjYAAFiUnVo2JCQAAFiVffIRWjYAAMB8VEgAALAow2GfEgkJCQAAVmWj\nOSS0bAAAgOlISAAAgOlo2QAAYFE26thQIQEAAOajQgIAgEXZaWM0KiQAAMB0VEgAALAq9iEBAABm\no2UDAADgRSQkAADAdLRsAACwKvt0bKiQAAAA81EhAQDAouw0qZWEBAAAizJstOyXlg0AADAdFRIA\nAKyKlg0AADCbneaQ0LIBAACmIyEBAACmo2UDAIBV2adjQ4UEAACYjwoJAAAWZad9SEhIAACwKlbZ\nAAAAeA8VEgAALIp9SAAAALyIhAQAAJiOlg0AAFbFKhsAAGA25pAAAAB4kUcVkpycHD333HNKT09X\nhw4d1KhRI9WvX9/XsQEAgNLYp0DiWYUkISFB9erV06FDh1StWjUlJib6Oi4AAFAGwzC8ejOTRwlJ\nVlaWevXqJX9/f910001yuVy+jgsAAFQgHs8h2b9/vyTp5MmT8vPz81lAAACg4vEoIZk8ebISEhKU\nmpqqUaNGaeLEib6OCwAAVCAeTWo9fPiw1qxZI4eDRTkAAFw1bLQPiUcZxscff6zu3btrwYIFOnLk\niK9jAgAAHrDTpFaPKiRTpkxRQUGB3n33XSUlJamwsFAvvviij0MDAAAVhcc9mJ07d+rDDz/U6dOn\ndeutt/oyJgAA4AnD8O7NRB5VSLp27arGjRurd+/eSk5O9nVMAADAA2a3WbzJo4Rk9erVCg8P93Us\nFdZ7W7Zq8ozZ+ui9f5gdCixo47v/0qpX/ybDMFS5UiWNGz5UdWtHaeaCZ3Tw6DG53W7d3bGDHurd\n0+xQUY5u+X1rdep7p9xutwryCrT+z6/p8N7LzwG84f+aa1DCgxrbZcKves+gqkH6Q+KDiqgVIZfL\npdVPrtOBXQd/cTyomEpNSEaNGqWFCxfqnnvu+clzH374oc+CqkgOHT6i+Qv/IrfbbXYosKBDR4/p\nmeUrtHorIUhHAAAPRElEQVTxAkWEhWnb51/qsZmPq8NtbVSzejU9MXmC8vLy9cCwR9WqeTNd37iR\n2SGjHNSoV1094+5V8uC5ys7KUbPfNtGw5CFK7D39p6+tW133D+/ulXJ97Nje2rdjvzaNX6o6DWvr\n0blxmhKbpIia4R7Hg6tbz549FRwcLEmqW7eu4uLiNHHiRDkcDsXExGjatGlXPHapCcnChQslSS+/\n/LKioqJKjv93kzT8Ohfy8pQwfZbGjX1UE6ckmR0OLCjA6dTkMY8qIixMktQkpqHOnM3S6KF/kOP7\nXzAZZ86osKhIwUFBZoaKclRUUKSUJ9YoOytHknR4zxGFhofI4eeQq/h/O207Kzk1aPIAvbxogwZP\nfajkuMPPoZ7DuyvmhoYyHA4d2XdU6//8ivIvFJS8ZuCkftqzfZ8+3fS5JMlwGGp+WzOtmb9eknRs\n/3GdOpKuZr9tosN7jnoUD65AOS77LSi4+O+/cuXKkmPDhw9XfHy8WrdurWnTpmnz5s3q2LHjFY1f\n6qTWvXv36oMPPlBcXJy2bdumDz/8UFu3blV8fPwVvRkuNXPOPD1w/32KadjQ7FBgUVE1a6jtza1K\nHi9Yulztb71F/n5+cjgcmjJ3gfoOH6VWLa5X/bp1TIwU5enMqbPa9em3JY97jeyhHR9+/ZNf/v0f\n66Otf/tQx/Yfv+R45wc7qbioWI8PnafZQ+bq/Olz6hHXvdT3DK4aLMMwlHv+u5JjWZnnFF49TGfT\nPYsHV7fdu3fru+++05AhQzRo0CDt2LFDqampat26tSSpXbt2+vjjj694/FIrJOfPn9fGjRt1+vRp\nvfnmm5IuTqDp16/fFb8hLlr7ygY5/f3V/e4uOnb8hNnhwOLy8vI1bd7Tyjh9WgtnTS85PnP8WCXm\njdC4mY/rudXr9MiDfU2LEeXPWcmpQYkPKqxamJ557C+XPNf+vttVXFSsT/7xmSJrRVzyXPPbmqlK\nUBU1ubmxJMnP36Hss9mSpPHPxsvf6aeImhFqdGOMfvfAHdr/dZreTvnnZWNwuf7Xji4tHlyZ8pzU\nWrlyZQ0ZMkS9e/fWwYMHNXTo0EumGwQFBSk7O/uKxy81IWndurVat26tXbt2qVmzZlf8JvipNza+\nrfz8fD0wcLAKCwqV9/39JQueVLXISLPDg4WcTM9Q/PRkNahfT0vnJsvpdOqTL7/SddH1VS0yQpUr\nV9Jdd7TTe9uu/C8XWE94jXCNmDNUJw6c1PxRC1VcVHzJ82263CJnJacSnh8nf6e/Ar6/v2j8Ujkc\nDq1f+KpSP9st6WIi4QxwSpLmxs2XdPmWjSRVDqqsvNw8SVJYtao6m57lUTy4QuWYkERHR6t+/fol\n98PCwpSamlryfG5urkJDQ694/FITkqSkJE2dOlVJSUk/ycLWrl17xW8K6aXlfy25f/zESfXsN1Dr\nVy43MSJY0fnsHD0yLkH3/r6jHu7fp+T4P7d+qPc/+kSTRg5XQUGh/rn1Q7VpdaOJkaI8BQZX0Z+e\nGaWPNn6ijSs2XfY1TwybX3I/oma4pq6cpNlDnpQkpX72re7o2U67v9wrt8utgRP76UJunl6at67k\na348D9/tcuvrj3epXfe2eueld1WnYW1FRdfU3q/2KTAksMx4cPV79dVXtXfvXk2bNk2nTp1STk6O\n2rZtq88++0y33HKLtm7dqjZt2lzx+KUmJCNGjJAkzZ8/v7SXwQsM2WctOcrPK2+9rVOZp/X+R5/o\nvY8uVkAMGfrLnJmas+hZ9YkbJYdh6I7b2ij2vp+uloM9tetxu8JrhKlluxZq2e6G74+69dK8der3\nWJ+SxOOHfphgvLVik+4f0V2Jy8fL8f2k1lcXb7jk9SlzXvrJGGvnv6wHJ8Rqyos3y+12a/nMFOVf\nyFfnAZ0uG8/Toxfpu5wLXjrriskox0mtvXr10qRJk9SvXz85HA7NmTNHYWFhmjx5sgoLC9WwYUN1\n7tz5isc33B6sN929e7cuXLggh8Oh+fPnKy4uzqPdWvOz0q84MOByCs6eMTsE2Mi4gUvMDgE29OwH\nC8vtvTI//8ir41W7+TavjvdLeLR1/PTp0xUQEKC//OUvGjt2rBYtWuTruAAAQAXi0U6tAQEBiomJ\nUWFhoVq2bCmHw+NL4AAAAF+paFvHG4ah8ePHq127dtq4caOcTqev4wIAAGWocNeyWbBggb7++mu1\nb99en376KZNcAQCAV3ncsvnkk0+0evVqRUdHq1EjrocBAIDpbFQh8WgySEJCgmrXrq2xY8eqTp06\nmjhxoq/jAgAAZTAchldvZvKoQnL27FkNGDBAktSkSRNt2sTGNgAAwHs8qpDk5+crIyNDkpSRkSGX\niwsiAQAA7/GoQjJmzBjFxsbK6XSqsLBQM2fO9HVcAACgLBVtDklOTo5cLpf8/PzkdrtVXMxFkQAA\ngPd4VCFZsmSJXn75ZUVGRiozM1NxcXG6/fbbfR0bAAAojY0qJB4lJGFhYYqMjJQkVatWTcHBwT4N\nCgAAlK3CbYwWFBSkIUOG6Oabb9auXbuUl5dXsjlafHy8TwMEAAD251FC0rFjx5L7NWvW9FkwAADg\nFzB57xBv8igh6dGjh6/jAAAAFRiX7QUAAKbzqEICAACuPoZhn7qCfc4EAABYFhUSAACsqqIt+wUA\nAFcfO+1DQssGAACYjgoJAABWZaN9SKiQAAAA05GQAAAA09GyAQDAouw0qZWEBAAAq7JRQkLLBgAA\nmI4KCQAAVmWjreNJSAAAsCiDZb8AAADeQ0ICAABMR8sGAACrYpUNAACA91AhAQDAotgYDQAAmM9G\ny37tcyYAAMCyqJAAAGBR7EMCAADgRSQkAADAdLRsAACwKlbZAAAAs9lp2S8tGwAAYDoqJAAAWBX7\nkAAAAHgPFRIAAKyKfUgAAAC8h4QEAACYjpYNAAAWZadlvyQkAABYFatsAAAAvIcKCQAAFkXLBgAA\nmI+WDQAAgPeQkAAAANPRsgEAwKIMdmoFAADwHiokAABYFatsAACA2QxW2QAAAHgPFRIAAKzKRi0b\nw+12u80OAgAAVGy0bAAAgOlISAAAgOlISAAAgOlISAAAgOlISAAAgOlISAAAgOlISAAAgOlISK5C\nmzdvVkZGhjIzM5WUlGR2OLCwEydO6P333/f49QMGDNCBAwd8GBGs6Ic/i7744gvt3btXkjRq1Cgz\nw4LNkJBchVasWKGcnBxVq1ZNU6dONTscWNgnn3yi7du3mx0GLO6HP4teffVVnTp1SpK0cOFCM8OC\nzbB1/K+wYcMGbdmyRXl5eTpy5IiGDh2qpk2batasWZKksLAwzZ49W8HBwZoxY4Z27dqlyMhIHT16\nVEuXLlVubq7mzJkjl8uls2fPavr06Tp37px2796tCRMmaO7cuZowYYKSkpKUnJyslStXSpLi4uI0\nZswYZWdna8GCBfLz89M111yjpKQk+fn5mfktgZd5+hlLTU3V2rVrNX/+fEnS7bffrg8++EB//etf\nlZ+fr5tuuknLly9XZGSkzp8/r4ULF2ry5MnKzs5Wenq6+vfvr759+5p5qvCxDRs2aPPmzcrNzVVW\nVpZGjBih4OBgPf3006pUqZLCw8M1e/ZsFRQUaOzYsXK73SooKND06dMVEhKi+Ph4TZ06VR988IFS\nU1N13XXXqXfv3vr73/+u/v37a+PGjZKkmTNn6tZbb9U111xz2Z+FwM8hIfmVcnJytGzZMh06dEhx\ncXGqWrWqkpOT1bBhQ73yyit67rnn1KJFC507d07r16/XmTNn1LlzZ0nSvn37NHHiRMXExOjNN9/U\na6+9pqSkJDVu3FgzZ86U0+mUYRhq1KiRCgoKdOLECfn7+ysrK0uNGzfWXXfdpTVr1igiIkJ//vOf\n9dprr6l3794mf0fgbZ58xtq2bSvjR9e0MAxDjzzyiA4cOKAOHTpo+fLl6tatmzp27KjU1NSS++np\n6RowYAAJSQWQl5enF198UadPn1bv3r3lcDi0Zs0aVa9eXSkpKVq8eLHatGmj8PBwzZ07V/v27dOF\nCxcUEhIiwzDUrFkz/d///Z+6deumqKgoSVJ4eLgaN26sL774Qi1atNBnn32mxMRExcbGavbs2Zd8\nTseOHWvydwBXMxKSX6lJkyaSpKioKOXn52v//v2aMWOGJKmoqEj169dXWlqaWrZsKUmKiIjQtdde\nK0mqWbOmFi9erCpVqignJ+eSvx5+fImhXr16acOGDQoICFDPnj115swZZWRkaMyYMZKk/Px83Xbb\nbT4/X5Q/Tz5jnvrvZy8yMlIrVqzQO++8o6CgIBUVFXk/cFx1br75ZkkX//0DAwNVXFys6tWrS5Ja\nt26tBQsWaMKECTp48KCGDx8up9Op4cOH/2ScH/986t27tzZs2KCMjAzdeeedcjgcv+pzioqJhORX\n+vFfpQ0aNNDcuXNVq1Ytbd++XZmZmapUqZJef/11DRw4UOfOndPBgwclScnJyZo3b54aNGigZ555\nRsePH5ckORwOuVwuSf/7j9+1a1cNGjRIDodDy5cvV5UqVRQVFaUlS5YoODhY7733noKCgsrvxFFu\nPP2MpaenS5KOHTumrKyskq/972dJuvjZkqQXXnhBN954o/r27atPP/1UW7ZsKaezgZl27dol6eIk\n1QsXLsgwDGVkZKh69er67LPPFB0drU8//VTVq1fX888/r3//+9+aP3++Zs+eXTLGjz9TknTrrbfq\nySefVHp6eslck8t9ToHSkJB4kWEYmjZtmsaNG6fi4mI5HA4lJyerfv362rJli2JjY1WtWjVVqVJF\n/v7+uvfeezV69GhVrVpVNWvWLPklcuONN5bMHfnvL6PAwEA1btxYxcXFCgwMlCQlJibqkUcekcvl\nUkhIiJ544gnTzh3l4+c+Y3Xr1lVISIj69OmjBg0aqF69epKkRo0aaenSpWratOkliU2HDh00a9Ys\nvfXWWwoJCZHT6VRBQcFPkh/YS0ZGhgYNGqScnBzNmDFDfn5+GjlypBwOh0JDQzVnzhxJUnx8vNas\nWSOXy6VHH330kjFuuOEGPfXUU6pTp84lx++66y59/PHHJZ+9y31OgdIY7h/X3uB1aWlp2r17t7p2\n7aqsrCx169ZN77//vpxOp9mhAaggNmzYoAMHDig+Pt7sUIDLokJSDqKiojRv3jytWLFCLpdL48aN\nIxkBAOAHqJAAAADTsTEaAAAwHQkJAAAwHQkJAAAwHQkJAAAwHQkJAAAw3f8DzMMpxAfA9Z0AAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106244f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation data\n",
    "predicted_labels_LR = model_LR.predict(vocab_dev_tf)\n",
    "\n",
    "print \"Dev dataset with\", len(predicted_labels_LR), \"sentences\"\n",
    "print \"\"\n",
    "\n",
    "print \"Data split - Negative, Neutral, Positive\"\n",
    "print \"----------------------------------------\"\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev_predicted\",count_classes(0,predicted_labels_LR), \n",
    "                                                     count_classes(1,predicted_labels_LR),\n",
    "                                                     count_classes(2,predicted_labels_LR))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev_actual\",count_classes(0,dev_labels), \n",
    "                                                     count_classes(1,dev_labels),\n",
    "                                                     count_classes(2,dev_labels))\n",
    "\n",
    "\n",
    "accuracy = model_LR.score(vocab_dev_tf, dev_labels)\n",
    "print \"\\nAccuracy\"\n",
    "print \"--------\"\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)\n",
    "\n",
    "print \"\\nClassification Report\"\n",
    "print \"---------------------\"\n",
    "print classification_report(dev_labels, predicted_labels_LR)\n",
    "\n",
    "print \"\\nConfusion matrix for Dev data\"\n",
    "print \"-----------------------------\"\n",
    "\n",
    "array = confusion_matrix(dev_labels, predicted_labels_LR)\n",
    "df_cm = pd.DataFrame(array, index = [\"negative\", \"neutral\", \"positive\"],\n",
    "                  columns = [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "# Find the most confused pair\n",
    "cm2 = confusion_matrix(dev_labels, predicted_labels_LR)  # copy the cm matrix so that can modify the copy without affecting original cm\n",
    "np.fill_diagonal(cm2, 0)  # set the values in the diagonal = 0 to obtain number of confused pairs matrix\n",
    "maximum_pair_idx = np.where(cm2 == cm2.max())  # returns the indices of the max value in cm matrix\n",
    "true_interaction = maximum_pair_idx[0][0]\n",
    "predicted_interaction = maximum_pair_idx[1][0]\n",
    "max_wrong_prediction = cm2[true_interaction][predicted_interaction]\n",
    "print \"The most confused pair of classes is:\", true_interaction, \"(\", classes_dict[true_interaction],\")\",\\\n",
    "\" incorrectly predicted as\", predicted_interaction, \"(\", classes_dict[predicted_interaction],\")\"\n",
    "print \"Number of such confusion occurences:\", max_wrong_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 642 sentences\n",
      "\n",
      "Data split - Negative, Neutral, Positive\n",
      "----------------------------------------\n",
      "        dataset |       negative |        neutral |       positive\n",
      " test_predicted |      41.000000 |     515.000000 |      86.000000\n",
      "    test_actual |      95.000000 |     446.000000 |     101.000000\n",
      "\n",
      "Accuracy\n",
      "--------\n",
      "Accuracy (test data): 0.687\n",
      "\n",
      "Classification Report\n",
      "---------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.39      0.17      0.24        95\n",
      "          1       0.78      0.90      0.83       446\n",
      "          2       0.28      0.24      0.26       101\n",
      "\n",
      "avg / total       0.64      0.69      0.65       642\n",
      "\n",
      "\n",
      "Confusion matrix for test data\n",
      "------------------------------\n",
      "The most confused pair of classes is: 2 ( positive )  incorrectly predicted as 1 ( neutral )\n",
      "Number of such confusion occurences: 70\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGoCAYAAAB2af5OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111b3cb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test data\n",
    "\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "predicted_labels_LR2 = model_LR.predict(vocab_test_tf)\n",
    "print \"Test dataset with\", len(predicted_labels_LR2), \"sentences\"\n",
    "print \"\"\n",
    "\n",
    "print \"Data split - Negative, Neutral, Positive\"\n",
    "print \"----------------------------------------\"\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_predicted\",count_classes(0,predicted_labels_LR2), \n",
    "                                                     count_classes(1,predicted_labels_LR2),\n",
    "                                                     count_classes(2,predicted_labels_LR2))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_actual\",count_classes(0,test_labels), \n",
    "                                                     count_classes(1,test_labels),\n",
    "                                                     count_classes(2,test_labels))\n",
    "\n",
    "accuracy = model_LR.score(vocab_test_tf, test_labels)\n",
    "print \"\\nAccuracy\"\n",
    "print \"--------\"\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)\n",
    "\n",
    "print \"\\nClassification Report\"\n",
    "print \"---------------------\"\n",
    "print classification_report(test_labels, predicted_labels_LR2)\n",
    "\n",
    "\n",
    "print \"\\nConfusion matrix for test data\"\n",
    "print \"------------------------------\"\n",
    "\n",
    "array = confusion_matrix(test_labels, predicted_labels_LR2)\n",
    "df_cm = pd.DataFrame(array, index = [\"negative\", \"neutral\", \"positive\"],\n",
    "                  columns = [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, fmt='g')\n",
    "\n",
    "\n",
    "# Find the most confused pair\n",
    "cm3 = confusion_matrix(test_labels, predicted_labels_LR2)  # copy the cm matrix so that can modify the copy without affecting original cm\n",
    "np.fill_diagonal(cm3, 0)  # set the values in the diagonal = 0 to obtain number of confused pairs matrix\n",
    "maximum_pair_idx = np.where(cm3 == cm3.max())  # returns the indices of the max value in cm matrix\n",
    "true_interaction = maximum_pair_idx[0][0]\n",
    "predicted_interaction = maximum_pair_idx[1][0]\n",
    "max_wrong_prediction = cm3[true_interaction][predicted_interaction]\n",
    "print \"The most confused pair of classes is:\", true_interaction, \"(\", classes_dict[true_interaction],\")\",\\\n",
    "\" incorrectly predicted as\", predicted_interaction, \"(\", classes_dict[predicted_interaction],\")\"\n",
    "print \"Number of such confusion occurences:\", max_wrong_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Words with the highest weights per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 ( negative )\n",
      "1 weight: 9.029 for feature \" induced \"\n",
      "2 weight: 8.099 for feature \" acetylneuraminic \"\n",
      "3 weight: 6.967 for feature \" reversed \"\n",
      "4 weight: 6.932 for feature \" inhibited \"\n",
      "5 weight: 6.754 for feature \" also \"\n",
      "6 weight: 6.730 for feature \" nicotine \"\n",
      "7 weight: 6.685 for feature \" mug \"\n",
      "8 weight: 6.491 for feature \" mitochondrial \"\n",
      "9 weight: 6.485 for feature \" hepatotoxicity \"\n",
      "10 weight: 6.480 for feature \" stimulated \"\n",
      "Class 1 ( neutral )\n",
      "1 weight: 8.304 for feature \" on \"\n",
      "2 weight: 7.743 for feature \" study \"\n",
      "3 weight: 7.073 for feature \" investigated \"\n",
      "4 weight: 6.736 for feature \" not \"\n",
      "5 weight: 6.329 for feature \" were \"\n",
      "6 weight: 6.226 for feature \" measured \"\n",
      "7 weight: 5.891 for feature \" studied \"\n",
      "8 weight: 5.719 for feature \" no \"\n",
      "9 weight: 5.415 for feature \" evaluate \"\n",
      "10 weight: 5.406 for feature \" using \"\n",
      "Class 2 ( positive )\n",
      "1 weight: 8.108 for feature \" increased \"\n",
      "2 weight: 7.884 for feature \" inhibitory \"\n",
      "3 weight: 7.100 for feature \" increasing \"\n",
      "4 weight: 6.926 for feature \" identified \"\n",
      "5 weight: 6.281 for feature \" pectin \"\n",
      "6 weight: 5.801 for feature \" antagonism \"\n",
      "7 weight: 5.762 for feature \" h2o2 \"\n",
      "8 weight: 5.692 for feature \" aa \"\n",
      "9 weight: 5.498 for feature \" diabetic \"\n",
      "10 weight: 5.375 for feature \" monoamine \"\n",
      "\n",
      "Table of weights for each feature for each of the 3 labels:\n",
      "\n",
      "                                negative             neutral            positive\n",
      "             induced               9.029              -4.615              -6.430\n",
      "    acetylneuraminic               8.099              -2.569              -5.806\n",
      "            reversed               6.967              -2.893              -4.149\n",
      "           inhibited               6.932              -5.859              -0.439\n",
      "                also               6.754              -3.836              -2.965\n",
      "            nicotine               6.730              -3.077              -3.541\n",
      "                 mug               6.685              -2.297              -4.009\n",
      "       mitochondrial               6.491              -5.597              -1.469\n",
      "      hepatotoxicity               6.485              -2.696              -5.381\n",
      "          stimulated               6.480              -4.937              -1.614\n",
      "                  on              -1.895               8.304              -8.412\n",
      "               study              -6.948               7.743              -4.009\n",
      "        investigated              -3.195               7.073              -6.719\n",
      "                 not              -4.182               6.736              -2.126\n",
      "                were              -4.938               6.329              -3.042\n",
      "            measured              -3.522               6.226              -2.713\n",
      "             studied              -1.827               5.891              -4.202\n",
      "                  no              -0.481               5.719              -5.008\n",
      "            evaluate              -3.177               5.415              -3.365\n",
      "               using              -2.569               5.406              -4.142\n",
      "           increased              -0.137              -7.782               8.108\n",
      "          inhibitory              -2.707              -6.926               7.884\n",
      "          increasing              -3.207              -4.453               7.100\n",
      "          identified              -2.442              -5.628               6.926\n",
      "              pectin              -3.509              -3.234               6.281\n",
      "          antagonism              -1.693              -3.717               5.801\n",
      "                h2o2              -2.364              -3.056               5.762\n",
      "                  aa              -2.448              -3.044               5.692\n",
      "            diabetic              -3.708              -3.227               5.498\n",
      "           monoamine              -2.902              -1.993               5.375\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train = vectorizer.fit_transform(train_data)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "model_LR = LogisticRegression(C=optimal_Cs)\n",
    "model_LR.fit(vocab_train, train_labels)\n",
    "\n",
    "weights = model_LR.coef_   # weight vector for each label\n",
    "top30_features_index = []  # list of 30 features (10 words with the largest weights for each label)\n",
    "class_list = ['negative', 'neutral', 'positive']\n",
    "\n",
    "for i in range(3):  # 4 labels\n",
    "    weights_label_i = list(weights[i])  # list of weights for label i\n",
    "    top10_weights_label_i = sorted(weights_label_i, reverse=True)[0:10]  # sort and filter greatest 10 weights\n",
    "    top10_features_index_i = [weights_label_i.index(weight) \\\n",
    "                             for weight in top10_weights_label_i]  # find index of top 10\n",
    "    top10_features_i = [feature_names[index] for index in top10_features_index_i]  # list of features of top 10 weights\n",
    "    top30_features_index += top10_features_index_i  # add the top 10 weigths index of label i to the list of 30\n",
    "\n",
    "    # Print top 5 features per label\n",
    "    print \"Class\", i, \"(\", class_list[i] , \")\"\n",
    "    for index, (weight, feature) in enumerate(zip(top10_weights_label_i,top10_features_i), start = 1):\n",
    "        print index, \"weight: %.3f\" %(weight), \"for feature \\\"\", feature, \"\\\"\"\n",
    "\n",
    "top30_features = [feature_names[index] for index in top30_features_index]  # list of features of top 20 weights\n",
    "\n",
    "# Formatting weights for each class for printing table of results\n",
    "top30_w_class0 = [\"%.3f\" %(list(weights[0])[index]) for index in top30_features_index]\n",
    "top30_w_class1 = [\"%.3f\" %(list(weights[1])[index]) for index in top30_features_index]\n",
    "top30_w_class2 = [\"%.3f\" %(list(weights[2])[index]) for index in top30_features_index]\n",
    "\n",
    "\n",
    "\n",
    "weights_array = np.column_stack((top30_w_class0, top30_w_class1, top30_w_class2))\n",
    "\n",
    "# Print table of weights for the 20 top features\n",
    "print \"\\nTable of weights for each feature for each of the 3 labels:\\n\"\n",
    "row_format =\"{:>20}\" * (len(class_list) + 1)\n",
    "print row_format.format(\"\", *class_list)\n",
    "for feature, weights in zip(top30_features, weights_array):\n",
    "    print row_format.format(feature, *weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. R-ratio analysis - look at individual sentences with highest errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 sentences where the ratio R is largest:\n",
      "\n",
      "                         ratio R     Max pred Pr      Correct Pr Predicted label      True label       Doc Index\n",
      "       Highest R         386.589           0.975           0.003             1.0             2.0           344.0\n",
      "     2nd highest         239.864           0.508           0.002             2.0             0.0           593.0\n",
      "     3rd highest         224.204           0.973           0.004             2.0             0.0           387.0\n",
      "             4th         218.533           0.867           0.004             1.0             0.0           164.0\n",
      "             5th         175.276           0.596           0.003             1.0             0.0            56.0\n",
      "             6th         175.276           0.596           0.003             1.0             0.0            57.0\n",
      "             7th         175.276           0.596           0.003             1.0             0.0            58.0\n",
      "             8th         172.807           0.985           0.006             1.0             0.0           124.0\n",
      "             9th         170.902           0.549           0.003             1.0             0.0           554.0\n",
      "            10th         137.194           0.794           0.006             1.0             0.0           403.0\n",
      "\n",
      "Sentences:\n",
      "\n",
      "1) Sentence with ratio R = 386.589 :\n",
      "We developed a diagnostic assay based upon color transformations of polydiacetylene, a unique conjugated polymer, upon interactions with blood plasma obtained from healthy individuals, hypercholesterolemic patients, hypercholesterolemic patients treated with statin, and hypercholesterolemic patients treated with statin together with pomegranate extracts.\n",
      "\n",
      "2) Sentence with ratio R = 239.864 :\n",
      "A concurrent increase in plasma 3-O-methyldopa (3-OMD) and a decrease in plasma 3,4-dihydroxyphenylacetic acid (DOPAC) and homovanillic acid (HVA), the three major metabolites of levodopa, suggests an inhibition of the enzyme dopa decarboxylase, probably by isoniazid.\n",
      "\n",
      "3) Sentence with ratio R = 224.204 :\n",
      "Bupropion administration significantly increased digoxin renal clearance in rats.\\\n",
      "\n",
      "4) Sentence with ratio R = 218.533 :\n",
      "Nevertheless, lovastatin did inhibit the accumulation of gibberellins in the culture medium; this inhibition, however, was counteracted by the addition of mevalonate to the medium.\n",
      "\n",
      "5) Sentence with ratio R = 175.276 :\n",
      "Consumption of pectin or oat bran together with Lovastatin reduces absorption of the drug, while alcohol intake does not appear to affect the efficacy and safety of Fluvastatin treatment.\n",
      "\n",
      "6) Sentence with ratio R = 175.276 :\n",
      "Consumption of pectin or oat bran together with Lovastatin reduces absorption of the drug, while alcohol intake does not appear to affect the efficacy and safety of Fluvastatin treatment.\n",
      "\n",
      "7) Sentence with ratio R = 175.276 :\n",
      "Consumption of pectin or oat bran together with Lovastatin reduces absorption of the drug, while alcohol intake does not appear to affect the efficacy and safety of Fluvastatin treatment.\"\n",
      "\n",
      "8) Sentence with ratio R = 172.807 :\n",
      "In this study, we tested the hypothesis that statins act directly on sensory neurons to decrease expression of proinflammatory neuropeptides that trigger neurogenic inflammation, specifically calcitonin gene-related peptide (CGRP) and substance P. Reverse transcriptase-polymerase chain reaction, radioimmunoassay, and immunocytochemistry were used to quantify CGRP and substance P expression in dorsal root ganglia (DRG) harvested from adult male rats and in primary cultures of sensory neurons derived from embryonic rat DRG.\n",
      "\n",
      "9) Sentence with ratio R = 170.902 :\n",
      "In animals pretreated with microinjections of isoniazid, 150 micrograms, an inhibitor of activity of the GABA-synthesizing enzyme, L-glutamic acid decarboxylase, into the substantia nigra pars reticulata (SNR), bilaterally, non-convulsant doses of pilocarpine, 100 and 200 mg/kg, resulted in severe motor limbic seizures and status epilepticus.\n",
      "\n",
      "10) Sentence with ratio R = 137.194 :\n",
      "Drugs which reduce digoxin absorption include the antacids aluminium hydroxide, magnesium hydroxide and magnesium trisilicate, the antidiarrhoeals kaolin and pectin, the hypocholesterolaemic agent cholestyramine and the chemotoxins cyclophosphamide, vincristine and bleomycin.\\\n",
      "\n",
      "Sentence 1 (example number 344 ):\n",
      "Influential word: patients with magnitude: 1.56835722571\n",
      "Influential word: assay with magnitude: 0.5945889718\n",
      "Influential word: pomegranate with magnitude: 0.474120098123\n",
      "Influential word: we with magnitude: 0.402457945349\n",
      "Influential word: obtained with magnitude: 0.366814336195\n",
      "\n",
      "Sentence 2 (example number 593 ):\n",
      "Influential word: decrease with magnitude: 0.689604727429\n",
      "Influential word: increase with magnitude: 0.680514658316\n",
      "Influential word: suggests with magnitude: 0.614038037393\n",
      "Influential word: in with magnitude: 0.427028328718\n",
      "Influential word: concurrent with magnitude: 0.41700097484\n",
      "\n",
      "Sentence 3 (example number 387 ):\n",
      "Influential word: clearance with magnitude: 1.98824341072\n",
      "Influential word: increased with magnitude: 1.72837371135\n",
      "Influential word: renal with magnitude: 1.30580158207\n",
      "Influential word: significantly with magnitude: 0.982483667512\n",
      "Influential word: rats with magnitude: 0.51802284309\n",
      "\n",
      "Sentence 4 (example number 164 ):\n",
      "Influential word: medium with magnitude: 1.60085258991\n",
      "Influential word: this with magnitude: 0.663588268124\n",
      "Influential word: did with magnitude: 0.568567709304\n",
      "Influential word: culture with magnitude: 0.316830916389\n",
      "Influential word: of with magnitude: 0.311128364461\n",
      "\n",
      "Sentence 5 (example number 56 ):\n",
      "Influential word: not with magnitude: 0.885744279973\n",
      "Influential word: affect with magnitude: 0.746040913215\n",
      "Influential word: or with magnitude: 0.501892237949\n",
      "Influential word: of with magnitude: 0.381455213305\n",
      "Influential word: alcohol with magnitude: 0.335098584249\n",
      "\n",
      "Sentence 6 (example number 57 ):\n",
      "Influential word: not with magnitude: 0.885744279973\n",
      "Influential word: affect with magnitude: 0.746040913215\n",
      "Influential word: or with magnitude: 0.501892237949\n",
      "Influential word: of with magnitude: 0.381455213305\n",
      "Influential word: alcohol with magnitude: 0.335098584249\n",
      "\n",
      "Sentence 7 (example number 58 ):\n",
      "Influential word: not with magnitude: 0.885744279973\n",
      "Influential word: affect with magnitude: 0.746040913215\n",
      "Influential word: or with magnitude: 0.501892237949\n",
      "Influential word: of with magnitude: 0.381455213305\n",
      "Influential word: alcohol with magnitude: 0.335098584249\n",
      "\n",
      "Sentence 8 (example number 124 ):\n",
      "Influential word: expression with magnitude: 1.01386739442\n",
      "Influential word: substance with magnitude: 0.981060366422\n",
      "Influential word: study with magnitude: 0.539135873628\n",
      "Influential word: calcitonin with magnitude: 0.529134866765\n",
      "Influential word: tested with magnitude: 0.524335155827\n",
      "\n",
      "Sentence 9 (example number 554 ):\n",
      "Influential word: 200 with magnitude: 0.595607864103\n",
      "Influential word: of with magnitude: 0.425054922266\n",
      "Influential word: doses with magnitude: 0.408328087241\n",
      "Influential word: 100 with magnitude: 0.398821065934\n",
      "Influential word: isoniazid with magnitude: 0.339233142388\n",
      "\n",
      "Sentence 10 (example number 403 ):\n",
      "Influential word: magnesium with magnitude: 0.803673685392\n",
      "Influential word: aluminium with magnitude: 0.566703618379\n",
      "Influential word: and with magnitude: 0.425422236581\n",
      "Influential word: include with magnitude: 0.348377372297\n",
      "Influential word: hydroxide with magnitude: 0.282756863552\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Logistic regression model with optimal C\n",
    "model_LR = LogisticRegression(C=optimal_Cs)\n",
    "model_LR.fit(vocab_train_tf, train_labels)\n",
    "predicted_labels_LR = model_LR.predict(vocab_test_tf)\n",
    "\n",
    "#feature_names = vectorizer.get_feature_names()\n",
    "#print \"features names length:\", len(feature_names)\n",
    "\n",
    "    \n",
    "# Variables to calculate R\n",
    "probabilities = model_LR.predict_proba(vocab_test_tf)  # Each label probability (4) for each document\n",
    "proba_max = probabilities.max(axis=1)  # Maximum predicted probability\n",
    "proba_correct_label = [probabilities[i][test_labels[i]] \\\n",
    "                       for i in range(probabilities.shape[0])]  # Predicted prob of the correct label\n",
    "r_ratio = proba_max/proba_correct_label  # R = maximum predicted prob / predicted prob of the correct label\n",
    "sentence_index = [i for i in range(probabilities.shape[0])]  # Index of the document to retrace once sorted by R\n",
    "\n",
    "# Results array with 5 columns (R, max prob, prob of correct label, predicted labels, true labels,\n",
    "# document index)\n",
    "results = np.column_stack((r_ratio, proba_max, proba_correct_label, predicted_labels_LR, \\\n",
    "                           test_labels, sentence_index))\n",
    "results_max3r = sorted(results, key=lambda x: x[0], reverse=True)[:10]  # top 10 sentences with highest R\n",
    "\n",
    "\n",
    "# Format and print top 3 documents with highest R:\n",
    "# 1) print top 10 sentences related info - probabilities, predicted/correct labels, etc.\n",
    "print \"\\nTop 10 sentences where the ratio R is largest:\\n\"\n",
    "column_names = [\"ratio R\", \"Max pred Pr\", \"Correct Pr\", \"Predicted label\", \"True label\", \\\n",
    "                \"Doc Index\"]\n",
    "row_format =\"{:>16}\" * (len(column_names)+1)\n",
    "print row_format.format(\"\", *column_names)\n",
    "top_10 = [\"Highest R\", \"2nd highest\", \"3rd highest\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \"10th\"]\n",
    "for index, row in zip(top_10, results_max3r):\n",
    "    row = [round(item,3) for item in row]\n",
    "    print row_format.format(index, *row)\n",
    "\n",
    "# 2) print top 3 R documents messages\n",
    "print \"\\nSentences:\"\n",
    "i = 1\n",
    "for row in results_max3r:\n",
    "    print \"\\n\" + str(i) +\") Sentence with ratio R = %.3f\" %(row[0]), \":\"\n",
    "    print test_data[int(row[5])]\n",
    "    i +=1  \n",
    "\n",
    "\n",
    "# Diagnosis of influential words in the 3 documents with highest R\n",
    "weights = model_LR.coef_\n",
    "sentence_list = [int(result[5]) for result in results_max3r]\n",
    "j=1\n",
    "\n",
    "for example in sentence_list:\n",
    "    predicted_label = predicted_labels_LR[example]\n",
    "    indices = vocab_test_tf[example].indices  # list of indices of non zero features of document\n",
    "    vocab_freq = vocab_test_tf[example].data  # list of features values of document\n",
    "    weights_example = [weights[predicted_label][index] for index in indices]  # list of LR weights \n",
    "                                                                              # for non zero features of doc\n",
    "    feature_importance = vocab_freq * weights_example  # feature value x weight for total influence on prediction\n",
    "\n",
    "    features_array = np.column_stack((feature_importance, indices))\n",
    "    features_sorted = sorted(features_array, key=lambda x: x[0], reverse=True)  # Sort words by influence\n",
    "\n",
    "    # Print top 5 features (words) of the document with heaviest weight x value\n",
    "    \n",
    "    print \"\\nSentence\", j,  \"(example number\", example, \"):\"\n",
    "    for i in range(5):\n",
    "        index = int(features_sorted[i][1])\n",
    "        print \"Influential word:\", feature_names[index] ,\"with magnitude:\", features_sorted[i][0]\n",
    "    j +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def empty_preprocessor(s):\n",
    "    return s\n",
    "\n",
    "def better_preprocessor(s):\n",
    "    #s = s.lower()  # to lowercase all letters in the string\n",
    "    #s = re.sub(\"[^a-zA-Z0-9]\", \" \", s) # to remove non-letter and non-numerical characters\n",
    "    #s = re.sub ('\\d+', \" numsequence \",s)  # replace sequences of numbers with a single token\n",
    "    \n",
    "    pronoun_list = ['you', 'he', 'she', 'we', 'they', 'me', 'him', 'his', 'her', 'hers', 'yours', 'us', 'our'\\\n",
    "                   'ours', 'their', 'theirs']  # list of pronouns as stopwords since not informative for prediciton\n",
    "    for word in pronoun_list:\n",
    "        s = re.sub(r'\\b%s\\b' % word, \" \",s)  # to remove stopwords in the list\n",
    "        \n",
    "    nothelping = ['or', 'to', 'of', 'a', 'on', 'the']\n",
    "    for word in nothelping:\n",
    "        s = re.sub(r'\\b%s\\b' % word, \" \",s)  # to remove stopwords in the list\n",
    "        \n",
    "    #s = re.sub(r'ly\\b', \"\",s)   # to remove \"ly\" from words ending by \"ly\"\n",
    "    s = re.sub(r'ing\\b', \"\",s)  # to remove \"ing\" from words ending by \"ing\"\n",
    "    #s = re.sub(r's\\b', \"\",s)    # to remove \"s\" from words ending by \"s\"\n",
    "    \n",
    "    for word in s.split():  # to shorten words longer than 15 characters (from histogram, most words < 15)\n",
    "        if len(word)>15:\n",
    "            short_word = word[:15]\n",
    "            s = s.replace(word,short_word)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary with no preprocessor: 8057\n",
      "accuracy with no custom preprocessor is: 0.687\n",
      "\n",
      "Size of vocabulary with custom preprocessor: 8600\n",
      "accuracy with custom preprocessor is: 0.676\n"
     ]
    }
   ],
   "source": [
    "# No preprocessor\n",
    "vectorizer_initial = TfidfVectorizer()\n",
    "vocab_train_initial = vectorizer_initial.fit_transform(train_data)\n",
    "vocab_test_initial = vectorizer_initial.transform(test_data)\n",
    "count_features_init = len(vectorizer_initial.get_feature_names())\n",
    "print \"Size of vocabulary with no preprocessor:\", count_features_init\n",
    "\n",
    "model_LR_initial = LogisticRegression(C=optimal_Cs)\n",
    "model_LR_initial.fit(vocab_train_initial, train_labels)\n",
    "predicted_labels_initial = model_LR_initial.predict(vocab_test_initial)\n",
    "accuracy_initial = model_LR_initial.score(vocab_test_initial, test_labels)\n",
    "print \"accuracy with no custom preprocessor is: %.3f\" %(accuracy_initial)\n",
    "print \"\"\n",
    "\n",
    "\n",
    "# With preprocessor\n",
    "vectorizer_better = TfidfVectorizer(preprocessor=better_preprocessor)\n",
    "vocab_train_better = vectorizer_better.fit_transform(train_data)\n",
    "vocab_test_better = vectorizer_better.transform(test_data)\n",
    "\n",
    "count_features_better = len(vectorizer_better.get_feature_names())\n",
    "print \"Size of vocabulary with custom preprocessor:\", count_features_better\n",
    "\n",
    "model_LR_better = LogisticRegression(C=optimal_Cs)\n",
    "model_LR_better.fit(vocab_train_better, train_labels)\n",
    "predicted_labels_better = model_LR_better.predict(vocab_test_better)\n",
    "accuracy_better = model_LR_better.score(vocab_test_better, test_labels)\n",
    "print \"accuracy with custom preprocessor is: %.3f\" %(accuracy_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. N-grams instead of unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (dev data): 0.912\n",
      "Accuracy (test data): 0.688\n"
     ]
    }
   ],
   "source": [
    "# Turn the raw training text into feature vectors based on \"td-idf\"\n",
    "vectorizer = TfidfVectorizer(analyzer='word' , ngram_range=(4,5))\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_dev_tf = vectorizer.transform(dev_data)\n",
    "\n",
    "# Logistic regression model\n",
    "model_LR = LogisticRegression(C=optimal_Cs)\n",
    "model_LR.fit(vocab_train_tf, train_labels)\n",
    "predicted_labels_LR_ngram = model_LR.predict(vocab_dev_tf)\n",
    "\n",
    "accuracy = model_LR.score(vocab_dev_tf, dev_labels)\n",
    "print \"Accuracy (dev data): %.3f\" %(accuracy)\n",
    "\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "predicted_labels_LR_ngram2 = model_LR.predict(vocab_test_tf)\n",
    "accuracy = model_LR.score(vocab_test_tf, test_labels)\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_dev_tf = vectorizer.transform(dev_data)\n",
    "vocab_test_tf = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Support Vector Machine model ...\n",
      "Performing grid search for Support Vector Machine model. It may take a few minutes ...\n",
      "Support Vector Machines grid search model fitting time = 10.589717 seconds.\n",
      "As per the grid search on the training data, the optimal value of C = 0.000100.\n",
      "Support Vector Machines prediction time for dev data = 0.110224 seconds.\n",
      "Accuracy on dev data for Support Vector Machine is = 0.596070\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        76\n",
      "          1       0.60      1.00      0.75       273\n",
      "          2       0.00      0.00      0.00       109\n",
      "\n",
      "avg / total       0.36      0.60      0.45       458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Support Vector Machines:\n",
    "print \"Evaluating Support Vector Machine model ...\"\n",
    "\n",
    "# Create a Support Vector Machine model. \n",
    "SVMmodel = SVC(C=1.0)\n",
    "\n",
    "# Create a grid search.\n",
    "print \"Performing grid search for Support Vector Machine model. It may take a few minutes ...\"\n",
    "Cs = {'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0]}\n",
    "CV_SVMmodel = GridSearchCV(estimator=SVMmodel, param_grid=Cs)\n",
    "\n",
    "# Fit the models using grid search and display the results.\n",
    "start_time = time.time()\n",
    "CV_SVMmodel.fit(vocab_train_tf, train_labels)\n",
    "end_time = time.time()\n",
    "print \"Support Vector Machines grid search model fitting time = %f seconds.\" % (end_time - start_time)\n",
    "\n",
    "optimal_Cs = CV_SVMmodel.best_params_['C']\n",
    "print \"As per the grid search on the training data, the optimal value of C = %f.\" % optimal_Cs\n",
    "\n",
    "# Predict labels for dev data and calculate accuracy using optimal C\n",
    "start_time = time.time()\n",
    "SVMmodel = CV_SVMmodel.predict(vocab_dev_tf)\n",
    "end_time = time.time()\n",
    "print \"Support Vector Machines prediction time for dev data = %f seconds.\" % (end_time - start_time)\n",
    "\n",
    "# Print goodness of fit measures\n",
    "print \"Accuracy on dev data for Support Vector Machine is = %f\" % CV_SVMmodel.score(vocab_dev_tf, dev_labels)\n",
    "print \"Classification Report\\n\", classification_report(dev_labels, SVMmodel)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model\n",
      "Accuracy (dev data): 0.620\n",
      "Test dataset with 671 sentences\n",
      "Accuracy (test data): 0.715\n",
      "        dataset |       negative |        neutral |       positive\n",
      " test_predicted |       0.000000 |     671.000000 |       0.000000\n",
      "    test_actual |     146.000000 |     480.000000 |      45.000000\n",
      "Confusion matrix for test data\n",
      "The most confused pair of classes is: 0 ( negative )  incorrectly predicted as 1 ( neutral )\n",
      "Number of such confusion occurences: 146\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGpCAYAAAC9NS3rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAGA4EhIAAGA4EhIAAGC4/w+sVVJQ3ebqzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11195fa10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Turn the raw training text into feature vectors based on \"td-idf\"\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "#vocab_dev_tf = vectorizer.transform(dev_data)\n",
    "\n",
    "# SVM model\n",
    "model_SVM = SVC(C=0.0001)\n",
    "model_SVM.fit(vocab_train_tf, train_labels)\n",
    "predicted_labels_SVM = model_SVM.predict(vocab_dev_tf)\n",
    "\n",
    "# DEV\n",
    "print \"SVM model\"\n",
    "accuracy = model_SVM.score(vocab_dev_tf, dev_labels)\n",
    "print \"Accuracy (dev data): %.3f\" %(accuracy)\n",
    "\n",
    "# TEST\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "predicted_labels_SVM2 = model_SVM.predict(vocab_test_tf)\n",
    "print \"Test dataset with\", len(predicted_labels_SVM2), \"sentences\"\n",
    "accuracy = model_SVM.score(vocab_test_tf, test_labels)\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)\n",
    "\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_predicted\",count_classes(0,predicted_labels_SVM2), \n",
    "                                                     count_classes(1,predicted_labels_SVM2),\n",
    "                                                     count_classes(2,predicted_labels_SVM2))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_actual\",count_classes(0,test_labels), \n",
    "                                                     count_classes(1,test_labels),\n",
    "                                                     count_classes(2,test_labels))\n",
    "\n",
    "print \"Confusion matrix for test data\"\n",
    "\n",
    "array = confusion_matrix(test_labels, predicted_labels_SVM2)\n",
    "df_cm = pd.DataFrame(array, index = [\"negative\", \"neutral\", \"positive\"],\n",
    "                  columns = [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "\n",
    "# Find the most confused pair\n",
    "cm3 = confusion_matrix(test_labels, predicted_labels_SVM2)  # copy the cm matrix so that can modify the copy without affecting original cm\n",
    "np.fill_diagonal(cm3, 0)  # set the values in the diagonal = 0 to obtain number of confused pairs matrix\n",
    "maximum_pair_idx = np.where(cm3 == cm3.max())  # returns the indices of the max value in cm matrix\n",
    "true_interaction = maximum_pair_idx[0][0]\n",
    "predicted_interaction = maximum_pair_idx[1][0]\n",
    "max_wrong_prediction = cm3[true_interaction][predicted_interaction]\n",
    "print \"The most confused pair of classes is:\", true_interaction, \"(\", classes_dict[true_interaction],\")\",\\\n",
    "\" incorrectly predicted as\", predicted_interaction, \"(\", classes_dict[predicted_interaction],\")\"\n",
    "print \"Number of such confusion occurences:\", max_wrong_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
