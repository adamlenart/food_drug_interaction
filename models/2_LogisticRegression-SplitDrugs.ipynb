{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import time\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_alpha</th>\n",
       "      <th>Label_num</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Food</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>pentadecanoic acid</td>\n",
       "      <td>(123)iodine labelled beta-methyl-iodophenyl pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>2-phenylethanol</td>\n",
       "      <td>2-Phenylethanol is a widely used aroma compoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>3,4-dihydroxyphenylacetic acid</td>\n",
       "      <td>3,4-dihydroxyphenylacetic acid and 4-methylcat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>arachin</td>\n",
       "      <td>A 96-well microplate format of this method was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>diethylamine</td>\n",
       "      <td>A biochemical study was performed in order to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label_alpha  Label_num           Drug                            Food  \\\n",
       "ID                                                                          \n",
       "400     neutral          1  ACE inhibitor              pentadecanoic acid   \n",
       "333    positive          2  ACE inhibitor                 2-phenylethanol   \n",
       "77     positive          2  ACE inhibitor  3,4-dihydroxyphenylacetic acid   \n",
       "338     neutral          1  ACE inhibitor                         arachin   \n",
       "214     neutral          1  ACE inhibitor                    diethylamine   \n",
       "\n",
       "                                              sentence  \n",
       "ID                                                      \n",
       "400  (123)iodine labelled beta-methyl-iodophenyl pe...  \n",
       "333  2-Phenylethanol is a widely used aroma compoun...  \n",
       "77   3,4-dihydroxyphenylacetic acid and 4-methylcat...  \n",
       "338  A 96-well microplate format of this method was...  \n",
       "214  A biochemical study was performed in order to ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../labeled_dataAll.csv\", index_col='ID')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ACE inhibitor', 'Antacid', 'GLP-1', 'Thyroxine', 'Statin',\n",
       "       'Acetaminophen', 'Digoxin', 'Isoniazid', 'Antihistamine', 'MOAI',\n",
       "       'Analgesics', 'Bronchodialators'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Drug.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.Drug == 'Digoxin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df[(df.Drug != \"Statin\") & (df.Drug != \"Isoniazid\") & (df.Drug != \"Digoxin\")]\n",
    "df_test = df[(df.Drug == \"Statin\") | (df.Drug == \"Isoniazid\") | (df.Drug == \"Digoxin\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Applications/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Applications/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Applications/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Randomly shuffle the data. Use same random seed to get same results every time. \n",
    "df_shuffle = df_train.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "# Separate labels\n",
    "labels = [i for i in df_shuffle.Label_num]\n",
    "labels = np.array(labels)\n",
    "n = len(labels)\n",
    "\n",
    "labels2 = [i for i in df_test.Label_num]\n",
    "labels2 = np.array(labels2)\n",
    "\n",
    "\n",
    "# Drop unecessary columns from input data\n",
    "df_shuffle.drop('Label_alpha', axis=1, inplace=True)\n",
    "df_shuffle.drop('Label_num', axis=1, inplace=True)\n",
    "df_shuffle.drop('Drug', axis=1, inplace=True)\n",
    "df_shuffle.drop('Food', axis=1, inplace=True)\n",
    "\n",
    "df_test.drop('Label_alpha', axis=1, inplace=True)\n",
    "df_test.drop('Label_num', axis=1, inplace=True)\n",
    "df_test.drop('Drug', axis=1, inplace=True)\n",
    "df_test.drop('Food', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Split the train data into training and dev datasets\n",
    "train_data =  df_shuffle[:3*n/4].sentence.tolist()\n",
    "dev_data = df_shuffle[3*n/4:].sentence.tolist()\n",
    "test_data = df_test.sentence.tolist()\n",
    "\n",
    "# Separate training and dev labels\n",
    "train_labels =  labels[:3*n/4]\n",
    "dev_labels = labels[3*n/4:]\n",
    "test_labels = labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training label shape: (1371,)\n",
      "test label shape: (642,)\n",
      "dev label shape: (458,)\n"
     ]
    }
   ],
   "source": [
    "print 'training label shape:', train_labels.shape\n",
    "print 'test label shape:', test_labels.shape\n",
    "print 'dev label shape:', dev_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['negative', 'neutral', 'positive'] # corresponding labels = 0, 1, 2\n",
    "classes_dict = {0:'negative', 1:'neutral', 2:'positive'} # corresponding labels = 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_classes(value, labels):\n",
    "    return len([i for i in labels if i == value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split among Negative, Neutral and Positive\n",
      "\n",
      "        dataset |       negative |        neutral |       positive\n",
      "          train |     188.000000 |     862.000000 |     321.000000\n",
      "            dev |      76.000000 |     273.000000 |     109.000000\n",
      "           test |      95.000000 |     446.000000 |     101.000000\n"
     ]
    }
   ],
   "source": [
    "# Check number of classes per train/dev/test dataset:\n",
    "print \"Dataset split among Negative, Neutral and Positive\"\n",
    "print \"\"\n",
    "\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"train\",count_classes(0,train_labels), \n",
    "                                                     count_classes(1,train_labels),\n",
    "                                                     count_classes(2,train_labels))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev\",count_classes(0,dev_labels), \n",
    "                                                     count_classes(1,dev_labels),\n",
    "                                                     count_classes(2,dev_labels))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test\",count_classes(0,test_labels), \n",
    "                                                     count_classes(1,test_labels),\n",
    "                                                     count_classes(2,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example 1\n",
      "Label 1 ( neutral )\n",
      "Sentence:\n",
      "This report shows that, in the absence of glucose, a nonglucidic nutrient, namely succinic acid dimethyl ester (SAD), allows full expression of the insulinotropic potential of GLP-1 in the perfused pancreas from diabetic GK rats.\" \n",
      "\n",
      "\n",
      "Training example 2\n",
      "Label 1 ( neutral )\n",
      "Sentence:\n",
      "Insulin responses to glucagon-like peptide-1 (10(-9) mol/l), cholecystokinin-8 (10(-8) mol/l) and L-alanine (10 mmol/l) were increased by 32%, 31% and 68% respectively (p<0.05-0.01).\" \n",
      "\n",
      "\n",
      "Training example 3\n",
      "Label 1 ( neutral )\n",
      "Sentence:\n",
      "As ACE is a membrane protein, the interaction of flavanols and procyanidins with the enzyme could be related to the number of hydroxyl groups on the procyanidins, which determine their capacity to be adsorbed on the membrane surface.\" \n",
      "\n",
      "\n",
      "Training example 4\n",
      "Label 1 ( neutral )\n",
      "Sentence:\n",
      "Patients were randomly assigned to consume 120g/day of 1 of the 3 types of bread for each nutritional intervention: conventional wheat bread (CB), low-sodium wheat bread enriched in potassium (LSB), and low-sodium wheat bread rich in potassium, GABA, and ACEI peptides (LSB+G).\" \n",
      "\n",
      "\n",
      "Training example 5\n",
      "Label 1 ( neutral )\n",
      "Sentence:\n",
      "The analgesic potential of six 14-membered-ring cyclopeptide alkaloids, namely, franganine (1), discarine B (2), scutianines B (3), C (4), and D (5), and adouetine X (6), have been investigated. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check few sentences\n",
    "\n",
    "def print_examples(num_examples=5):\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        print \"Training example\", i+1\n",
    "        print \"Label\", train_labels[i], \"(\", classes_dict[train_labels[i]],\")\"\n",
    "        print \"Sentence:\\n\", train_data[i], \"\\n\\n\"\n",
    "       \n",
    "    \n",
    "print_examples(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the raw training text into feature vectors based on \"td-idf\"\n",
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_dev_tf = vectorizer.transform(dev_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression model ...\n",
      "Performing grid search for Logistic Regression model. It may take a few minutes ...\n",
      "Logistic Regression grid search model fitting time = 0.645908 seconds.\n",
      "As per the grid search on the training data, the optimal value of C = 50.000000.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=50.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression:\n",
    "print \"Evaluating Logistic Regression model ...\"\n",
    "\n",
    "# Create a Logistic Regression model. \n",
    "LRmodel = LogisticRegression(C=1.0)\n",
    "\n",
    "# Create a grid search.\n",
    "print \"Performing grid search for Logistic Regression model. It may take a few minutes ...\"\n",
    "Cs = {'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0]}\n",
    "CV_LRmodel = GridSearchCV(estimator=LRmodel, param_grid=Cs)\n",
    "\n",
    "# Fit the models using grid search and display the results.\n",
    "start_time = time.time()\n",
    "CV_LRmodel.fit(vocab_train_tf, train_labels)\n",
    "end_time = time.time()\n",
    "print \"Logistic Regression grid search model fitting time = %f seconds.\" % (end_time - start_time)\n",
    "\n",
    "optimal_Cs = CV_LRmodel.best_params_['C']\n",
    "print \"As per the grid search on the training data, the optimal value of C = %f.\" % optimal_Cs\n",
    "\n",
    "# Construct model with optimal C\n",
    "model_LR = LogisticRegression(C=optimal_Cs)\n",
    "model_LR.fit(vocab_train_tf, train_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev dataset with 458 sentences\n",
      "\n",
      "Data split - Negative, Neutral, Positive\n",
      "----------------------------------------\n",
      "        dataset |       negative |        neutral |       positive\n",
      "  dev_predicted |      37.000000 |     334.000000 |      87.000000\n",
      "     dev_actual |      76.000000 |     273.000000 |     109.000000\n",
      "\n",
      "Accuracy\n",
      "--------\n",
      "Accuracy (test data): 0.734\n",
      "\n",
      "Classification Report\n",
      "---------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.38      0.51        76\n",
      "          1       0.74      0.90      0.81       273\n",
      "          2       0.69      0.55      0.61       109\n",
      "\n",
      "avg / total       0.73      0.73      0.72       458\n",
      "\n",
      "\n",
      "Confusion matrix for Dev data\n",
      "-----------------------------\n",
      "The most confused pair of classes is: 2 ( positive )  incorrectly predicted as 1 ( neutral )\n",
      "Number of such confusion occurences: 45\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGkCAYAAAABqz41AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIZEkSZkzIZEkSZn7/0BrF5QgN2w1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1124bca10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation data\n",
    "predicted_labels_LR = model_LR.predict(vocab_dev_tf)\n",
    "\n",
    "print \"Dev dataset with\", len(predicted_labels_LR), \"sentences\"\n",
    "print \"\"\n",
    "\n",
    "print \"Data split - Negative, Neutral, Positive\"\n",
    "print \"----------------------------------------\"\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev_predicted\",count_classes(0,predicted_labels_LR), \n",
    "                                                     count_classes(1,predicted_labels_LR),\n",
    "                                                     count_classes(2,predicted_labels_LR))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev_actual\",count_classes(0,dev_labels), \n",
    "                                                     count_classes(1,dev_labels),\n",
    "                                                     count_classes(2,dev_labels))\n",
    "\n",
    "\n",
    "accuracy = model_LR.score(vocab_dev_tf, dev_labels)\n",
    "print \"\\nAccuracy\"\n",
    "print \"--------\"\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)\n",
    "\n",
    "print \"\\nClassification Report\"\n",
    "print \"---------------------\"\n",
    "print classification_report(dev_labels, predicted_labels_LR)\n",
    "\n",
    "print \"\\nConfusion matrix for Dev data\"\n",
    "print \"-----------------------------\"\n",
    "\n",
    "array = confusion_matrix(dev_labels, predicted_labels_LR)\n",
    "df_cm = pd.DataFrame(array, index = [\"negative\", \"neutral\", \"positive\"],\n",
    "                  columns = [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "# Find the most confused pair\n",
    "cm2 = confusion_matrix(dev_labels, predicted_labels_LR)  # copy the cm matrix so that can modify the copy without affecting original cm\n",
    "np.fill_diagonal(cm2, 0)  # set the values in the diagonal = 0 to obtain number of confused pairs matrix\n",
    "maximum_pair_idx = np.where(cm2 == cm2.max())  # returns the indices of the max value in cm matrix\n",
    "true_interaction = maximum_pair_idx[0][0]\n",
    "predicted_interaction = maximum_pair_idx[1][0]\n",
    "max_wrong_prediction = cm2[true_interaction][predicted_interaction]\n",
    "print \"The most confused pair of classes is:\", true_interaction, \"(\", classes_dict[true_interaction],\")\",\\\n",
    "\" incorrectly predicted as\", predicted_interaction, \"(\", classes_dict[predicted_interaction],\")\"\n",
    "print \"Number of such confusion occurences:\", max_wrong_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 642 sentences\n",
      "\n",
      "Data split - Negative, Neutral, Positive\n",
      "----------------------------------------\n",
      "        dataset |       negative |        neutral |       positive\n",
      " test_predicted |      24.000000 |     548.000000 |      70.000000\n",
      "    test_actual |      95.000000 |     446.000000 |     101.000000\n",
      "\n",
      "Accuracy\n",
      "--------\n",
      "Accuracy (test data): 0.671\n",
      "\n",
      "Classification Report\n",
      "---------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.08      0.13        95\n",
      "          1       0.74      0.91      0.82       446\n",
      "          2       0.24      0.17      0.20       101\n",
      "\n",
      "avg / total       0.60      0.67      0.62       642\n",
      "\n",
      "\n",
      "Confusion matrix for test data\n",
      "------------------------------\n",
      "The most confused pair of classes is: 2 ( positive )  incorrectly predicted as 1 ( neutral )\n",
      "Number of such confusion occurences: 83\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGkCAYAAAABqz41AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm8XPP9+PHX3HuTSGSpxBpBv7V8QtGi1dp3Vb8qbfWL\n2qollhD70liKRlBLrUVJao+tvm1tX61SX0qVoqX0jdLQEiqRPSH3Zn5/zCC23JOYucc59/X0mMed\ne+bMmfd5mMx9z/v9+XxOpVqtIkmSlKeWvAOQJEkyIZEkSbkzIZEkSbkzIZEkSbkzIZEkSblra+bB\nZ0+c4BQeNdSM8ePzDkEl0mvQYnmHoBLqu8Iqla56rTVX2KShf2f/Ov7eLov9/ayQSJKk3DW1QiJJ\nkpqnUun6gkZKaUngEWBLoAO4HJgLPBkRw+v77AMMA+YAp0TEbZ0d1wqJJEnKJKXUBlwMzKxvOhsY\nGRGbAC0ppe1TSksBBwHrAdsAp6aUenR2bBMSSZIKqlJpaegtgzOBi4CXgQqwdkTcV3/sDmArYF3g\n/ohoj4ipwLPAmp0d2IREkiR1KqX0XeC1iPgttWQE3ptHTAP6A/2AKfNsnw4M6Oz4jiGRJElZ7AXM\nTSltBXwOuBJYYp7H+wGTganUEpP3b58vExJJkgqqha4b1FofJwJASuluYD/gjJTSxhHxf8BXgbuB\nh4FTUko9gd7AUODJzo5vQiJJUkHlMcvmfY4ALq0PWn0auCkiqiml84D7qbV2RkbEW50dqFKtNm/t\nMhdGU6O5MJoayYXR1AxduTDaOp/ZsqF/Z//8/F25ZThWSCRJKqiWbDNjCsGERJKkgvoEtGwapjyp\nlSRJKiwTEkmSlDtbNpIkFVSlC6f9NpsVEkmSlDsrJJIkFZSzbCRJUu6cZSNJktRAVkgkSSqoFisk\nkiRJjWNCIkmScmfLRpKkgqqUqK5QnjORJEmFZYVEkqSCKtO0XxMSSZIKylk2kiRJDWSFRJKkgvLi\nepIkSQ1kQiJJknJny0aSpILyar+SJCl3ZZr2W57USpIkFZYVEkmSCqpM65CYkEiSVFBO+5UkSWog\nExJJkpQ7WzaSJBVUmab9ludMJElSYVkhkSSpoMq0DokJiSRJBVWmab+2bCRJUu6skEiSVFCuQyJJ\nktRAJiSSJCl3tmwkSSooZ9lIkqTcOctGkiSpgayQSJJUUGWaZZMpIUkptQLfBVYA7gaejIjXmxiX\nJEnqRrK2bC6hloxsBfQDrmxaRJIkKZOWSktDb7meS8b9VoyIE4BZEXELMKCJMUmSpG4ma0LSllJa\nHCCl1A+Y27yQJElSd5N1UOuxwB+AZYA/Agc3LSJJkpRJd1yHZEpEpJTSEsDrEVFtZlCSJKlz3XEd\nklEppQeAHYA+TYxHkiR1Q5kSkojYDvgm8CngNymly5oalSRJ6lSlwf/laUEWRusB9AJagfbmhCNJ\nkrIqU8sm68Jod1NLRsYAW0TEjKZGJUmSupWsFZKDI+KJpkYiSZK6rfkmJCmlCyLiQOBnKaW3Z9ZU\ngGpErN/06CRJ0kfqTtN+f1T/uQfw1jzbBzYnHEmS1B11lpBUUkqrULt2ze7UqiMt1K5ts26TYyu9\n9vZ2jh91Ki+/MoHW1lZOOOZIPr38cnmHpQLaa+QJLNq7NwCDl1yCb229JWeMuZyePXqw8qdX4NA9\nd8s5QhVJe0cHJ591Li9PeI057e18f5f/Zukll2D0eRfS1trG8kMGc8JhI/IOU3SvQa1fprYqawJ+\nVt82F7izmUF1F/c/+BAdHXO54pIL+ePDj3D+xZdy1uiT8w5LBfPWnDkAXHD8D97Z9r1jf8jhe+3B\nZ1dakUtv/AW/+cMDbL2BXVZlc/vv7uFT/ftz8lGHMW36dHbebwSrrbISw3bbhfW/uA7HnXYW9z30\nMBt96Yt5h9rt5T1Vt5Hmm5BExC+BX6aUto2I27sopm5jheWG0NHRQbVaZfr0GfTosSCzsKWa58a/\nyKw33+SQU3/M3Llz2Xenb/P6pDf47EorArDGyitz358fNSFRZlttvCFbbbQhAB1z59LW1kZacUUm\nT51GtVpl5qxZtLW25hylyibrX8BJKaVLqK1FUgEGR8RXmhdW99CnT2/+/corbL/L7kyZMpXzzzg1\n75BUQL169WLXr23LdpttwkuvTOCw089k8FJL8NjTf2etVYdy/6OPMfvNN/MOUwXSe5FFAJgxcyZH\n/+h0Dqi3/E6/4GLGjruBvov24QufWyPPEFVXppZN1qXjLwJ+DwwAxgOvNyug7uSq625kgy+ty6+v\nu5obrhzDsT8azZx6+V3KavlllmbrDdYDYLlllmZA377st/N/c9WvbuXgU05n4IABDOjXL+coVTQT\nXvsP+x11LF/banO+stnGnHnRpYz5yencdNlP2XaLzTj7kjF5h6iSyZqQvB4R44CpEXEiMKR5IXUf\nA/r3p2/fRQHo17cvHR0ddMydm3NUKppb7/k/zr96HAD/mfQGM2fP5qnn/sGJB+7PuccezeRp01h3\njdVzjlJFMvGNNzhw5A8ZsfdebLf1FgAM6N+PRfvULmW2xKCBTJvu+phqrKwtm7kppc8CfVJKCaf9\nNsSuO+3ID0efzl77H0R7ezsj9hvGIr165R2WCma7zTZm1MWXsf+Jo6hUKozcd2+mTJvGQaNOpfci\nvVh7tVX58ufXzDtMFcjPr7uJadNncNk113PpNddRocJxhx7IMaecTltbGz3a2jju0APzDlOUax2S\nSrVa7XSnejLyWeDfwHnAVRFxTmfPmz1xQucHlxbAjPHj8w5BJdJr0GJ5h6AS6rvCKl2WJXxv/QMa\n+nd27AM/zS3DydqymQb8EXgJ+AZwfUqpR9OikiRJ3UrWhORW4HHgeuBR4CFgfErJ1ZYkScpJpcH/\n5SlrQvICsEpErAesDDwMrA4c1KzAJEnS/LVUKg295XouGfdbKiJeB4iIN+q/T6K2aqskSdLHknWW\nzZ9TSuOAB4H1gMdTSjsBrzYtMkmS1G1kqpBExHBgHLAItRk2B1IbU/KdJsYmSZLmo1KpNPSWp0wV\nkpRSP2pX9x0MPJdSWikioqmRSZKkbiPrGJKxwPPUBrROAFwzWJKknHXHQa2DImIsMCciHliA50mS\nJHUq8/XuU0pD6z+HAO1Ni0iSJGWS97iPRsqakIyg1rZZFbgROKBpEUmSpEy6cjGzlFILcCmQqC37\nsR/Qk9olZdqBN4E9IuI/KaV9gGHAHOCUiLits+Nnbb2sDSwGTAaWBn6xgOchSZKKbTugGhEbAscD\no4GfAMMjYnPgf4CjU0pLUVs4dT1gG+DULJebyZqQHF0PZGj9tuqCnoUkSSquiPgVtaoHwKeBN4Cd\nI+KJ+rY2YDa1Wbn3R0R7REwFngU6veR41pbN8xHx3IIELkmSmquli4eQRMTclNLlwA7AjhHxKkBK\naX1gOLAxtarIlHmeNh0Y0NmxsyYkM1NKd1BbDK1aD2pk1hOQJEnlEBHfTSktCfwppbQq8HXgB8C2\nETExpTQV6D/PU/pRG/IxX1kTktsXNGBJktRcXTnLJqW0GzAkIk6j1prpAL5FrY2zaUS8nXT8CRiV\nUuoJ9KY21OPJzo6fKSGJiCsWInZJktREXbyY2c3Az1NK91LLHw4BLgfGA/+TUqoC90bESSml84D7\ngQowMiLe6uzgmdchkSRJ3VdEzAR2et/mQR+x7xgWcFV3ExJJkgqqTAujuQS8JEnKnQmJJEnKnS0b\nSZIKqqULl45vNhMSSZIKyjEkkiRJDWSFRJKkguridUiayoREkqSCKlE+YstGkiTlz4REkiTlzpaN\nJEkFVaYxJFZIJElS7qyQSJJUUBUXRpMkSXlzYTRJkqQGskIiSVJBlWlQqwmJJEkFVaJ8xJaNJEnK\nnwmJJEnKnQmJJEnKnWNIJEkqKAe1SpKk3JVpYTRbNpIkKXdWSCRJKihbNpIkKXclykds2UiSpPyZ\nkEiSpNzZspEkqaC82q8kSVIDWSGRJKmgnGUjSZJyV6J8xJaNJEnKnxUSSZIKqkwtGyskkiQpdyYk\nkiQpd7ZsJEkqqDJd7deERJKkgnJhNEmSpAayQiJJUkG1lKdAYkIiSVJR2bKRJElqIBMSSZKUO1s2\nkiQVVJlaNk1NSKodc5p5eHVDm33jqLxDUIk8+IexeYcgqc4KiSRJBeUsG0mSlLsytWwc1CpJknJn\nhUSSpIIqUYHECokkScqfCYkkScqdLRtJkgqqpUQ9GyskkiQpd1ZIJEkqqArlqZCYkEiSVFAl6tjY\nspEkSfmzQiJJUkE5qFWSJKmBTEgkSVLubNlIklRQZbq4ngmJJEkFVaJ8xJaNJEnKnxUSSZIKypaN\nJEnKXUt58hFbNpIkKX8mJJIkKXe2bCRJKqgyjSGxQiJJknJnhUSSpIIqUYHEhESSpKIq08X1TEgk\nSVKnUkptwFjg00BP4JSIuKX+2HeAAyNi/frv+wDDgDn1/W7r7PiOIZEkqaAqlUpDb53YDXg9IjYG\nvgpcAJBSWgv43ts7pZSWAg4C1gO2AU5NKfXo7OAmJJIkKYsbgOPr91uAOSmlgcAo4OB59lsXuD8i\n2iNiKvAssGZnB7dlI0mSOhURMwFSSv2AG6klJ2OAw4A359m1PzBlnt+nAwM6O74JiSRJBdXVY1pT\nSssBN1Nr1zwHrARcBPQGVk0pnQ3cQy0peVs/YHJnxzYhkSSpoLpyYbT62JA7geERcU998xr1x1YA\nxkXEYfX9RqWUelJLVIYCT3Z2fMeQSJKkLH4AfAo4PqV0T0rp7pRSr/fvFBGvAucB9wN3ASMj4q3O\nDm6FRJKkgurKlk1EHAIc8hGPjQfWn+f3MdTGl2RmQiJJUkGVaWE0WzaSJCl3JiSSJCl3JiSSJCl3\njiGRJKmgSjSExIREkqSi6sp1SJrNlo0kScqdFRJJkgqqRAUSExJJkorKlo0kSVIDmZBIkqTc2bKR\nJKmgStSxsUIiSZLyZ4VEkqSCKtPF9UxIJEkqqBLlI7ZsJElS/qyQSJJUUK5DIkmS1EDzrZCklFb5\nqMci4pnGhyNJkrqjzlo2l3zE9iqweYNjkSRJC6BEHZv5JyQRsdmHbU8p9WxOOJIkKasyjSHJNKg1\npbQvcBjQA6gAc4CPbOdIkiQtiKyDWocDmwJ3AHsBTzUrIEmSlE2l0thbnrImJC9HxCtAv4j4PTCg\neSFJkqQsKpVKQ295ypqQTEkp7QBU6+2bxZsYkyRJ6mayJiT7AOOBH1AbO3JQ0yKSJEndTtaVWm+K\niK3r9w9vVjCSJCm7vMd9NFLWhOSNlNL2QABzwYXRPq4n/vY0515yGZeddxZ/f/Y5Rhx9HCssNwSA\nb++wHVtvtknOESpPAwd9inG3/Ixhux7G+Bf+9Z7HFlmkFxdffSY/PPL0DzyWxSZbrM+wEXvQ3t7O\nr268g5uvu43W1lZOPuNoBg9Zmh492rj0gqu593cPNOp0VDDtHR2cdMZPeHnCq8xpb+f739mZpZdc\nnIOPPZHlhywLwLe//v/YapONco5UZZI1IVkSOGSe310Y7WO4/Nrrue3Ou+jdpzcAT8ez7L7Tjuy+\n0445R6ZPgtbWVo4bfTizZ83+wGOrrr4Kx48+nCWXXrhhXK2trRxx/HB2/to+vDn7Ta74xYXc85v7\n2Wjz9XjjjSkce9ho+vXvy413jDEh6cZu/+3dfKp/f350zBFMnTaNnYcdyLA9dmW3b3+T3Xb8Rt7h\naR55D0RtpKxjSM6KiM3evgEXNzOoslt+yLKcPfqkd35/Kp7h/gcf4vsHHsZJp53FrFmzcoxOeTv8\n2P254apf8Z/XJn7gsR49e3DIPsfyz3+8+M621tZWTjz9SMZcdw4/v+E81vnS597znN89fPM79z+z\n0gq8+M9/MWP6TNrbO3jskSdY50uf4ze33sOFZ44BoKWlhfb29iadnYpgq0034oC99gBg7twqbW1t\nPP3Ms9z3xz+x96FHcfKZ5zDrQxJmdb0yTfvt7Fo2XwM2AHZJKa1f39wCbA/c0OTYSmvzjTfk5Qmv\nvvP7Gqutyre225ahq6zMZVdey0Vjr+Sw4fvmGKHy8vUdt2HSxMn88f5H2PvA3T7w+F8f/Vvtzjyf\nHN/c+f8xaeJkTjz6DPoP6MflN57HN7feiwsvP51ei/Sif/++XDbuJ7w64XVuvOZXTJ86453nzpw+\nk779+jJ79psA9Fm0N2dddBLnn3FZc09Un2i9F1kEgBkzZ3LUyaMZvtcevDVnDt/YdhuGrrwiY665\nnouvvIZD9/1+zpGqTDpr2fwFGATMojZ+BGpjSK5rZlDdzWYbrU+/vn0B2HzjDTj93Atzjkh52eHb\nX2VutcqXN/oCQ1dbiVPOHsmIvUcyaeLkj3zOykM/w1pfWIM111oNKhVaWlvpP6Afw797NFCrkOy9\ny6G1fdNnWLRfn3ee26dvH6ZNnQbAUssswU8uGcV1V9zMnbfe08SzVBFMeO0/HHHiKHbafju+svkm\nTJs+g359FwVgsw3X44wLLJR/ErTkXdZooM6uZfMScEVK6cqIqHZRTN3OAYcfwzGHHsRnhyb+9OfH\nWC2tnHdIysn3djr4nfuXXXcOP/rBmfNNRgBe+MeLTHj5NcZedC09e/Vk7+G7MXXKtHcer1bf/af7\n/HPjWX6FZenXvy+zZs1mnXXX5PJLxjFw8cW4+KozGX38OTz84GONPzEVysRJbzD86OM4ZsQBfHGt\nWgtw+DHHccxB+7NaWoU/PfYXVl3Fzyk1VtZBrS+nlKrUrmMzEHg+IlZtXljdy7GHH8xp51xAjx49\nGDRwMU448rC8Q9InQT2R+OrXt6B3n0W4+brbPvAYwI3X/JoTT6uNIVm0bx+uv+qX7znMlut+6537\nHR0dnDHqQi6+6kwqlQo3X3cbr782iaNOOJB+/fuy74g92PfgPaFaZf89j2LOW3Oae476RBo77gam\nzZjBpVeP49KrxkEFDt9/GGf+9Ge0tbWx+MDFOO6wEXmHKfIf99FIlXm/PWWRUloBODEi9ups31mv\nvWRVRQ31pS9+cFyFtLAe/MPYvENQCS06ZMUuSxN+e/RFDf07u9Xp++eW4mSdZfOOiBgPDG1CLJIk\nqZvK1LJJKY2jtvYIwGDg1fnsLkmSukCZ1iHJOoZk3uHUs4FHmhCLJElaACXKRzK3bB4FtgL2BJYF\n/qtpEUmSpG4na0IyFngeWBmYAIxpWkSSJCmTSkulobc8ZU1IBkXEWGBORDywAM+TJElNUqal4zMn\nFimlofWfQwAvdCFJkhom66DWEdTaNqsCNwIHNC0iSZLU7WRNSNYGFgMmA0sDvwA+06ygJElS57rj\ntN+jge2Al5oYiyRJ6qayJiTPR8RzTY1EkiQtkBIVSDInJDNTSncAj1NfsTUiRjYtKkmS1Knu2LK5\nvalRSJKkbi1TQhIRVzQ7EEmStGBKVCBxgTNJkpQ/ExJJkpS7rGNIJEnSJ02JejYmJJIkFVSZZtnY\nspEkSbmzQiJJUkGVqEBiQiJJUlFVWsqTkdiykSRJuTMhkSRJubNlI0lSQZVpDIkVEkmSlDsrJJIk\nFZTrkEiSJDWQFRJJkgqqRAUSExJJkorKlo0kSVIDmZBIkqTc2bKRJKmgStSxsUIiSZLyZ4VEkqSC\nKtOgVhMSSZKKKoc+R0rpS8BpEbFZSmkJ4FLgU0ArsEdEvJBS2gcYBswBTomI2zo7ri0bSZKUSUrp\nSGoJSK/6ph8DV0fEpsDxwNCU0lLAQcB6wDbAqSmlHp0d24REkqSCqlQqDb1l8BzwjXl+3wAYklL6\nLfAd4PfAusD9EdEeEVOBZ4E1OzuwCYkkScokIv4HaJ9n06eBSRGxFfAScAzQH5gyzz7TgQGdHduE\nRJIkLayJwC31+7cAX6CWjPSfZ59+wOTODuSgVkmSCuoTMMnmPmBb4BpgY+BJ4GHglJRST6A3MLS+\nfb5MSCRJKqhPwLTfI4DLUkr7U6uMfCcipqSUzgPuByrAyIh4q7MDmZBIkqTMImI8sH79/ovA1h+y\nzxhgzIIc14REkqSCyr9A0jgmJJIkFVWJMhJn2UiSpNyZkEiSpNzZspEkqaAqLbZsJEmSGsYKiSRJ\nBVWiMa0mJJIkFdUnYGG0hrFlI0mScmeFRJKkgipRgcQKiSRJyp8JiSRJyp0tG0mSiqpEPRsrJJIk\nKXdWSCRJKqgyrdRqQiJJUkGVqGNjy0aSJOXPCokkSUVVohKJFRJJkpS7plZIWhfp08zDqxu68/IT\n8g5BJVLp0SPvECTV2bKRJKmgStSxMSGRJKmoyjTt1zEkkiQpd1ZIJEkqqEqJejYmJJIkFVV58hFb\nNpIkKX8mJJIkKXe2bCRJKqgyjSGxQiJJknJnhUSSpIIqU4XEhESSpKIqUZ+jRKciSZKKygqJJEkF\nVaaWjRUSSZKUOxMSSZKUO1s2kiQVVJlaNiYkkiQVVXnyEVs2kiQpf1ZIJEkqqEpLeUokJiSSJBVV\nicaQ2LKRJEm5MyGRJEm5s2UjSVJBlahjY4VEkiTlzwqJJEkFVaaF0ayQSJKk3FkhkSSpqFyHRJIk\n5c2WjSRJUgOZkEiSpNzZspEkqajK07GxQiJJkvJnhUSSpIIq06BWExJJkgqqUqJpv7ZsJElS7qyQ\nSJJUVLZsJElS3so0hsSWjSRJyp0JiSRJyp0tG0mSiqo8HRsrJJIkKX9WSCRJKqgyrUNiQiJJUlE5\ny0aSJKlxrJBIklRQrkMiSZLUQCYkkiQpd7ZsJEkqKmfZSJKkvJVpDIkJiSRJ6lRKqQ24Avg00A7s\nA3QAlwNzgScjYvjCHj9TQpJS6gccDQwGbgX+GhHPLeyLSpKkBujaAsm2QGtEbJBS2hIYDfQARkbE\nfSmli1JK20fErxbm4FkHtY4FngdWBiYAYxbmxSRJUuNUKpWG3jrxDNCWUqoAA4A5wNoRcV/98TuA\nLRf2XLImJIMiYiwwJyIeWIDnSZKkcpgO/Bfwd+AS4DzeW6OZRi1RWSiZE4uU0tD6zyHUekeSJKn7\nOBT434hIwOeAK4Ge8zzeD5i8sAfPmpCMAH4OrA3cBBy+sC8oSZIKaRIwpX5/MrVxqI+llDapb/sq\ncN+HPTGLrLNsVgQ2iIi5C/tCkiSpwbp2HZJzgLEppf+jNpj1GODPwGUppR7A09SKFgsla0KyJTAq\npfRr4LKIeGFhX1CSJDVGV65DEhEzgJ0+5KFNG3H8TC2biDgIWAd4HLgwpXRXI15ckiQJFmxhtHWB\nrwBL8TFKMpIkqUG620qtKaWngL9Qa9fs3dyQJElSFt1x6fiNImJiUyPpxv765N8454KLGHvxBXmH\nogJq7+jgtMuvZMLEibS2tnDEbrvS0TGXs669FoAhSy7JkbvtSkuLywdpwTzx1NOcd8kYLj33TI45\n6RQmTZpMlSovv/Iqa66+KqeeMDLvEFUi801IUko3RcSOwJMppWp9cwWoRsTgpkfXDfz8qmu45fb/\npU/v3nmHooJ66Mm/0VGdywVHHcEjT/+dS3/5a6rVuQzbYQfWWGlFTrviSh746xNs+PnP5R2qCuSK\ncTdw25130bv+2XTaD48FYNq06Qw75EiOPGj/PMNTCc33K1M9GQFYNyIG12/LAJs3P7TuYfkhQzj3\njFPzDkMFNmSpJenomEu1WmXGrFn0aGvl5H2HscZKKzKnvZ1JU6eyqAmvFtByyw7mrFNO/MD2i8Ze\nwc7f2p6Biy3W9UHpg1oqjb3lqLMKyerAssDpKaUjqVVHWoDTgM83P7zy22KzTXj5lVfyDkMF1rtX\nLyZMfJ09TjyJKdNncOrwA6hUKrw6aRKHn3MefXv3ZqUhQ/IOUwWz+cYb8vKEV9+zbdLkyTz86OMc\nOeKAnKJSmXXWVF4M2JnazJrvALsA3wZ+2uS4JGV00+/uZt3VVuOqk05kzHHHcurlVzCnvZ2lBg7k\n6pNPZLuNN+SCG50Yp4/vrt/fxzZbbV6qgZRF18UX12uq+VZI6lfwuy+ltHZEPNpFMXVLVaqd7yR9\niH59+tDW2gpA3z69ae/oYORPL+LgnXdiyJJL0qfXIrTmXIpVcc372fTQI48ybM9dc4xGH1Ci5LCz\nls0FEXEgtcXQ3vMXMyLWb2pk3UyF8ryp1LV23GJzfnzlVYw482zaOzrYZ4ftWXrQIE674ip6trXR\nq2cPjtx9t7zDVEHN+9n04kv/YtnBy+QYjcqsUq1+9DfzlNJSEfFqSmmF9z8WEeM7O/hbUyf6tV8N\nNfHPj+cdgkpkwGor5x2CSqjPUst32TfM1x9+oKF/Zxf/4vq5fTvubJbN2yOaBgCDgaWBscBKTY5L\nkiR1I1lXSroYeBM4DjgW+GHTIpIkSd1O1oRkNvA3oGdE/BHoaF5IkiQpk0qlsbccZV06vgpcCdye\nUvpvYE7zQpIkSVnkPVW3kbJWSHYCroiIc4HXqK1NIkmS1BBZKyRvAZullIYDzwB/bV5IkiQpk25Y\nIRkLvEhtQOs/gcubFI8kScqo0lJp6C1PWSskgyLi/Pr9x1NKO853b0mSpAWQtULSO6W0NED9Z2vz\nQpIkSd1N1grJccAfUkpvAT2BfZoXkiRJyqQbjiHpT60q0gFUyJ7ISJIkdSprQnI8sG5ErA6sB4xq\nXkiSJCmTEi2MljUhmRgRr8E717eZ2ryQJElSFpVKpaG3PGVtvUxLKd0J3AusA/RJKY0GiIiRzQpO\nkiR1D1kTkl/Oc//fzQhEkiQtoJzXDmmkTAlJRFzR7EAkSVL3lXUMiSRJUtM4fVeSpIKqVMpTVyjP\nmUiSpMKyQiJJUlGVaKVWExJJkgoq77VDGsmWjSRJyp0VEkmSiqpE65BYIZEkSbkzIZEkSbmzZSNJ\nUkGVaVCrCYkkSUVVooTElo0kScqdFRJJkoqqREvHm5BIklRQFaf9SpIkNY4JiSRJyp0tG0mSispZ\nNpIkSY1jhUSSpIJyYTRJkpS/Ek37Lc+ZSJKkwrJCIklSQbkOiSRJUgOZkEiSpNzZspEkqaicZSNJ\nkvJWpmm/tmwkSVLurJBIklRUrkMiSZLUOFZIJEkqKtchkSRJahwTEkmSlDtbNpIkFVSZpv2akEiS\nVFTOspHfAXjlAAAEvUlEQVQkSWocKySSJBWULRtJkpQ/WzaSJEmNY0IiSZJyZ8tGkqSCqrhSqyRJ\nUuNYIZEkqaicZSNJkvJWcZaNJElS41ghkSSpqErUsqlUq9W8Y5AkSd2cLRtJkpQ7ExJJkpQ7ExJJ\nkpQ7ExJJkpQ7ExJJkpQ7ExJJkpQ7ExJJkpQ7E5JPoJTSDimlpVNKS6WULsg7HhVXSmm5lNLXFmD/\ne1JKqzQzJhXPvJ9FKaWNUkqr1+/flG9kKhNXav1kOhh4KiKeAQ7MOxgV2ubAUODWvANRcUXEq7z7\nWfQ94DrgyYjYMb+oVDYmJB9DSmlPYFugD/AZ4HTgUeC8+i4Tge9FxLSU0oXAOsCrwH8BXwP6AWdT\nq1QtDuwPDAQ+D1yZUtoduBIYBpwbEZvXX/cW4DhgAHAK0A78A9g3IjqafNrqQlnfY8DawH4RsUv9\nea8Ag4FjgN4ppT8AhwOvAYsBOwKXUnsPDQYujIhLuui0lIP6e2kHap87g4AfAVOBUcAs3n0v9QSu\nByrAIsB+wBRqSchwYBtgrZTSU8CfgNWB+yJitfrrnA/cRe0z6QOfhU0/URWWLZuPr39EbAdsD/wA\n+BlwQD15uAM4OqX0dWBgRHwZ+D4wpP7czwKHRcRWwI+BvSLiduBxYHfgLaAaEU8Averl96WBQRHx\nF2p/UL4REZsBLwPf7ZpTVhfr9D1W32/e60BUI6IKnAZcGxFvV0iujYitgRWBcRGxDfAV4LAuOA/l\nr09EbEnt//nZwCXADvXPkHuB44F1gdeBr1Kriixaf241Ih4F/hc4MiJeqm+bCPwlpbRhSqknsClw\nC7XPpw97n0ofygrJx/d4/edL1L5NrAr8NKUE0AN4llrJ/EGAiHg9pRT15/wbOCGlNBPoT+1byNve\nf8WkMcCewJvAz1NKSwDLADfUX6s38NuGnpk+KbK8x97vo6649fZ771XgkJTSN4Fp9eOo/O4FiIjX\nUkrTgdaImFB/7D7glIg4MqW0MvBral+KRn3Icd7//rqM2heiZYBfR8TclFKW96n0DiskH9/7r074\nd2CP+reCo6n17p8E1gNIKS0GrFzf9zzghIjYC3iCd/+Rz+Xd/zdvb7ueWptnB+Baat9gXgK2r7/W\naODuhp6ZPimyvMdmU2u9kFJagVrrD977Xnr7d6i1bx6IiD2AG/noBEblsg7UBqlSawP2rFddATYB\nnkkpbQq8EhFfodYSHv2+Y3zg8ykifgesBexFLTmBD3+fSh/JCkljVYEDgKtSSm3U/uF+PyKeSylt\nm1K6n9o305nAHOAq4KaU0iTgX9TGkQA8QG3syL71YxIRM1JKjwNtETEDIKV0MHB7SqmFWnVljy46\nT+XnQ99jwAvA5JTSg9T+EDxf3/8JYGRK6VHem9jcApyfUtqZ2ntnTr3c7uW/y22ZlNJd1Cqy+1Eb\nf3ZzSqkDeIN3277XpZT2B1qBk953jIeA01JK/+S975ebgC0i4oX67x/2PpU+UqVa9fOn2VKtZvn5\niLg+pTSQWsVkhYiYk3NokrqJ+qDWFBEj845F+jC2bLrGS8Au9W+vdwBHmYxIkvQuKySSJCl3Vkgk\nSVLuTEgkSVLuTEgkSVLuTEgkSVLuTEgkSVLu/j8vv1hWbrECRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111873350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test data\n",
    "\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "predicted_labels_LR2 = model_LR.predict(vocab_test_tf)\n",
    "print \"Test dataset with\", len(predicted_labels_LR2), \"sentences\"\n",
    "print \"\"\n",
    "\n",
    "print \"Data split - Negative, Neutral, Positive\"\n",
    "print \"----------------------------------------\"\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_predicted\",count_classes(0,predicted_labels_LR2), \n",
    "                                                     count_classes(1,predicted_labels_LR2),\n",
    "                                                     count_classes(2,predicted_labels_LR2))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_actual\",count_classes(0,test_labels), \n",
    "                                                     count_classes(1,test_labels),\n",
    "                                                     count_classes(2,test_labels))\n",
    "\n",
    "accuracy = model_LR.score(vocab_test_tf, test_labels)\n",
    "print \"\\nAccuracy\"\n",
    "print \"--------\"\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)\n",
    "\n",
    "print \"\\nClassification Report\"\n",
    "print \"---------------------\"\n",
    "print classification_report(test_labels, predicted_labels_LR2)\n",
    "\n",
    "\n",
    "print \"\\nConfusion matrix for test data\"\n",
    "print \"------------------------------\"\n",
    "\n",
    "array = confusion_matrix(test_labels, predicted_labels_LR2)\n",
    "df_cm = pd.DataFrame(array, index = [\"negative\", \"neutral\", \"positive\"],\n",
    "                  columns = [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "\n",
    "# Find the most confused pair\n",
    "cm3 = confusion_matrix(test_labels, predicted_labels_LR2)  # copy the cm matrix so that can modify the copy without affecting original cm\n",
    "np.fill_diagonal(cm3, 0)  # set the values in the diagonal = 0 to obtain number of confused pairs matrix\n",
    "maximum_pair_idx = np.where(cm3 == cm3.max())  # returns the indices of the max value in cm matrix\n",
    "true_interaction = maximum_pair_idx[0][0]\n",
    "predicted_interaction = maximum_pair_idx[1][0]\n",
    "max_wrong_prediction = cm3[true_interaction][predicted_interaction]\n",
    "print \"The most confused pair of classes is:\", true_interaction, \"(\", classes_dict[true_interaction],\")\",\\\n",
    "\" incorrectly predicted as\", predicted_interaction, \"(\", classes_dict[predicted_interaction],\")\"\n",
    "print \"Number of such confusion occurences:\", max_wrong_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Words with the highest weights per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 ( negative )\n",
      "1 weight: 6.791 for feature \" induced \"\n",
      "2 weight: 6.338 for feature \" acetylneuraminic \"\n",
      "3 weight: 5.905 for feature \" mug \"\n",
      "4 weight: 5.900 for feature \" that \"\n",
      "5 weight: 5.858 for feature \" mitochondrial \"\n",
      "6 weight: 5.808 for feature \" reversed \"\n",
      "7 weight: 5.263 for feature \" also \"\n",
      "8 weight: 5.099 for feature \" against \"\n",
      "9 weight: 4.714 for feature \" suggest \"\n",
      "10 weight: 4.622 for feature \" reduced \"\n",
      "Class 1 ( neutral )\n",
      "1 weight: 7.774 for feature \" study \"\n",
      "2 weight: 6.490 for feature \" regular \"\n",
      "3 weight: 6.078 for feature \" on \"\n",
      "4 weight: 5.388 for feature \" were \"\n",
      "5 weight: 5.276 for feature \" this \"\n",
      "6 weight: 5.251 for feature \" investigated \"\n",
      "7 weight: 4.468 for feature \" measured \"\n",
      "8 weight: 4.370 for feature \" using \"\n",
      "9 weight: 4.364 for feature \" evaluate \"\n",
      "10 weight: 4.357 for feature \" or \"\n",
      "Class 2 ( positive )\n",
      "1 weight: 6.373 for feature \" monoamine \"\n",
      "2 weight: 6.101 for feature \" inhibitory \"\n",
      "3 weight: 6.057 for feature \" increase \"\n",
      "4 weight: 5.686 for feature \" ace \"\n",
      "5 weight: 5.514 for feature \" antagonism \"\n",
      "6 weight: 5.410 for feature \" increasing \"\n",
      "7 weight: 5.332 for feature \" identified \"\n",
      "8 weight: 5.067 for feature \" which \"\n",
      "9 weight: 4.767 for feature \" inhibits \"\n",
      "10 weight: 4.574 for feature \" type \"\n",
      "\n",
      "Table of weights for each feature for each of the 3 labels:\n",
      "\n",
      "                                negative             neutral            positive\n",
      "             induced               6.791              -2.221              -5.877\n",
      "    acetylneuraminic               6.338              -1.690              -3.401\n",
      "                 mug               5.905              -3.095              -2.250\n",
      "                that               5.900              -7.499               3.681\n",
      "       mitochondrial               5.858              -5.361              -0.080\n",
      "            reversed               5.808              -2.960              -3.103\n",
      "                also               5.263              -2.251              -2.162\n",
      "             against               5.099              -2.847              -3.141\n",
      "             suggest               4.714              -1.179              -3.026\n",
      "             reduced               4.622              -3.685              -0.153\n",
      "               study              -5.921               7.774              -4.525\n",
      "             regular              -1.504               6.490              -5.291\n",
      "                  on              -2.376               6.078              -6.004\n",
      "                were              -4.515               5.388              -2.867\n",
      "                this              -5.870               5.276              -2.275\n",
      "        investigated              -1.984               5.251              -5.487\n",
      "            measured              -2.296               4.468              -2.139\n",
      "               using              -3.065               4.370              -2.630\n",
      "            evaluate              -2.535               4.364              -2.852\n",
      "                  or              -1.919               4.357              -3.662\n",
      "           monoamine              -1.979              -4.164               6.373\n",
      "          inhibitory              -0.728              -6.485               6.101\n",
      "            increase              -2.566              -3.629               6.057\n",
      "                 ace              -3.038              -4.176               5.686\n",
      "          antagonism              -1.374              -3.897               5.514\n",
      "          increasing              -2.011              -3.971               5.410\n",
      "          identified              -1.686              -4.399               5.332\n",
      "               which               1.032              -5.643               5.067\n",
      "            inhibits              -1.318              -3.558               4.767\n",
      "                type              -2.042              -3.174               4.574\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train = vectorizer.fit_transform(train_data)\n",
    "vocab_dev = vectorizer.transform(dev_data)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "model_LR = LogisticRegression(C=50)\n",
    "model_LR.fit(vocab_train, train_labels)\n",
    "predicted_labels_LR = model_LR.predict(vocab_dev)\n",
    "\n",
    "weights = model_LR.coef_   # weight vector for each label\n",
    "top30_features_index = []  # list of 30 features (10 words with the largest weights for each label)\n",
    "class_list = ['negative', 'neutral', 'positive']\n",
    "\n",
    "for i in range(3):  # 4 labels\n",
    "    weights_label_i = list(weights[i])  # list of weights for label i\n",
    "    top10_weights_label_i = sorted(weights_label_i, reverse=True)[0:10]  # sort and filter greatest 10 weights\n",
    "    top10_features_index_i = [weights_label_i.index(weight) \\\n",
    "                             for weight in top10_weights_label_i]  # find index of top 10\n",
    "    top10_features_i = [feature_names[index] for index in top10_features_index_i]  # list of features of top 10 weights\n",
    "    top30_features_index += top10_features_index_i  # add the top 10 weigths index of label i to the list of 30\n",
    "\n",
    "    # Print top 5 features per label\n",
    "    print \"Class\", i, \"(\", class_list[i] , \")\"\n",
    "    for index, (weight, feature) in enumerate(zip(top10_weights_label_i,top10_features_i), start = 1):\n",
    "        print index, \"weight: %.3f\" %(weight), \"for feature \\\"\", feature, \"\\\"\"\n",
    "\n",
    "top30_features = [feature_names[index] for index in top30_features_index]  # list of features of top 20 weights\n",
    "\n",
    "# Formatting weights for each class for printing table of results\n",
    "top30_w_class0 = [\"%.3f\" %(list(weights[0])[index]) for index in top30_features_index]\n",
    "top30_w_class1 = [\"%.3f\" %(list(weights[1])[index]) for index in top30_features_index]\n",
    "top30_w_class2 = [\"%.3f\" %(list(weights[2])[index]) for index in top30_features_index]\n",
    "\n",
    "\n",
    "\n",
    "weights_array = np.column_stack((top30_w_class0, top30_w_class1, top30_w_class2))\n",
    "\n",
    "# Print table of weights for the 20 top features\n",
    "print \"\\nTable of weights for each feature for each of the 3 labels:\\n\"\n",
    "row_format =\"{:>20}\" * (len(class_list) + 1)\n",
    "print row_format.format(\"\", *class_list)\n",
    "for feature, weights in zip(top30_features, weights_array):\n",
    "    print row_format.format(feature, *weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. R-ratio analysis - look at individual sentences with highest errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 sentences where the ratio R is largest:\n",
      "\n",
      "                         ratio R     Max pred Pr      Correct Pr Predicted label      True label       Doc Index\n",
      "       Highest R         526.865           0.955           0.002             1.0             0.0            87.0\n",
      "     2nd highest         526.865           0.955           0.002             1.0             0.0            88.0\n",
      "     3rd highest         260.525           0.908           0.003             1.0             0.0           164.0\n",
      "             4th         253.858           0.668           0.003             1.0             0.0           554.0\n",
      "             5th         205.676           0.741           0.004             1.0             0.0           593.0\n",
      "             6th           176.6           0.982           0.006             1.0             0.0           611.0\n",
      "             7th         175.638           0.991           0.006             1.0             2.0           606.0\n",
      "             8th         170.873           0.803           0.005             1.0             0.0            56.0\n",
      "             9th         170.873           0.803           0.005             1.0             0.0            57.0\n",
      "            10th         170.873           0.803           0.005             1.0             0.0            58.0\n",
      "\n",
      "Sentences:\n",
      "\n",
      "1) Sentence with ratio R = 526.865 :\n",
      "However, while the addition of mevalonate, the product of HMG-CoA-reductase, circumvented the inhibition by lovastatin it had no reversing effect on the inhibition by L-ascorbic acid.\n",
      "\n",
      "2) Sentence with ratio R = 526.865 :\n",
      "However, while the addition of mevalonate, the product of HMG-CoA-reductase, circumvented the inhibition by lovastatin it had no reversing effect on the inhibition by L-ascorbic acid.\n",
      "\n",
      "3) Sentence with ratio R = 260.525 :\n",
      "Nevertheless, lovastatin did inhibit the accumulation of gibberellins in the culture medium; this inhibition, however, was counteracted by the addition of mevalonate to the medium.\n",
      "\n",
      "4) Sentence with ratio R = 253.858 :\n",
      "In animals pretreated with microinjections of isoniazid, 150 micrograms, an inhibitor of activity of the GABA-synthesizing enzyme, L-glutamic acid decarboxylase, into the substantia nigra pars reticulata (SNR), bilaterally, non-convulsant doses of pilocarpine, 100 and 200 mg/kg, resulted in severe motor limbic seizures and status epilepticus.\n",
      "\n",
      "5) Sentence with ratio R = 205.676 :\n",
      "A concurrent increase in plasma 3-O-methyldopa (3-OMD) and a decrease in plasma 3,4-dihydroxyphenylacetic acid (DOPAC) and homovanillic acid (HVA), the three major metabolites of levodopa, suggests an inhibition of the enzyme dopa decarboxylase, probably by isoniazid.\n",
      "\n",
      "6) Sentence with ratio R = 176.600 :\n",
      "The addition of a spermine oxidase inhibitor, isoniazid, or the use of the TCA-purified BSA preparation allowed the direct effects of spermine or seminal plasma on mammalian fertilization to be assessed.\n",
      "\n",
      "7) Sentence with ratio R = 175.638 :\n",
      "In the first experiment, mongrel and ddS mice produced under an unsatisfactory control of proximate environment were purchased, and acute toxicity tests of thiamine hydrochloride (B1HCl) and isonicotinic acid hydrazide (INAH) were practiced at two different conditioned rooms.\n",
      "\n",
      "8) Sentence with ratio R = 170.873 :\n",
      "Consumption of pectin or oat bran together with Lovastatin reduces absorption of the drug, while alcohol intake does not appear to affect the efficacy and safety of Fluvastatin treatment.\n",
      "\n",
      "9) Sentence with ratio R = 170.873 :\n",
      "Consumption of pectin or oat bran together with Lovastatin reduces absorption of the drug, while alcohol intake does not appear to affect the efficacy and safety of Fluvastatin treatment.\n",
      "\n",
      "10) Sentence with ratio R = 170.873 :\n",
      "Consumption of pectin or oat bran together with Lovastatin reduces absorption of the drug, while alcohol intake does not appear to affect the efficacy and safety of Fluvastatin treatment.\"\n",
      "\n",
      "Sentence 1 (example number 87 ):\n",
      "Influential word: no with magnitude: 0.789374577178\n",
      "Influential word: on with magnitude: 0.650550020984\n",
      "Influential word: reductase with magnitude: 0.450485092668\n",
      "Influential word: acid with magnitude: 0.416687894207\n",
      "Influential word: had with magnitude: 0.412207300627\n",
      "\n",
      "Sentence 2 (example number 88 ):\n",
      "Influential word: no with magnitude: 0.789374577178\n",
      "Influential word: on with magnitude: 0.650550020984\n",
      "Influential word: reductase with magnitude: 0.450485092668\n",
      "Influential word: acid with magnitude: 0.416687894207\n",
      "Influential word: had with magnitude: 0.412207300627\n",
      "\n",
      "Sentence 3 (example number 164 ):\n",
      "Influential word: medium with magnitude: 1.25133064675\n",
      "Influential word: this with magnitude: 0.722731963851\n",
      "Influential word: did with magnitude: 0.622550867699\n",
      "Influential word: to with magnitude: 0.34369399199\n",
      "Influential word: was with magnitude: 0.335409027589\n",
      "\n",
      "Sentence 4 (example number 554 ):\n",
      "Influential word: 200 with magnitude: 0.490264416811\n",
      "Influential word: 100 with magnitude: 0.369599868749\n",
      "Influential word: acid with magnitude: 0.329754259199\n",
      "Influential word: mg with magnitude: 0.325217096197\n",
      "Influential word: of with magnitude: 0.317771027794\n",
      "\n",
      "Sentence 5 (example number 593 ):\n",
      "Influential word: acid with magnitude: 0.757703863376\n",
      "Influential word: dopa with magnitude: 0.403684627632\n",
      "Influential word: probably with magnitude: 0.403062038981\n",
      "Influential word: metabolites with magnitude: 0.335826849949\n",
      "Influential word: decarboxylase with magnitude: 0.301267997955\n",
      "\n",
      "Sentence 6 (example number 611 ):\n",
      "Influential word: or with magnitude: 0.903102916945\n",
      "Influential word: direct with magnitude: 0.529896212514\n",
      "Influential word: on with magnitude: 0.517592546704\n",
      "Influential word: assessed with magnitude: 0.470164011354\n",
      "Influential word: use with magnitude: 0.421211110098\n",
      "\n",
      "Sentence 7 (example number 606 ):\n",
      "Influential word: were with magnitude: 1.15568804678\n",
      "Influential word: different with magnitude: 0.668418810403\n",
      "Influential word: hydrochloride with magnitude: 0.644915582761\n",
      "Influential word: two with magnitude: 0.545822789767\n",
      "Influential word: acute with magnitude: 0.540643298955\n",
      "\n",
      "Sentence 8 (example number 56 ):\n",
      "Influential word: affect with magnitude: 0.595577983652\n",
      "Influential word: not with magnitude: 0.530978462316\n",
      "Influential word: or with magnitude: 0.507889004697\n",
      "Influential word: to with magnitude: 0.280339183155\n",
      "Influential word: of with magnitude: 0.269503811636\n",
      "\n",
      "Sentence 9 (example number 57 ):\n",
      "Influential word: affect with magnitude: 0.595577983652\n",
      "Influential word: not with magnitude: 0.530978462316\n",
      "Influential word: or with magnitude: 0.507889004697\n",
      "Influential word: to with magnitude: 0.280339183155\n",
      "Influential word: of with magnitude: 0.269503811636\n",
      "\n",
      "Sentence 10 (example number 58 ):\n",
      "Influential word: affect with magnitude: 0.595577983652\n",
      "Influential word: not with magnitude: 0.530978462316\n",
      "Influential word: or with magnitude: 0.507889004697\n",
      "Influential word: to with magnitude: 0.280339183155\n",
      "Influential word: of with magnitude: 0.269503811636\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Logistic regression model with C=50\n",
    "model_LR = LogisticRegression(C=50)\n",
    "model_LR.fit(vocab_train_tf, train_labels)\n",
    "predicted_labels_LR = model_LR.predict(vocab_test_tf)\n",
    "\n",
    "#feature_names = vectorizer.get_feature_names()\n",
    "#print \"features names length:\", len(feature_names)\n",
    "\n",
    "    \n",
    "# Variables to calculate R\n",
    "probabilities = model_LR.predict_proba(vocab_test_tf)  # Each label probability (4) for each document\n",
    "proba_max = probabilities.max(axis=1)  # Maximum predicted probability\n",
    "proba_correct_label = [probabilities[i][test_labels[i]] \\\n",
    "                       for i in range(probabilities.shape[0])]  # Predicted prob of the correct label\n",
    "r_ratio = proba_max/proba_correct_label  # R = maximum predicted prob / predicted prob of the correct label\n",
    "sentence_index = [i for i in range(probabilities.shape[0])]  # Index of the document to retrace once sorted by R\n",
    "\n",
    "# Results array with 5 columns (R, max prob, prob of correct label, predicted labels, true labels,\n",
    "# document index)\n",
    "results = np.column_stack((r_ratio, proba_max, proba_correct_label, predicted_labels_LR, \\\n",
    "                           test_labels, sentence_index))\n",
    "results_max3r = sorted(results, key=lambda x: x[0], reverse=True)[:10]  # top 10 sentences with highest R\n",
    "\n",
    "\n",
    "# Format and print top 3 documents with highest R:\n",
    "# 1) print top 10 sentences related info - probabilities, predicted/correct labels, etc.\n",
    "print \"\\nTop 10 sentences where the ratio R is largest:\\n\"\n",
    "column_names = [\"ratio R\", \"Max pred Pr\", \"Correct Pr\", \"Predicted label\", \"True label\", \\\n",
    "                \"Doc Index\"]\n",
    "row_format =\"{:>16}\" * (len(column_names)+1)\n",
    "print row_format.format(\"\", *column_names)\n",
    "top_10 = [\"Highest R\", \"2nd highest\", \"3rd highest\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \"10th\"]\n",
    "for index, row in zip(top_10, results_max3r):\n",
    "    row = [round(item,3) for item in row]\n",
    "    print row_format.format(index, *row)\n",
    "\n",
    "# 2) print top 3 R documents messages\n",
    "print \"\\nSentences:\"\n",
    "i = 1\n",
    "for row in results_max3r:\n",
    "    print \"\\n\" + str(i) +\") Sentence with ratio R = %.3f\" %(row[0]), \":\"\n",
    "    print test_data[int(row[5])]\n",
    "    i +=1  \n",
    "\n",
    "\n",
    "# Diagnosis of influential words in the 3 documents with highest R\n",
    "weights = model_LR.coef_\n",
    "sentence_list = [int(result[5]) for result in results_max3r]\n",
    "j=1\n",
    "\n",
    "for example in sentence_list:\n",
    "    predicted_label = predicted_labels_LR[example]\n",
    "    indices = vocab_test_tf[example].indices  # list of indices of non zero features of document\n",
    "    vocab_freq = vocab_test_tf[example].data  # list of features values of document\n",
    "    weights_example = [weights[predicted_label][index] for index in indices]  # list of LR weights \n",
    "                                                                              # for non zero features of doc\n",
    "    feature_importance = vocab_freq * weights_example  # feature value x weight for total influence on prediction\n",
    "\n",
    "    features_array = np.column_stack((feature_importance, indices))\n",
    "    features_sorted = sorted(features_array, key=lambda x: x[0], reverse=True)  # Sort words by influence\n",
    "\n",
    "    # Print top 5 features (words) of the document with heaviest weight x value\n",
    "    \n",
    "    print \"\\nSentence\", j,  \"(example number\", example, \"):\"\n",
    "    for i in range(5):\n",
    "        index = int(features_sorted[i][1])\n",
    "        print \"Influential word:\", feature_names[index] ,\"with magnitude:\", features_sorted[i][0]\n",
    "    j +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def empty_preprocessor(s):\n",
    "    return s\n",
    "\n",
    "def better_preprocessor(s):\n",
    "    #s = s.lower()  # to lowercase all letters in the string\n",
    "    #s = re.sub(\"[^a-zA-Z0-9]\", \" \", s) # to remove non-letter and non-numerical characters\n",
    "    #s = re.sub ('\\d+', \" numsequence \",s)  # replace sequences of numbers with a single token\n",
    "    \n",
    "    pronoun_list = ['you', 'he', 'she', 'we', 'they', 'me', 'him', 'his', 'her', 'hers', 'yours', 'us', 'our'\\\n",
    "                   'ours', 'their', 'theirs']  # list of pronouns as stopwords since not informative for prediciton\n",
    "    for word in pronoun_list:\n",
    "        s = re.sub(r'\\b%s\\b' % word, \" \",s)  # to remove stopwords in the list\n",
    "        \n",
    "    nothelping = ['or', 'to', 'of', 'a', 'on', 'the']\n",
    "    for word in nothelping:\n",
    "        s = re.sub(r'\\b%s\\b' % word, \" \",s)  # to remove stopwords in the list\n",
    "        \n",
    "    #s = re.sub(r'ly\\b', \"\",s)   # to remove \"ly\" from words ending by \"ly\"\n",
    "    s = re.sub(r'ing\\b', \"\",s)  # to remove \"ing\" from words ending by \"ing\"\n",
    "    #s = re.sub(r's\\b', \"\",s)    # to remove \"s\" from words ending by \"s\"\n",
    "    \n",
    "    for word in s.split():  # to shorten words longer than 15 characters (from histogram, most words < 15)\n",
    "        if len(word)>15:\n",
    "            short_word = word[:15]\n",
    "            s = s.replace(word,short_word)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary with no preprocessor: 7898\n",
      "accuracy with no custom preprocessor is: 0.671\n",
      "\n",
      "Size of vocabulary with custom preprocessor: 8403\n",
      "accuracy with custom preprocessor is: 0.681\n"
     ]
    }
   ],
   "source": [
    "# No preprocessor\n",
    "vectorizer_initial = TfidfVectorizer()\n",
    "vocab_train_initial = vectorizer_initial.fit_transform(train_data)\n",
    "vocab_test_initial = vectorizer_initial.transform(test_data)\n",
    "count_features_init = len(vectorizer_initial.get_feature_names())\n",
    "print \"Size of vocabulary with no preprocessor:\", count_features_init\n",
    "\n",
    "model_LR_initial = LogisticRegression(C=50)\n",
    "model_LR_initial.fit(vocab_train_initial, train_labels)\n",
    "predicted_labels_initial = model_LR_initial.predict(vocab_test_initial)\n",
    "accuracy_initial = model_LR_initial.score(vocab_test_initial, test_labels)\n",
    "print \"accuracy with no custom preprocessor is: %.3f\" %(accuracy_initial)\n",
    "print \"\"\n",
    "\n",
    "\n",
    "# With preprocessor\n",
    "vectorizer_better = TfidfVectorizer(preprocessor=better_preprocessor)\n",
    "vocab_train_better = vectorizer_better.fit_transform(train_data)\n",
    "vocab_test_better = vectorizer_better.transform(test_data)\n",
    "\n",
    "count_features_better = len(vectorizer_better.get_feature_names())\n",
    "print \"Size of vocabulary with custom preprocessor:\", count_features_better\n",
    "\n",
    "model_LR_better = LogisticRegression(C=50)\n",
    "model_LR_better.fit(vocab_train_better, train_labels)\n",
    "predicted_labels_better = model_LR_better.predict(vocab_test_better)\n",
    "accuracy_better = model_LR_better.score(vocab_test_better, test_labels)\n",
    "print \"accuracy with custom preprocessor is: %.3f\" %(accuracy_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. N-grams instead of unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (dev data): 0.653\n",
      "Accuracy (test data): 0.693\n"
     ]
    }
   ],
   "source": [
    "# Turn the raw training text into feature vectors based on \"td-idf\"\n",
    "vectorizer = TfidfVectorizer(analyzer='word' , ngram_range=(4,5), preprocessor=better_preprocessor)\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_dev_tf = vectorizer.transform(dev_data)\n",
    "\n",
    "# Logistic regression model with C=50\n",
    "model_LR = LogisticRegression(C=50)\n",
    "model_LR.fit(vocab_train_tf, train_labels)\n",
    "predicted_labels_LR_ngram = model_LR.predict(vocab_dev_tf)\n",
    "\n",
    "accuracy = model_LR.score(vocab_dev_tf, dev_labels)\n",
    "print \"Accuracy (dev data): %.3f\" %(accuracy)\n",
    "\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "predicted_labels_LR_ngram2 = model_LR.predict(vocab_test_tf)\n",
    "accuracy = model_LR.score(vocab_test_tf, test_labels)\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_dev_tf = vectorizer.transform(dev_data)\n",
    "vocab_test_tf = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Support Vector Machine model ...\n",
      "Performing grid search for Support Vector Machine model. It may take a few minutes ...\n",
      "Support Vector Machines grid search model fitting time = 9.621734 seconds.\n",
      "As per the grid search on the training data, the optimal value of C = 0.000100.\n",
      "Support Vector Machines prediction time for dev data = 0.093828 seconds.\n",
      "Accuracy on dev data for Support Vector Machine is = 0.596070\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        76\n",
      "          1       0.60      1.00      0.75       273\n",
      "          2       0.00      0.00      0.00       109\n",
      "\n",
      "avg / total       0.36      0.60      0.45       458\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Support Vector Machines:\n",
    "print \"Evaluating Support Vector Machine model ...\"\n",
    "\n",
    "# Create a Support Vector Machine model. \n",
    "SVMmodel = SVC(C=1.0)\n",
    "\n",
    "# Create a grid search.\n",
    "print \"Performing grid search for Support Vector Machine model. It may take a few minutes ...\"\n",
    "Cs = {'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0]}\n",
    "CV_SVMmodel = GridSearchCV(estimator=SVMmodel, param_grid=Cs)\n",
    "\n",
    "# Fit the models using grid search and display the results.\n",
    "start_time = time.time()\n",
    "CV_SVMmodel.fit(vocab_train_tf, train_labels)\n",
    "end_time = time.time()\n",
    "print \"Support Vector Machines grid search model fitting time = %f seconds.\" % (end_time - start_time)\n",
    "\n",
    "optimal_Cs = CV_SVMmodel.best_params_['C']\n",
    "print \"As per the grid search on the training data, the optimal value of C = %f.\" % optimal_Cs\n",
    "\n",
    "# Predict labels for dev data and calculate accuracy using optimal C\n",
    "start_time = time.time()\n",
    "SVMmodel = CV_SVMmodel.predict(vocab_dev_tf)\n",
    "end_time = time.time()\n",
    "print \"Support Vector Machines prediction time for dev data = %f seconds.\" % (end_time - start_time)\n",
    "\n",
    "# Print goodness of fit measures\n",
    "print \"Accuracy on dev data for Support Vector Machine is = %f\" % CV_SVMmodel.score(vocab_dev_tf, dev_labels)\n",
    "print \"Classification Report\\n\", classification_report(dev_labels, SVMmodel)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model\n",
      "Accuracy (dev data): 0.596\n",
      "Test dataset with 642 sentences\n",
      "Accuracy (test data): 0.695\n",
      "        dataset |       negative |        neutral |       positive\n",
      " test_predicted |       0.000000 |     642.000000 |       0.000000\n",
      "    test_actual |      95.000000 |     446.000000 |     101.000000\n",
      "Confusion matrix for test data\n",
      "The most confused pair of classes is: 2 ( positive )  incorrectly predicted as 1 ( neutral )\n",
      "Number of such confusion occurences: 101\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGkCAYAAAABqz41AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npML9fwx7icn7MAl+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115e028d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Turn the raw training text into feature vectors based on \"td-idf\"\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "#vocab_dev_tf = vectorizer.transform(dev_data)\n",
    "\n",
    "# SVM model\n",
    "model_SVM = SVC(C=0.0001)\n",
    "model_SVM.fit(vocab_train_tf, train_labels)\n",
    "predicted_labels_SVM = model_SVM.predict(vocab_dev_tf)\n",
    "\n",
    "# DEV\n",
    "print \"SVM model\"\n",
    "accuracy = model_SVM.score(vocab_dev_tf, dev_labels)\n",
    "print \"Accuracy (dev data): %.3f\" %(accuracy)\n",
    "\n",
    "# TEST\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "predicted_labels_SVM2 = model_SVM.predict(vocab_test_tf)\n",
    "print \"Test dataset with\", len(predicted_labels_SVM2), \"sentences\"\n",
    "accuracy = model_SVM.score(vocab_test_tf, test_labels)\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)\n",
    "\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_predicted\",count_classes(0,predicted_labels_SVM2), \n",
    "                                                     count_classes(1,predicted_labels_SVM2),\n",
    "                                                     count_classes(2,predicted_labels_SVM2))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_actual\",count_classes(0,test_labels), \n",
    "                                                     count_classes(1,test_labels),\n",
    "                                                     count_classes(2,test_labels))\n",
    "\n",
    "print \"Confusion matrix for test data\"\n",
    "\n",
    "array = confusion_matrix(test_labels, predicted_labels_SVM2)\n",
    "df_cm = pd.DataFrame(array, index = [\"negative\", \"neutral\", \"positive\"],\n",
    "                  columns = [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "\n",
    "# Find the most confused pair\n",
    "cm3 = confusion_matrix(test_labels, predicted_labels_SVM2)  # copy the cm matrix so that can modify the copy without affecting original cm\n",
    "np.fill_diagonal(cm3, 0)  # set the values in the diagonal = 0 to obtain number of confused pairs matrix\n",
    "maximum_pair_idx = np.where(cm3 == cm3.max())  # returns the indices of the max value in cm matrix\n",
    "true_interaction = maximum_pair_idx[0][0]\n",
    "predicted_interaction = maximum_pair_idx[1][0]\n",
    "max_wrong_prediction = cm3[true_interaction][predicted_interaction]\n",
    "print \"The most confused pair of classes is:\", true_interaction, \"(\", classes_dict[true_interaction],\")\",\\\n",
    "\" incorrectly predicted as\", predicted_interaction, \"(\", classes_dict[predicted_interaction],\")\"\n",
    "print \"Number of such confusion occurences:\", max_wrong_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
