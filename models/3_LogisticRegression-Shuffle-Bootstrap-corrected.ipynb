{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import time\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_alpha</th>\n",
       "      <th>Label_num</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Food</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>pentadecanoic acid</td>\n",
       "      <td>(123)iodine labelled beta-methyl-iodophenyl pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>2-phenylethanol</td>\n",
       "      <td>2-Phenylethanol is a widely used aroma compoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>3,4-dihydroxyphenylacetic acid</td>\n",
       "      <td>3,4-dihydroxyphenylacetic acid and 4-methylcat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>arachin</td>\n",
       "      <td>A 96-well microplate format of this method was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>diethylamine</td>\n",
       "      <td>A biochemical study was performed in order to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label_alpha  Label_num           Drug                            Food  \\\n",
       "ID                                                                          \n",
       "400     neutral          1  ACE inhibitor              pentadecanoic acid   \n",
       "333    positive          2  ACE inhibitor                 2-phenylethanol   \n",
       "77     positive          2  ACE inhibitor  3,4-dihydroxyphenylacetic acid   \n",
       "338     neutral          1  ACE inhibitor                         arachin   \n",
       "214     neutral          1  ACE inhibitor                    diethylamine   \n",
       "\n",
       "                                              sentence  \n",
       "ID                                                      \n",
       "400  (123)iodine labelled beta-methyl-iodophenyl pe...  \n",
       "333  2-Phenylethanol is a widely used aroma compoun...  \n",
       "77   3,4-dihydroxyphenylacetic acid and 4-methylcat...  \n",
       "338  A 96-well microplate format of this method was...  \n",
       "214  A biochemical study was performed in order to ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../labeled_dataAll.csv\", index_col='ID')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split 75/25 for training/testing\n",
    "\n",
    "# Randomly shuffle the data. Use same random seed to get same results every time. \n",
    "df_shuffle = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "n = len(df_shuffle.Drug)\n",
    "\n",
    "\n",
    "# Split the train data into training and dev datasets\n",
    "df_train =  df_shuffle[:3*n/4]\n",
    "df_test = df_shuffle[3*n/4:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1853\n",
      "618\n"
     ]
    }
   ],
   "source": [
    "print len(df_train)\n",
    "print len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACE inhibitor' 'Antacid' 'GLP-1' 'Thyroxine' 'Statin' 'Acetaminophen'\n",
      " 'Digoxin' 'Isoniazid' 'Antihistamine' 'MOAI' 'Analgesics'\n",
      " 'Bronchodialators']\n"
     ]
    }
   ],
   "source": [
    "drugs = df.Drug.unique()\n",
    "print drugs\n",
    "add_dict = {}\n",
    "\n",
    "for drug in drugs:\n",
    "    \n",
    "    count_list = []\n",
    "    for i in range(3):\n",
    "        count = len(df_train[(df_train.Drug == drug) & (df_train.Label_num == i)])\n",
    "        count_list.append(count)\n",
    "        \n",
    "    max_count = max(count_list)\n",
    "    add_list = [max(0,max_count-c) for c in count_list]\n",
    "    add_dict[drug] = add_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GLP-1': [86, 0, 39], 'Thyroxine': [48, 0, 63], 'MOAI': [26, 0, 0], 'Antihistamine': [16, 0, 6], 'Analgesics': [7, 2, 0], 'Digoxin': [86, 0, 97], 'Isoniazid': [28, 0, 34], 'Acetaminophen': [255, 0, 326], 'Statin': [149, 0, 128], 'Antacid': [20, 0, 14], 'Bronchodialators': [10, 0, 0], 'ACE inhibitor': [208, 0, 81]}\n"
     ]
    }
   ],
   "source": [
    "print add_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1853\n"
     ]
    }
   ],
   "source": [
    "n_train_original = len(df_train)\n",
    "print n_train_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3582\n"
     ]
    }
   ],
   "source": [
    "for drug in drugs:\n",
    "    for i in range(3):\n",
    "        temp = df_train[(df_train.Drug == drug) & (df_train.Label_num == i)].sample(add_dict[drug][i], replace=True)\n",
    "        df_train = df_train.append(temp)\n",
    "\n",
    "print len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3582\n"
     ]
    }
   ],
   "source": [
    "print sum([j for i in add_dict.values() for j in i]) + n_train_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle the data. Use same random seed to get same results every time. \n",
    "df_shuffle = df_train.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "# Separate labels\n",
    "labels = [i for i in df_shuffle.Label_num]\n",
    "labels = np.array(labels)\n",
    "n = len(labels)\n",
    "\n",
    "labels2 = [i for i in df_test.Label_num]\n",
    "labels2 = np.array(labels2)\n",
    "\n",
    "\n",
    "# Drop unecessary columns from input data\n",
    "df_shuffle.drop('Label_alpha', axis=1, inplace=True)\n",
    "df_shuffle.drop('Label_num', axis=1, inplace=True)\n",
    "df_shuffle.drop('Drug', axis=1, inplace=True)\n",
    "df_shuffle.drop('Food', axis=1, inplace=True)\n",
    "\n",
    "df_test.drop('Label_alpha', axis=1, inplace=True)\n",
    "df_test.drop('Label_num', axis=1, inplace=True)\n",
    "df_test.drop('Drug', axis=1, inplace=True)\n",
    "df_test.drop('Food', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Split the train data into training and dev datasets\n",
    "train_data =  df_shuffle[:3*n/4].sentence.tolist()\n",
    "dev_data = df_shuffle[3*n/4:].sentence.tolist()\n",
    "test_data = df_test.sentence.tolist()\n",
    "\n",
    "# Separate training and dev labels\n",
    "train_labels =  labels[:3*n/4]\n",
    "dev_labels = labels[3*n/4:]\n",
    "test_labels = labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training label shape: (2686,)\n",
      "test label shape: (618,)\n",
      "dev label shape: (896,)\n"
     ]
    }
   ],
   "source": [
    "print 'training label shape:', train_labels.shape\n",
    "print 'test label shape:', test_labels.shape\n",
    "print 'dev label shape:', dev_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['negative', 'neutral', 'positive'] # corresponding labels = 0, 1, 2\n",
    "classes_dict = {0:'negative', 1:'neutral', 2:'positive'} # corresponding labels = 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_classes(value, labels):\n",
    "    return len([i for i in labels if i == value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split among Negative, Neutral and Positive\n",
      "        dataset |       negative |        neutral |       positive\n",
      "          train |     885.000000 |     898.000000 |     903.000000\n",
      "            dev |     309.000000 |     296.000000 |     291.000000\n",
      "           test |     104.000000 |     389.000000 |     125.000000\n"
     ]
    }
   ],
   "source": [
    "# Check number of classes per train/dev/test dataset:\n",
    "print \"Dataset split among Negative, Neutral and Positive\"\n",
    "\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"train\",count_classes(0,train_labels), \n",
    "                                                     count_classes(1,train_labels),\n",
    "                                                     count_classes(2,train_labels))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev\",count_classes(0,dev_labels), \n",
    "                                                     count_classes(1,dev_labels),\n",
    "                                                     count_classes(2,dev_labels))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test\",count_classes(0,test_labels), \n",
    "                                                     count_classes(1,test_labels),\n",
    "                                                     count_classes(2,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example 1\n",
      "Label 1 ( neutral )\n",
      "Sentence:\n",
      "Pharmaceutical compounds evaluated were nonsteroidal anti-inflammatory drugs (acetaminophen, diclofenac, ibuprofen, ketoprofen, naproxen and salicylic acid), antibiotics (sulfamethoxazole and trimethoprim), an anti-epileptic drug (carbamazepine), a beta-blocker (propranolol), a nervous stimulant (caffeine), estrogens (17alpha-ethinylestradiol, 17beta-estradiol, estriol and estrone) and lipid regulators (clofibric acid, metabolite of clofibrate and gemfibrozil). \n",
      "\n",
      "\n",
      "Training example 2\n",
      "Label 1 ( neutral )\n",
      "Sentence:\n",
      "Rice, parboiled rice, finger millet, germinated finger millet, broken wheat, njavara (medicinal rice), sorghum and maize were used as substrates for solid state fermentation of Monascus purpureus at 28C for 7 days using 2% seed medium as inoculum for the production of its metabolites. \n",
      "\n",
      "\n",
      "Training example 3\n",
      "Label 0 ( negative )\n",
      "Sentence:\n",
      "Treatment with 200 M L-DOPA significantly increased death-related signaling proteins, while combined treatment with 5 M statins reduced the levels of these proteins. \n",
      "\n",
      "\n",
      "Training example 4\n",
      "Label 0 ( negative )\n",
      "Sentence:\n",
      "The risk reduction associated with the daily consumption of most statins, with the exception of pravastatin, is more powerful than the risk increase caused by the daily extra fat intake associated with a 7-oz hamburger (Quarter Pounder) with cheese and a small milkshake. \n",
      "\n",
      "\n",
      "Training example 5\n",
      "Label 0 ( negative )\n",
      "Sentence:\n",
      "The extensive modification of carbohydrate metabolism produced by lysophosphatidylserine in mice was largely prevented by the antihistaminic drug, pyrilamine.\\ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check few sentences\n",
    "\n",
    "def print_examples(num_examples=5):\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        print \"Training example\", i+1\n",
    "        print \"Label\", train_labels[i], \"(\", classes_dict[train_labels[i]],\")\"\n",
    "        print \"Sentence:\\n\", train_data[i], \"\\n\\n\"\n",
    "       \n",
    "    \n",
    "print_examples(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn the raw training text into feature vectors based on \"td-idf\"\n",
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_dev_tf = vectorizer.transform(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression model ...\n",
      "Performing grid search for Logistic Regression model. It may take a few minutes ...\n",
      "Logistic Regression grid search model fitting time = 0.915961 seconds.\n",
      "As per the grid search on the training data, the optimal value of C = 10.000000.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "# Logistic Regression:\n",
    "print \"Evaluating Logistic Regression model ...\"\n",
    "\n",
    "# Create a Logistic Regression model. \n",
    "LRmodel = LogisticRegression(C=1.0)\n",
    "\n",
    "# Create a grid search.\n",
    "print \"Performing grid search for Logistic Regression model. It may take a few minutes ...\"\n",
    "Cs = {'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0]}\n",
    "CV_LRmodel = GridSearchCV(estimator=LRmodel, param_grid=Cs)\n",
    "\n",
    "# Fit the models using grid search and display the results.\n",
    "start_time = time.time()\n",
    "CV_LRmodel.fit(vocab_train_tf, train_labels)\n",
    "end_time = time.time()\n",
    "print \"Logistic Regression grid search model fitting time = %f seconds.\" % (end_time - start_time)\n",
    "\n",
    "optimal_Cs = CV_LRmodel.best_params_['C']\n",
    "print \"As per the grid search on the training data, the optimal value of C = %f.\" % optimal_Cs\n",
    "\n",
    "# Construct model with optimal C\n",
    "model_LR = LogisticRegression(C=optimal_Cs)\n",
    "model_LR.fit(vocab_train_tf, train_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev dataset with 896 sentences\n",
      "\n",
      "Data split - Negative, Neutral, Positive\n",
      "----------------------------------------\n",
      "        dataset |       negative |        neutral |       positive\n",
      "  dev_predicted |     324.000000 |     291.000000 |     281.000000\n",
      "     dev_actual |     309.000000 |     296.000000 |     291.000000\n",
      "\n",
      "Accuracy\n",
      "--------\n",
      "Accuracy (test data): 0.900\n",
      "\n",
      "Classification Report\n",
      "---------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       309\n",
      "          1       0.87      0.86      0.87       296\n",
      "          2       0.88      0.85      0.87       291\n",
      "\n",
      "avg / total       0.90      0.90      0.90       896\n",
      "\n",
      "\n",
      "Confusion matrix for Dev data\n",
      "-----------------------------\n",
      "The most confused pair of classes is: 2 ( positive )  incorrectly predicted as 1 ( neutral )\n",
      "Number of such confusion occurences: 35\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGkCAYAAAABqz41AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6RKoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111b34910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation data\n",
    "predicted_labels_LR = model_LR.predict(vocab_dev_tf)\n",
    "\n",
    "print \"Dev dataset with\", len(predicted_labels_LR), \"sentences\"\n",
    "print \"\"\n",
    "\n",
    "print \"Data split - Negative, Neutral, Positive\"\n",
    "print \"----------------------------------------\"\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev_predicted\",count_classes(0,predicted_labels_LR), \n",
    "                                                     count_classes(1,predicted_labels_LR),\n",
    "                                                     count_classes(2,predicted_labels_LR))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev_actual\",count_classes(0,dev_labels), \n",
    "                                                     count_classes(1,dev_labels),\n",
    "                                                     count_classes(2,dev_labels))\n",
    "\n",
    "\n",
    "accuracy = model_LR.score(vocab_dev_tf, dev_labels)\n",
    "print \"\\nAccuracy\"\n",
    "print \"--------\"\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)\n",
    "\n",
    "print \"\\nClassification Report\"\n",
    "print \"---------------------\"\n",
    "print classification_report(dev_labels, predicted_labels_LR)\n",
    "\n",
    "print \"\\nConfusion matrix for Dev data\"\n",
    "print \"-----------------------------\"\n",
    "\n",
    "array = confusion_matrix(dev_labels, predicted_labels_LR)\n",
    "df_cm = pd.DataFrame(array, index = [\"negative\", \"neutral\", \"positive\"],\n",
    "                  columns = [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "# Find the most confused pair\n",
    "cm2 = confusion_matrix(dev_labels, predicted_labels_LR)  # copy the cm matrix so that can modify the copy without affecting original cm\n",
    "np.fill_diagonal(cm2, 0)  # set the values in the diagonal = 0 to obtain number of confused pairs matrix\n",
    "maximum_pair_idx = np.where(cm2 == cm2.max())  # returns the indices of the max value in cm matrix\n",
    "true_interaction = maximum_pair_idx[0][0]\n",
    "predicted_interaction = maximum_pair_idx[1][0]\n",
    "max_wrong_prediction = cm2[true_interaction][predicted_interaction]\n",
    "print \"The most confused pair of classes is:\", true_interaction, \"(\", classes_dict[true_interaction],\")\",\\\n",
    "\" incorrectly predicted as\", predicted_interaction, \"(\", classes_dict[predicted_interaction],\")\"\n",
    "print \"Number of such confusion occurences:\", max_wrong_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 618 sentences\n",
      "\n",
      "Data split - Negative, Neutral, Positive\n",
      "----------------------------------------\n",
      "        dataset |       negative |        neutral |       positive\n",
      " test_predicted |      92.000000 |     402.000000 |     124.000000\n",
      "    test_actual |     104.000000 |     389.000000 |     125.000000\n",
      "\n",
      "Accuracy\n",
      "--------\n",
      "Accuracy (test data): 0.728\n",
      "\n",
      "Classification Report\n",
      "---------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.52      0.55       104\n",
      "          1       0.82      0.84      0.83       389\n",
      "          2       0.55      0.54      0.55       125\n",
      "\n",
      "avg / total       0.72      0.73      0.73       618\n",
      "\n",
      "\n",
      "Confusion matrix for test data\n",
      "------------------------------\n",
      "The most confused pair of classes is: 2 ( positive )  incorrectly predicted as 1 ( neutral )\n",
      "Number of such confusion occurences: 45\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGkCAYAAAABqz41AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1156d2190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test data\n",
    "\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "predicted_labels_LR2 = model_LR.predict(vocab_test_tf)\n",
    "print \"Test dataset with\", len(predicted_labels_LR2), \"sentences\"\n",
    "print \"\"\n",
    "\n",
    "print \"Data split - Negative, Neutral, Positive\"\n",
    "print \"----------------------------------------\"\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_predicted\",count_classes(0,predicted_labels_LR2), \n",
    "                                                     count_classes(1,predicted_labels_LR2),\n",
    "                                                     count_classes(2,predicted_labels_LR2))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_actual\",count_classes(0,test_labels), \n",
    "                                                     count_classes(1,test_labels),\n",
    "                                                     count_classes(2,test_labels))\n",
    "\n",
    "accuracy = model_LR.score(vocab_test_tf, test_labels)\n",
    "print \"\\nAccuracy\"\n",
    "print \"--------\"\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)\n",
    "\n",
    "print \"\\nClassification Report\"\n",
    "print \"---------------------\"\n",
    "print classification_report(test_labels, predicted_labels_LR2)\n",
    "\n",
    "\n",
    "print \"\\nConfusion matrix for test data\"\n",
    "print \"------------------------------\"\n",
    "\n",
    "array = confusion_matrix(test_labels, predicted_labels_LR2)\n",
    "df_cm = pd.DataFrame(array, index = [\"negative\", \"neutral\", \"positive\"],\n",
    "                  columns = [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "\n",
    "# Find the most confused pair\n",
    "cm3 = confusion_matrix(test_labels, predicted_labels_LR2)  # copy the cm matrix so that can modify the copy without affecting original cm\n",
    "np.fill_diagonal(cm3, 0)  # set the values in the diagonal = 0 to obtain number of confused pairs matrix\n",
    "maximum_pair_idx = np.where(cm3 == cm3.max())  # returns the indices of the max value in cm matrix\n",
    "true_interaction = maximum_pair_idx[0][0]\n",
    "predicted_interaction = maximum_pair_idx[1][0]\n",
    "max_wrong_prediction = cm3[true_interaction][predicted_interaction]\n",
    "print \"The most confused pair of classes is:\", true_interaction, \"(\", classes_dict[true_interaction],\")\",\\\n",
    "\" incorrectly predicted as\", predicted_interaction, \"(\", classes_dict[predicted_interaction],\")\"\n",
    "print \"Number of such confusion occurences:\", max_wrong_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Words with the highest weights per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 ( negative )\n",
      "1 weight: 7.902 for feature \" induced \"\n",
      "2 weight: 5.251 for feature \" acetylneuraminic \"\n",
      "3 weight: 5.156 for feature \" inhibited \"\n",
      "4 weight: 4.964 for feature \" stimulated \"\n",
      "5 weight: 4.323 for feature \" hepatotoxicity \"\n",
      "6 weight: 4.152 for feature \" treatment \"\n",
      "7 weight: 3.928 for feature \" breads \"\n",
      "8 weight: 3.918 for feature \" protect \"\n",
      "9 weight: 3.894 for feature \" consumption \"\n",
      "10 weight: 3.845 for feature \" reduced \"\n",
      "Class 1 ( neutral )\n",
      "1 weight: 7.056 for feature \" study \"\n",
      "2 weight: 4.796 for feature \" were \"\n",
      "3 weight: 4.752 for feature \" on \"\n",
      "4 weight: 3.806 for feature \" mouse \"\n",
      "5 weight: 3.759 for feature \" studied \"\n",
      "6 weight: 3.751 for feature \" investigated \"\n",
      "7 weight: 3.714 for feature \" not \"\n",
      "8 weight: 3.683 for feature \" evaluated \"\n",
      "9 weight: 3.350 for feature \" no \"\n",
      "10 weight: 3.043 for feature \" sodium \"\n",
      "Class 2 ( positive )\n",
      "1 weight: 6.027 for feature \" enhanced \"\n",
      "2 weight: 5.169 for feature \" inhibitory \"\n",
      "3 weight: 4.559 for feature \" red \"\n",
      "4 weight: 4.419 for feature \" increased \"\n",
      "5 weight: 4.300 for feature \" showed \"\n",
      "6 weight: 4.103 for feature \" increasing \"\n",
      "7 weight: 4.044 for feature \" their \"\n",
      "8 weight: 4.004 for feature \" which \"\n",
      "9 weight: 4.004 for feature \" lovastatin \"\n",
      "10 weight: 3.946 for feature \" secretion \"\n",
      "\n",
      "Table of weights for each feature for each of the 3 labels:\n",
      "\n",
      "                                negative             neutral            positive\n",
      "             induced               7.902              -3.329              -5.840\n",
      "    acetylneuraminic               5.251              -2.005              -3.804\n",
      "           inhibited               5.156              -4.337              -0.924\n",
      "          stimulated               4.964              -4.279              -0.890\n",
      "      hepatotoxicity               4.323              -2.590              -2.729\n",
      "           treatment               4.152              -2.179              -2.233\n",
      "              breads               3.928              -1.996              -2.156\n",
      "             protect               3.918              -2.801              -1.194\n",
      "         consumption               3.894              -2.500              -1.756\n",
      "             reduced               3.845              -3.382              -0.244\n",
      "               study              -5.125               7.056              -3.660\n",
      "                were              -4.001               4.796              -1.914\n",
      "                  on              -1.981               4.752              -3.711\n",
      "               mouse              -1.253               3.806              -2.255\n",
      "             studied              -1.406               3.759              -2.345\n",
      "        investigated              -1.184               3.751              -3.684\n",
      "                 not              -1.395               3.714              -2.016\n",
      "           evaluated              -0.976               3.683              -3.154\n",
      "                  no               0.217               3.350              -3.515\n",
      "              sodium               0.222               3.043              -3.801\n",
      "            enhanced              -1.594              -4.743               6.027\n",
      "          inhibitory              -0.714              -5.187               5.169\n",
      "                 red              -0.406              -4.098               4.559\n",
      "           increased               1.570              -5.581               4.419\n",
      "              showed               1.012              -5.883               4.300\n",
      "          increasing              -1.847              -2.428               4.103\n",
      "               their              -2.139              -1.818               4.044\n",
      "               which              -0.717              -3.378               4.004\n",
      "          lovastatin              -0.987              -3.379               4.004\n",
      "           secretion              -2.261              -1.422               3.946\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train = vectorizer.fit_transform(train_data)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "model_LR = LogisticRegression(C=optimal_Cs)\n",
    "model_LR.fit(vocab_train, train_labels)\n",
    "\n",
    "weights = model_LR.coef_   # weight vector for each label\n",
    "top30_features_index = []  # list of 30 features (10 words with the largest weights for each label)\n",
    "class_list = ['negative', 'neutral', 'positive']\n",
    "\n",
    "for i in range(3):  # 4 labels\n",
    "    weights_label_i = list(weights[i])  # list of weights for label i\n",
    "    top10_weights_label_i = sorted(weights_label_i, reverse=True)[0:10]  # sort and filter greatest 10 weights\n",
    "    top10_features_index_i = [weights_label_i.index(weight) \\\n",
    "                             for weight in top10_weights_label_i]  # find index of top 10\n",
    "    top10_features_i = [feature_names[index] for index in top10_features_index_i]  # list of features of top 10 weights\n",
    "    top30_features_index += top10_features_index_i  # add the top 10 weigths index of label i to the list of 30\n",
    "\n",
    "    # Print top 5 features per label\n",
    "    print \"Class\", i, \"(\", class_list[i] , \")\"\n",
    "    for index, (weight, feature) in enumerate(zip(top10_weights_label_i,top10_features_i), start = 1):\n",
    "        print index, \"weight: %.3f\" %(weight), \"for feature \\\"\", feature, \"\\\"\"\n",
    "\n",
    "top30_features = [feature_names[index] for index in top30_features_index]  # list of features of top 20 weights\n",
    "\n",
    "# Formatting weights for each class for printing table of results\n",
    "top30_w_class0 = [\"%.3f\" %(list(weights[0])[index]) for index in top30_features_index]\n",
    "top30_w_class1 = [\"%.3f\" %(list(weights[1])[index]) for index in top30_features_index]\n",
    "top30_w_class2 = [\"%.3f\" %(list(weights[2])[index]) for index in top30_features_index]\n",
    "\n",
    "\n",
    "\n",
    "weights_array = np.column_stack((top30_w_class0, top30_w_class1, top30_w_class2))\n",
    "\n",
    "# Print table of weights for the 20 top features\n",
    "print \"\\nTable of weights for each feature for each of the 3 labels:\\n\"\n",
    "row_format =\"{:>20}\" * (len(class_list) + 1)\n",
    "print row_format.format(\"\", *class_list)\n",
    "for feature, weights in zip(top30_features, weights_array):\n",
    "    print row_format.format(feature, *weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Observations **  \n",
    "**BEFORE** bootstrapping:\n",
    "1. Some neutral prediction words seem promising, in particular, \"study\", \"investigated\", \"studied\"\n",
    "2. Some negative and positive prediciton words seem helpful\n",
    "3. Main weakness of the model: this is a bag of word model with feature based on tf-idf. Thus, a drug name or food compound can also result with an important weight to predict a class and this is misleading. For example, \"monoamine\" has a high weight for class \"positive\" based on the positive labels of sentences containing this word. Thus, even if we will add a sentence with a negative interaction between monoamine and a food compound, the BOW model will predict a positive label. The proportion of labels for a drug-food interaction sentences in the training will affect how the model will retain those drugs or food compounds as predictors of positive/negative/neutral. \n",
    "\n",
    "**AFTER** bootstrapping:\n",
    "similar to above but seems to have less drug and food related words with high weight for predicting label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. R-ratio analysis - look at individual sentences with highest errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R is equal to maximum predicted probability divided by predicted probability of the correct label.  \n",
    "In other words, it looks how \"far\" the prediction of a class is from the true class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 sentences where the ratio R is largest:\n",
      "\n",
      "                         ratio R     Max pred Pr      Correct Pr Predicted label      True label       Doc Index\n",
      "       Highest R          76.185           0.898           0.012             1.0             2.0           428.0\n",
      "     2nd highest          51.776            0.53            0.01             2.0             0.0            91.0\n",
      "     3rd highest           47.84           0.927           0.019             1.0             0.0            30.0\n",
      "             4th          44.444            0.79           0.018             2.0             0.0           337.0\n",
      "             5th          43.047           0.809           0.019             2.0             0.0           435.0\n",
      "             6th          40.012           0.935           0.023             2.0             1.0           360.0\n",
      "             7th          37.808            0.55           0.015             0.0             1.0           587.0\n",
      "             8th           25.24            0.77            0.03             2.0             0.0            29.0\n",
      "             9th          24.709           0.708           0.029             1.0             0.0           414.0\n",
      "            10th          23.767           0.882           0.037             2.0             0.0           386.0\n",
      "\n",
      "Sentences:\n",
      "\n",
      "1) Sentence with ratio R = 76.185 :\n",
      "The release of acetaminophen (AAP) from tablets containing phospholipids was examined using hydrogenated soybean phospholipid (HSL) and its main components, phosphatidylcholine (PC), phosphatidylethanolamine (PE) and phosphatidylinositol (PI), although the PI was not well purified (PI rich).\n",
      "\n",
      "2) Sentence with ratio R = 51.776 :\n",
      "It was found that besides sodium salicylate and high doses of aspirin, other salicylate-type drugs, such as diflunisal, 4-aminosalicylic acid, 2,4-dihydroxybenzoic acid and methyl salicylate, and several non-acidic compounds, such as proquazone, benzydamine and paracetamol, were gastroprotective.\n",
      "\n",
      "3) Sentence with ratio R = 47.840 :\n",
      "Activated carbon (AC)/CoFe2O4 nanocomposites, MAC-1 and MAC-2, were prepared by a simple pyrolytic method using a mixture of iron(III)/cobalt(II) benzoates and iron(III)/cobalt(II) oxalates, respectively, and were used as efficient adsorbents for the removal of amoxicillin (AMX) and paracetamol (PCT) of aqueous effluents.\n",
      "\n",
      "4) Sentence with ratio R = 44.444 :\n",
      "The IC(50) values of the four potent flavonoids, quercitrin, isoquercitrin, rutin, and quercetin on monoamine oxidase were 19.06, 11.64, 3.89, and 10.89 microM and enzyme kinetics analysis revealed apparent inhibition constants (K(i)) of 21.01, 2.72, 1.83, and 7.95 microM, respectively, on the substrate, benzylamine.\n",
      "\n",
      "5) Sentence with ratio R = 43.047 :\n",
      "In the hydroponic arrangement, the best results were achieved for Lupinus, where acetaminophen was totally removed from media during two or four days in concentrations of 0.1 or 0.2 mM, respectively.\n",
      "\n",
      "6) Sentence with ratio R = 40.012 :\n",
      "[reaction: see text] Lovastatin nonaketide synthase (LovB, LNKS) is an iterative type I polyketide synthase (PKS) from Aspergillus terreus that produces dihydromonacolin L (2), the biosynthetic precursor of lovastatin (1), from acetyl CoA, malonyl CoA, and S-adenosylmethionine (SAM) if the accessory protein LovC is present.\"\n",
      "\n",
      "7) Sentence with ratio R = 37.808 :\n",
      "Purified preparations of the esterase derived from the first component of complement (C'1 esterase) increased vascular permeability in guinea pig skin, an effect inhibited by triprolidine, an antihistaminic agent, but not by soy bean trypsin inhibitor.\\\n",
      "\n",
      "8) Sentence with ratio R = 25.240 :\n",
      "L-Cysteine, which activates endogenous H2S producing enzymes cystathionine--lyase and cystathionine--synthase, and NaHS and GYY4137, which generate H2S, inhibited PI hydrolysis and GLP-1 and PYY release in response to OA or 8-pCPT-2'-O-Me-cAMP.\"\n",
      "\n",
      "9) Sentence with ratio R = 24.709 :\n",
      "The thyroxin toxicosis was shown to alter also the body and tissue sensitivity to the injuring effect of hydrogen sulfide, maximal manifestation of which was observed at the periods of thyrotoxic crisis.\n",
      "\n",
      "10) Sentence with ratio R = 23.767 :\n",
      "Acclimatized sponge showed significantly enhanced removal of some less hydrophobic compounds (log D<2.5), such as ibuprofen, acetaminophen, naproxen, and estriol, as compared with non-acclimatized sponge.\n",
      "\n",
      "Sentence 1 (example number 428 ):\n",
      "Influential word: not with magnitude: 0.493112153339\n",
      "Influential word: aap with magnitude: 0.425587691449\n",
      "Influential word: rich with magnitude: 0.42488102722\n",
      "Influential word: examined with magnitude: 0.415147931849\n",
      "Influential word: using with magnitude: 0.367525153806\n",
      "\n",
      "Sentence 2 (example number 91 ):\n",
      "Influential word: type with magnitude: 0.57097455598\n",
      "Influential word: other with magnitude: 0.402866768543\n",
      "Influential word: it with magnitude: 0.297030968244\n",
      "Influential word: aspirin with magnitude: 0.291462807676\n",
      "Influential word: aminosalicylic with magnitude: 0.276077940793\n",
      "\n",
      "Sentence 3 (example number 30 ):\n",
      "Influential word: were with magnitude: 0.752006953833\n",
      "Influential word: method with magnitude: 0.370896882972\n",
      "Influential word: used with magnitude: 0.36255998068\n",
      "Influential word: using with magnitude: 0.297268638014\n",
      "Influential word: mixture with magnitude: 0.262184793254\n",
      "\n",
      "Sentence 4 (example number 337 ):\n",
      "Influential word: values with magnitude: 0.455536344415\n",
      "Influential word: substrate with magnitude: 0.380928451671\n",
      "Influential word: monoamine with magnitude: 0.373418621476\n",
      "Influential word: quercetin with magnitude: 0.363465031547\n",
      "Influential word: 89 with magnitude: 0.306390942254\n",
      "\n",
      "Sentence 5 (example number 435 ):\n",
      "Influential word: achieved with magnitude: 0.617283996029\n",
      "Influential word: best with magnitude: 0.612656566302\n",
      "Influential word: results with magnitude: 0.496506099152\n",
      "Influential word: removed with magnitude: 0.481788500417\n",
      "Influential word: where with magnitude: 0.426545299566\n",
      "\n",
      "Sentence 6 (example number 360 ):\n",
      "Influential word: lovastatin with magnitude: 0.846806715236\n",
      "Influential word: type with magnitude: 0.529132020408\n",
      "Influential word: acetyl with magnitude: 0.3366149736\n",
      "Influential word: biosynthetic with magnitude: 0.256593219619\n",
      "Influential word: precursor with magnitude: 0.254850692243\n",
      "\n",
      "Sentence 7 (example number 587 ):\n",
      "Influential word: inhibited with magnitude: 0.675069674847\n",
      "Influential word: by with magnitude: 0.544898425478\n",
      "Influential word: derived with magnitude: 0.389519905726\n",
      "Influential word: component with magnitude: 0.371731126621\n",
      "Influential word: from with magnitude: 0.339975265617\n",
      "\n",
      "Sentence 8 (example number 29 ):\n",
      "Influential word: which with magnitude: 0.938440974879\n",
      "Influential word: h2s with magnitude: 0.883565922879\n",
      "Influential word: pyy with magnitude: 0.439544155838\n",
      "Influential word: release with magnitude: 0.438682970623\n",
      "Influential word: enzymes with magnitude: 0.290163693983\n",
      "\n",
      "Sentence 9 (example number 414 ):\n",
      "Influential word: sensitivity with magnitude: 0.415027704604\n",
      "Influential word: hydrogen with magnitude: 0.368007571447\n",
      "Influential word: was with magnitude: 0.336428995831\n",
      "Influential word: maximal with magnitude: 0.250311755104\n",
      "Influential word: sulfide with magnitude: 0.210165125825\n",
      "\n",
      "Sentence 10 (example number 386 ):\n",
      "Influential word: enhanced with magnitude: 1.44599512979\n",
      "Influential word: showed with magnitude: 0.855953950379\n",
      "Influential word: less with magnitude: 0.638971634718\n",
      "Influential word: significantly with magnitude: 0.591035620115\n",
      "Influential word: compared with magnitude: 0.352312437475\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Logistic regression model with optimal C\n",
    "model_LR = LogisticRegression(C=optimal_Cs)\n",
    "model_LR.fit(vocab_train_tf, train_labels)\n",
    "predicted_labels_LR = model_LR.predict(vocab_test_tf)\n",
    "\n",
    "#feature_names = vectorizer.get_feature_names()\n",
    "#print \"features names length:\", len(feature_names)\n",
    "\n",
    "    \n",
    "# Variables to calculate R\n",
    "probabilities = model_LR.predict_proba(vocab_test_tf)  # Each label probability (4) for each document\n",
    "proba_max = probabilities.max(axis=1)  # Maximum predicted probability\n",
    "proba_correct_label = [probabilities[i][test_labels[i]] \\\n",
    "                       for i in range(probabilities.shape[0])]  # Predicted prob of the correct label\n",
    "r_ratio = proba_max/proba_correct_label  # R = maximum predicted prob / predicted prob of the correct label\n",
    "sentence_index = [i for i in range(probabilities.shape[0])]  # Index of the document to retrace once sorted by R\n",
    "\n",
    "# Results array with 5 columns (R, max prob, prob of correct label, predicted labels, true labels,\n",
    "# document index)\n",
    "results = np.column_stack((r_ratio, proba_max, proba_correct_label, predicted_labels_LR, \\\n",
    "                           test_labels, sentence_index))\n",
    "results_max3r = sorted(results, key=lambda x: x[0], reverse=True)[:10]  # top 10 sentences with highest R\n",
    "\n",
    "\n",
    "# Format and print top 3 documents with highest R:\n",
    "# 1) print top 10 sentences related info - probabilities, predicted/correct labels, etc.\n",
    "print \"\\nTop 10 sentences where the ratio R is largest:\\n\"\n",
    "column_names = [\"ratio R\", \"Max pred Pr\", \"Correct Pr\", \"Predicted label\", \"True label\", \\\n",
    "                \"Doc Index\"]\n",
    "row_format =\"{:>16}\" * (len(column_names)+1)\n",
    "print row_format.format(\"\", *column_names)\n",
    "top_10 = [\"Highest R\", \"2nd highest\", \"3rd highest\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \"10th\"]\n",
    "for index, row in zip(top_10, results_max3r):\n",
    "    row = [round(item,3) for item in row]\n",
    "    print row_format.format(index, *row)\n",
    "\n",
    "# 2) print top 3 R documents messages\n",
    "print \"\\nSentences:\"\n",
    "i = 1\n",
    "for row in results_max3r:\n",
    "    print \"\\n\" + str(i) +\") Sentence with ratio R = %.3f\" %(row[0]), \":\"\n",
    "    print test_data[int(row[5])]\n",
    "    i +=1  \n",
    "\n",
    "\n",
    "# Diagnosis of influential words in the 3 documents with highest R\n",
    "weights = model_LR.coef_\n",
    "sentence_list = [int(result[5]) for result in results_max3r]\n",
    "j=1\n",
    "\n",
    "for example in sentence_list:\n",
    "    predicted_label = predicted_labels_LR[example]\n",
    "    indices = vocab_test_tf[example].indices  # list of indices of non zero features of document\n",
    "    vocab_freq = vocab_test_tf[example].data  # list of features values of document\n",
    "    weights_example = [weights[predicted_label][index] for index in indices]  # list of LR weights \n",
    "                                                                              # for non zero features of doc\n",
    "    feature_importance = vocab_freq * weights_example  # feature value x weight for total influence on prediction\n",
    "\n",
    "    features_array = np.column_stack((feature_importance, indices))\n",
    "    features_sorted = sorted(features_array, key=lambda x: x[0], reverse=True)  # Sort words by influence\n",
    "\n",
    "    # Print top 5 features (words) of the document with heaviest weight x value\n",
    "    \n",
    "    print \"\\nSentence\", j,  \"(example number\", example, \"):\"\n",
    "    for i in range(5):\n",
    "        index = int(features_sorted[i][1])\n",
    "        print \"Influential word:\", feature_names[index] ,\"with magnitude:\", features_sorted[i][0]\n",
    "    j +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 1. Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def empty_preprocessor(s):\n",
    "    return s\n",
    "\n",
    "def better_preprocessor(s):\n",
    "    s = s.lower()  # to lowercase all letters in the string\n",
    "    s = re.sub(\"[^a-zA-Z0-9]\", \" \", s) # to remove non-letter and non-numerical characters\n",
    "    s = re.sub ('\\d+', \" numsequence \",s)  # replace sequences of numbers with a single token\n",
    "    \n",
    "    pronoun_list = ['you', 'he', 'she', 'we', 'they', 'me', 'him', 'his', 'her', 'hers', 'yours', 'us', 'our'\\\n",
    "                   'ours', 'their', 'theirs']  # list of pronouns as stopwords since not informative for prediciton\n",
    "    for word in pronoun_list:\n",
    "        s = re.sub(r'\\b%s\\b' % word, \" \",s)  # to remove stopwords in the list\n",
    "        \n",
    "    nothelping = ['or', 'to', 'of', 'a', 'on', 'the']\n",
    "    for word in nothelping:\n",
    "        s = re.sub(r'\\b%s\\b' % word, \" \",s)  # to remove stopwords in the list\n",
    "        \n",
    "    #s = re.sub(r'ly\\b', \"\",s)   # to remove \"ly\" from words ending by \"ly\"\n",
    "    s = re.sub(r'ing\\b', \"\",s)  # to remove \"ing\" from words ending by \"ing\"\n",
    "    #s = re.sub(r's\\b', \"\",s)    # to remove \"s\" from words ending by \"s\"\n",
    "    \n",
    "    for word in s.split():  # to shorten words longer than 15 characters (from histogram, most words < 15)\n",
    "        if len(word)>15:\n",
    "            short_word = word[:15]\n",
    "            s = s.replace(word,short_word)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary with no preprocessor: 8435\n",
      "accuracy with no custom preprocessor is: 0.728\n",
      "\n",
      "Size of vocabulary with custom preprocessor: 7778\n",
      "accuracy with custom preprocessor is: 0.715\n"
     ]
    }
   ],
   "source": [
    "# No preprocessor\n",
    "vectorizer_initial = TfidfVectorizer()\n",
    "vocab_train_initial = vectorizer_initial.fit_transform(train_data)\n",
    "vocab_test_initial = vectorizer_initial.transform(test_data)\n",
    "count_features_init = len(vectorizer_initial.get_feature_names())\n",
    "print \"Size of vocabulary with no preprocessor:\", count_features_init\n",
    "\n",
    "model_LR_initial = LogisticRegression(C=optimal_Cs)\n",
    "model_LR_initial.fit(vocab_train_initial, train_labels)\n",
    "predicted_labels_initial = model_LR_initial.predict(vocab_test_initial)\n",
    "accuracy_initial = model_LR_initial.score(vocab_test_initial, test_labels)\n",
    "print \"accuracy with no custom preprocessor is: %.3f\" %(accuracy_initial)\n",
    "print \"\"\n",
    "\n",
    "\n",
    "# With preprocessor\n",
    "vectorizer_better = TfidfVectorizer(preprocessor=better_preprocessor)\n",
    "vocab_train_better = vectorizer_better.fit_transform(train_data)\n",
    "vocab_test_better = vectorizer_better.transform(test_data)\n",
    "\n",
    "count_features_better = len(vectorizer_better.get_feature_names())\n",
    "print \"Size of vocabulary with custom preprocessor:\", count_features_better\n",
    "\n",
    "model_LR_better = LogisticRegression(C=optimal_Cs)\n",
    "model_LR_better.fit(vocab_train_better, train_labels)\n",
    "predicted_labels_better = model_LR_better.predict(vocab_test_better)\n",
    "accuracy_better = model_LR_better.score(vocab_test_better, test_labels)\n",
    "print \"accuracy with custom preprocessor is: %.3f\" %(accuracy_better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessor not helping...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. N-grams instead of unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (dev data): 0.916\n",
      "Accuracy (test data): 0.731\n"
     ]
    }
   ],
   "source": [
    "# Turn the raw training text into feature vectors based on \"td-idf\"\n",
    "vectorizer = TfidfVectorizer(analyzer='char' , ngram_range=(5,8))\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_dev_tf = vectorizer.transform(dev_data)\n",
    "\n",
    "# Logistic regression model\n",
    "model_LR = LogisticRegression(C=optimal_Cs)\n",
    "model_LR.fit(vocab_train_tf, train_labels)\n",
    "predicted_labels_LR_ngram = model_LR.predict(vocab_dev_tf)\n",
    "\n",
    "accuracy = model_LR.score(vocab_dev_tf, dev_labels)\n",
    "print \"Accuracy (dev data): %.3f\" %(accuracy)\n",
    "\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "predicted_labels_LR_ngram2 = model_LR.predict(vocab_test_tf)\n",
    "accuracy = model_LR.score(vocab_test_tf, test_labels)\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
