{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_alpha</th>\n",
       "      <th>Label_num</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Food</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>pentadecanoic acid</td>\n",
       "      <td>(123)iodine labelled beta-methyl-iodophenyl pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>2-phenylethanol</td>\n",
       "      <td>2-Phenylethanol is a widely used aroma compoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>3,4-dihydroxyphenylacetic acid</td>\n",
       "      <td>3,4-dihydroxyphenylacetic acid and 4-methylcat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>arachin</td>\n",
       "      <td>A 96-well microplate format of this method was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>diethylamine</td>\n",
       "      <td>A biochemical study was performed in order to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label_alpha  Label_num           Drug                            Food  \\\n",
       "ID                                                                          \n",
       "400     neutral          1  ACE inhibitor              pentadecanoic acid   \n",
       "333    positive          2  ACE inhibitor                 2-phenylethanol   \n",
       "77     positive          2  ACE inhibitor  3,4-dihydroxyphenylacetic acid   \n",
       "338     neutral          1  ACE inhibitor                         arachin   \n",
       "214     neutral          1  ACE inhibitor                    diethylamine   \n",
       "\n",
       "                                              sentence  \n",
       "ID                                                      \n",
       "400  (123)iodine labelled beta-methyl-iodophenyl pe...  \n",
       "333  2-Phenylethanol is a widely used aroma compoun...  \n",
       "77   3,4-dihydroxyphenylacetic acid and 4-methylcat...  \n",
       "338  A 96-well microplate format of this method was...  \n",
       "214  A biochemical study was performed in order to ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../labeled_dataAll.csv\", index_col='ID')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACE inhibitor' 'Antacid' 'GLP-1' 'Thyroxine' 'Statin' 'Acetaminophen'\n",
      " 'Digoxin' 'Isoniazid' 'Antihistamine' 'MOAI' 'Analgesics'\n",
      " 'Bronchodialators']\n"
     ]
    }
   ],
   "source": [
    "drugs = df.Drug.unique()\n",
    "print drugs\n",
    "add_dict = {}\n",
    "\n",
    "for drug in drugs:\n",
    "    \n",
    "    count_list = []\n",
    "    for i in range(3):\n",
    "        count = len(df[(df.Drug == drug) & (df.Label_num == i)])\n",
    "        count_list.append(count)\n",
    "        \n",
    "    max_count = max(count_list)\n",
    "    add_list = [max(0,max_count-c) for c in count_list]\n",
    "    add_dict[drug] = add_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GLP-1': [109, 0, 59], 'Thyroxine': [66, 0, 85], 'MOAI': [34, 2, 0], 'Antihistamine': [18, 0, 5], 'Analgesics': [8, 2, 0], 'Digoxin': [116, 0, 132], 'Isoniazid': [39, 0, 42], 'Acetaminophen': [334, 0, 435], 'Statin': [196, 0, 171], 'Antacid': [22, 0, 16], 'Bronchodialators': [12, 0, 2], 'ACE inhibitor': [272, 0, 107]}\n"
     ]
    }
   ],
   "source": [
    "print add_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2471\n"
     ]
    }
   ],
   "source": [
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4755\n"
     ]
    }
   ],
   "source": [
    "for drug in drugs:\n",
    "    for i in range(3):\n",
    "        temp = df[(df.Drug == drug) & (df.Label_num == i)].sample(add_dict[drug][i], replace=True)\n",
    "        df = df.append(temp)\n",
    "\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4755\n"
     ]
    }
   ],
   "source": [
    "print sum([j for i in add_dict.values() for j in i]) + 2471"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly shuffle the data. Use same random seed to get same results every time. \n",
    "df_shuffle = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "# Separate labels\n",
    "labels = [i for i in df_shuffle.Label_num]\n",
    "labels = np.array(labels)\n",
    "n = len(labels)\n",
    "\n",
    "# Drop unecessary columns from input data\n",
    "df_shuffle.drop('Label_alpha', axis=1, inplace=True)\n",
    "df_shuffle.drop('Label_num', axis=1, inplace=True)\n",
    "df_shuffle.drop('Drug', axis=1, inplace=True)\n",
    "df_shuffle.drop('Food', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Split the train data into training and dev datasets\n",
    "train_data =  df_shuffle[:n/2].sentence.tolist()\n",
    "dev_data = df_shuffle[n/2: 3*n/4].sentence.tolist()\n",
    "test_data = df_shuffle[3*n/4:].sentence.tolist()\n",
    "\n",
    "# Separate training and dev labels\n",
    "train_labels =  labels[:n/2]\n",
    "dev_labels = labels[n/2: 3*n/4]\n",
    "test_labels = labels[3*n/4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training label shape: (2377,)\n",
      "test label shape: (1189,)\n",
      "dev label shape: (1189,)\n"
     ]
    }
   ],
   "source": [
    "print 'training label shape:', train_labels.shape\n",
    "print 'test label shape:', test_labels.shape\n",
    "print 'dev label shape:', dev_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['negative', 'neutral', 'positive'] # corresponding labels = 0, 1, 2\n",
    "classes_dict = {0:'negative', 1:'neutral', 2:'positive'} # corresponding labels = 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_classes(value, labels):\n",
    "    return len([i for i in labels if i == value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split among Negative, Neutral and Positive\n",
      "        dataset |       negative |        neutral |       positive\n",
      "          train |     784.000000 |     797.000000 |     796.000000\n",
      "            dev |     387.000000 |     400.000000 |     402.000000\n",
      "           test |     414.000000 |     388.000000 |     387.000000\n"
     ]
    }
   ],
   "source": [
    "# Check number of classes per train/dev/test dataset:\n",
    "print \"Dataset split among Negative, Neutral and Positive\"\n",
    "\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"train\",count_classes(0,train_labels), \n",
    "                                                     count_classes(1,train_labels),\n",
    "                                                     count_classes(2,train_labels))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev\",count_classes(0,dev_labels), \n",
    "                                                     count_classes(1,dev_labels),\n",
    "                                                     count_classes(2,dev_labels))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test\",count_classes(0,test_labels), \n",
    "                                                     count_classes(1,test_labels),\n",
    "                                                     count_classes(2,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example 1\n",
      "Label 0 ( negative )\n",
      "Sentence:\n",
      "Ultrasonic imaging revealed enlarged thyroid glands with lowered echotexture and relatively heterogeneous features in the high-fat lard fed rats. \n",
      "\n",
      "\n",
      "Training example 2\n",
      "Label 1 ( neutral )\n",
      "Sentence:\n",
      "In order to develop a practicable, reliable and cost-effective bioassay suitable for routine testing, a combined dot-blot/RNAse protection assay, utilising digoxigenin-labelled cRNA transcripts of plasmid psg5Vg1.1 was used for the quantification of vitellogenin-mRNA in isolated rainbow trout (Oncorhynchus mykiss) hepatocytes.\\ \n",
      "\n",
      "\n",
      "Training example 3\n",
      "Label 0 ( negative )\n",
      "Sentence:\n",
      "Additionally, atorvastatin (10, 20 mg/kg), simvastatin (30 mg/kg) and fluvastatin (10 mg/kg) significantly decrease the TNF- level and striatal lesion volume in quinolinic acid treated animals indicating their anti-inflammatory effects. \n",
      "\n",
      "\n",
      "Training example 4\n",
      "Label 1 ( neutral )\n",
      "Sentence:\n",
      "Three sets of drug-loaded crosslinked pectin wafers were produced employing the model water-soluble antihistamine, diphenhydramine and were compared with noncrosslinked wafers.\\ \n",
      "\n",
      "\n",
      "Training example 5\n",
      "Label 2 ( positive )\n",
      "Sentence:\n",
      "The angiotensin I-converting enzyme (ACE) inhibitory activity of FSS (IC(50) = 454 microg/mL) was greater than that of regular soy sauce (IC(50) = 1620 microg/mL). \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check few sentences\n",
    "\n",
    "def print_examples(num_examples=5):\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        print \"Training example\", i+1\n",
    "        print \"Label\", train_labels[i], \"(\", classes_dict[train_labels[i]],\")\"\n",
    "        print \"Sentence:\\n\", train_data[i], \"\\n\\n\"\n",
    "       \n",
    "    \n",
    "print_examples(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn the raw training text into feature vectors based on \"td-idf\"\n",
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_dev_tf = vectorizer.transform(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression model ...\n",
      "Performing grid search for Logistic Regression model. It may take a few minutes ...\n",
      "Logistic Regression grid search model fitting time = 0.802970 seconds.\n",
      "As per the grid search on the training data, the optimal value of C = 50.000000.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=50.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "# Logistic Regression:\n",
    "print \"Evaluating Logistic Regression model ...\"\n",
    "\n",
    "# Create a Logistic Regression model. \n",
    "LRmodel = LogisticRegression(C=1.0)\n",
    "\n",
    "# Create a grid search.\n",
    "print \"Performing grid search for Logistic Regression model. It may take a few minutes ...\"\n",
    "Cs = {'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0]}\n",
    "CV_LRmodel = GridSearchCV(estimator=LRmodel, param_grid=Cs)\n",
    "\n",
    "# Fit the models using grid search and display the results.\n",
    "start_time = time.time()\n",
    "CV_LRmodel.fit(vocab_train_tf, train_labels)\n",
    "end_time = time.time()\n",
    "print \"Logistic Regression grid search model fitting time = %f seconds.\" % (end_time - start_time)\n",
    "\n",
    "optimal_Cs = CV_LRmodel.best_params_['C']\n",
    "print \"As per the grid search on the training data, the optimal value of C = %f.\" % optimal_Cs\n",
    "\n",
    "# Construct model with optimal C\n",
    "model_LR = LogisticRegression(C=optimal_Cs)\n",
    "model_LR.fit(vocab_train_tf, train_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev dataset with 1189 sentences\n",
      "\n",
      "Data split - Negative, Neutral, Positive\n",
      "----------------------------------------\n",
      "        dataset |       negative |        neutral |       positive\n",
      "  dev_predicted |     399.000000 |     356.000000 |     434.000000\n",
      "     dev_actual |     387.000000 |     400.000000 |     402.000000\n",
      "\n",
      "Accuracy\n",
      "--------\n",
      "Accuracy (test data): 0.881\n",
      "\n",
      "Classification Report\n",
      "---------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.94      0.93       387\n",
      "          1       0.88      0.79      0.83       400\n",
      "          2       0.85      0.92      0.88       402\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1189\n",
      "\n",
      "\n",
      "Confusion matrix for Dev data\n",
      "-----------------------------\n",
      "The most confused pair of classes is: 1 ( neutral )  incorrectly predicted as 2 ( positive )\n",
      "Number of such confusion occurences: 58\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGkCAYAAAABqz41AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111552c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation data\n",
    "predicted_labels_LR = model_LR.predict(vocab_dev_tf)\n",
    "\n",
    "print \"Dev dataset with\", len(predicted_labels_LR), \"sentences\"\n",
    "print \"\"\n",
    "\n",
    "print \"Data split - Negative, Neutral, Positive\"\n",
    "print \"----------------------------------------\"\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev_predicted\",count_classes(0,predicted_labels_LR), \n",
    "                                                     count_classes(1,predicted_labels_LR),\n",
    "                                                     count_classes(2,predicted_labels_LR))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev_actual\",count_classes(0,dev_labels), \n",
    "                                                     count_classes(1,dev_labels),\n",
    "                                                     count_classes(2,dev_labels))\n",
    "\n",
    "\n",
    "accuracy = model_LR.score(vocab_dev_tf, dev_labels)\n",
    "print \"\\nAccuracy\"\n",
    "print \"--------\"\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)\n",
    "\n",
    "print \"\\nClassification Report\"\n",
    "print \"---------------------\"\n",
    "print classification_report(dev_labels, predicted_labels_LR)\n",
    "\n",
    "print \"\\nConfusion matrix for Dev data\"\n",
    "print \"-----------------------------\"\n",
    "\n",
    "array = confusion_matrix(dev_labels, predicted_labels_LR)\n",
    "df_cm = pd.DataFrame(array, index = [\"negative\", \"neutral\", \"positive\"],\n",
    "                  columns = [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "# Find the most confused pair\n",
    "cm2 = confusion_matrix(dev_labels, predicted_labels_LR)  # copy the cm matrix so that can modify the copy without affecting original cm\n",
    "np.fill_diagonal(cm2, 0)  # set the values in the diagonal = 0 to obtain number of confused pairs matrix\n",
    "maximum_pair_idx = np.where(cm2 == cm2.max())  # returns the indices of the max value in cm matrix\n",
    "true_interaction = maximum_pair_idx[0][0]\n",
    "predicted_interaction = maximum_pair_idx[1][0]\n",
    "max_wrong_prediction = cm2[true_interaction][predicted_interaction]\n",
    "print \"The most confused pair of classes is:\", true_interaction, \"(\", classes_dict[true_interaction],\")\",\\\n",
    "\" incorrectly predicted as\", predicted_interaction, \"(\", classes_dict[predicted_interaction],\")\"\n",
    "print \"Number of such confusion occurences:\", max_wrong_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 1189 sentences\n",
      "\n",
      "Data split - Negative, Neutral, Positive\n",
      "----------------------------------------\n",
      "        dataset |       negative |        neutral |       positive\n",
      " test_predicted |     424.000000 |     336.000000 |     429.000000\n",
      "    test_actual |     414.000000 |     388.000000 |     387.000000\n",
      "\n",
      "Accuracy\n",
      "--------\n",
      "Accuracy (test data): 0.884\n",
      "\n",
      "Classification Report\n",
      "---------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.95      0.94       414\n",
      "          1       0.90      0.78      0.83       388\n",
      "          2       0.83      0.92      0.88       387\n",
      "\n",
      "avg / total       0.89      0.88      0.88      1189\n",
      "\n",
      "\n",
      "Confusion matrix for test data\n",
      "------------------------------\n",
      "The most confused pair of classes is: 1 ( neutral )  incorrectly predicted as 2 ( positive )\n",
      "Number of such confusion occurences: 60\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGkCAYAAAABqz41AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XlcVPX+x/H3DIuiLCIooplbpGaZqZWW6dXs5lUrLUnR\nKMsls9woN1Dc19wyNfclM01Lrreya5lmm5llZWmZifvCpiiQrDO/P/xdbpZXRp3heA6v5+Mxj5jh\n8D2fQyN8+Hy+3++xOZ1OpwAAAAxkNzoAAAAAEhIAAGA4EhIAAGA4EhIAAGA4EhIAAGA4b08OXr9a\nC08OjxJo5/drjQ4BFuJ0sMgQ7lc6pFKxncvdv2d3H97m1vGuBBUSAABgOI9WSAAAgOfYbDajQ3Ab\nKiQAAMBwVEgAADApm806dQXrXAkAADAtEhIAAGA4WjYAAJiUXdaZ1EpCAgCASbHKBgAAwI2okAAA\nYFJ2C62yISEBAMCkaNkAAAC4EQkJAAAwHC0bAABMymahZb9USAAAgOGokAAAYFKssgEAAIZjlQ0A\nAIAbUSEBAMCk7FRIAAAA3IeEBAAAGI6WDQAAJmWzUF3BOlcCAABMiwoJAAAmZaVlvyQkAACYFKts\nAAAA3IgKCQAAJsXN9QAAANyIhAQAABiOlg0AACbF3X4BAIDhrLTs1zqpFQAAMC0qJAAAmJSV9iEh\nIQEAwKRY9gsAAOBGJCQAAMBwtGwAADApKy37tc6VAAAA06JCAgCASVlpHxISEgAATMpKy35p2QAA\nAMNRIQEAwKTYhwQAAMCNSEgAAIDhaNkAAGBSrLIBAACGY5UNAACAG1EhAQDApKy0ysalhKSgoEDr\n16/XiRMn1KRJE0VERKh8+fKejg0AAJQQLrVs4uPjdeLECX355ZfKysrS0KFDPR0XAAAogt1md+vD\n0Gtx5aAjR45owIABKlWqlFq1aqWMjAxPxwUAAEoQlxKSgoICnT59WpKUmZkpu525sAAAwH1cmkMy\naNAgRUVFKSUlRZ07d1ZcXJyn4wIAAEUocfuQBAQEaNOmTTp9+rSCg4Mt9Q0AAMCsStw+JLNmzVKX\nLl20efNmnT9/3tMxAQCAEsalCsn8+fOVkpKiDRs26JlnnlGtWrU0YcIET8cGAAAuo8TtQyJJ+fn5\nys3NlcPhkJeXlydjAgAALrBSy8alhOTJJ59Ubm6uOnXqpOXLl6tMmTKejgsAAJQgLiUkcXFxql27\ntqdjAQAAJdRlE5KxY8cqPj5e8fHxhStrnE6nbDab1qxZUywBAgCAS7PSqtfLJiR9+/aVJE2ZMkU+\nPj6Fr589e9azUV3nujzVUY93e1gOh1NHD5/QmGEvK/3Mxd+TqO6Pqkt0B2Vn5yjxt8OaOHKWMs5l\nXvU5ywUHacLMWIVXCZOjwKGxsdO1e9ceSVK7jg/oqV6d5XQ6df58tqaMflU///TrNV0jzOvNte9o\nzTsJKl2qlGpWr6bYwYMUGBBgdFgwoZHjJymiVk09GdVZOTk5mjh9lvb8/IucTqduq3eLYl8cKF9f\nX6PDhEVcdtmv0+nUwYMHNWTIEOXl5Sk3N1fZ2dmKj48vrviuO3VvjdCTPR9Xtw591anNMzp6+Jhe\neLHHRcfc2fQOde/dRT2iBqpzu176/JMdGjV58DWdN3bcQH274wc9+kB3xQ6aoOnzRsu3lK+q1bhB\nA4c9qz7RL6lzu15aPOcNzVww7prOBfP6+ttdWr5qtZbMnaW1ry9Rs6ZNNGbSy0aHBZM5eOiwevUb\npI+2bit8bdGKN+RwOPT2ymV6e+UyZWdna8nrqwyMEtKFSa3ufBjpshWSH374QStWrNDBgwc1cuRI\nSZLdblezZs2KJbjr0c8/7Vf7Ft3kcDjkW8pXFStV0LEjJy46pu6tEfrqi2+Vmnxhu/2PP/hUoycP\nlpeXl2w2aeDwPmp0V33Zvbz0y579mjxqts7//t/9Xca+PEw7t3+nd9dvknThe97i/qaaMGKmJOnX\nnw/o8MFjurfFXfr5p181ZujLOp2WLkna++M+hYQGy8vLSwUFBcXxLcF15OdfflWTOxurQmioJOn+\nls01etJU5efny9vb5UV1KOHWrE9Qh/ZtFV4prPC1xnfcrsrhlSRdaBPUuTlCBw4eMihC/EeJWfbb\nunVrtW7dWtu2bVOLFi2KK6brnsPh0N8euFejpwxRbk6u5kxbctHnf/r+F0U99ajCwiso6WSKOnRu\nK28fbwUFB6pT14eUn5evqIeelST1G9xTg4Y/q4kjZ/3P85UrHyTZbDqbfq7wtaRTqQoLr6CtH36u\nUyeSC19/aeTz2vrRFyQjJdSt9epq9br1OpWUpEphYfrnu+8rPz9fZ8+eU0hIeaPDg0kMjxkoSfpq\n5zeFrzW5s3HhxydOntIbb72t0cOvrfIL/JFLfzIFBQUpPj5eeXl5kqTk5GQtWbKkiK+ytk8++kJ/\n++gRPdqlnRa8MU3tmnct/Nyunbs1/5UVemXRBBUUOPTPtRt1Nj1Debl5atGqqfwDyqpp8zslST7e\nXkpLPSNJeiNhnnx8fRReJUx3Nm2gJ3p00nff/KTFc1deMgZHgaPw49KlS2n8jFhVrBSq557kh0RJ\n1ajB7erTs7sGDImTl5ddHdq3U1BgwEVzwIBrsfeXfYoZPlJdIx9Ts6ZNjA6nxDO6zeJOLiUko0eP\nVs+ePbVp0ybdfPPNys3N9XRc160bbqys0Irl9f03P0mSEt7aqBETYhQQ6F84adWvjJ++3fGDNqz7\nQJJUPqScnn+xhzLOZcruZdeUMa/qy093SrqQSPiWujAp7ImOFyYRX6plI0n+AWWVmZElSQqrFKqk\nkymSpEqVK2r24ok6sP+Qnuk8QPl5+cXxrcB16Pfff1ejBrerQ/u2kqS002c0d+FiBQYyqRXX7oOP\nPtbkGa9o+IsD1aZ1K6PDgcW4dC+b4OBgtW/fXv7+/urXr5+SkpI8Hdd1q0LFEE19dZQCgy78gG/f\n8e/av+/gRStoKoaFaOlbr6hMWT9JUu/+T+mDDZslSV9+ulNRTz0qb28v2Ww2jZk6VAOG9r7oHE45\nL3rucDj02ZavFNn1YUlSRJ2aqnFTNe386jsFBgVo2drZ2vzvTzV8wHiSkRIuOTVNz/Ttr6ys3yVJ\nC5eu0D8eaG1wVLCCj7Z8oqmzXtX8WdNIRuARLlVI7Ha79u/fr/PnzysxMbFEL/v97psftfDV17Vs\n7Wzl5+crOSlVA3vFqe6tN2v0lMHq3K6XDh88piXzVmnVhvmy2Wz6buePmhh/YY7IgtmvKyb2Oa3d\nuFg2u1379v6maePnXXSOUYOn/OW8E0fO1OgpQ9T+0b/L4XAoduB4/Z51Xj2ff0IVK1XQ/Q/ep/vb\nNL9wsNOpnlGDrmmZMcyp+o1V1ePJJ9Stx7NyOp264/b6in1poNFhwaT+uMfF7AWLJEmjJ00t3I+q\nQf1bC+ebwBhW2ofE5nQ6nUUdtH//fu3fv19hYWGaMGGCHn74YXXv3r3IwetXYyIs3Gvn92uNDgEW\n4nQU+eMPuGKlQyoV27meuaevW8db+uW8og/yEJcqJGXLllWDBg0kSXPmzJG3t7fy8vKYKAcAQAnh\ncDg0YsQIHTx4UHa7XWPGjFFeXp7Gjx8vLy8v+fr6aurUqSpfvrzWrl2rt956Sz4+PurTp4/+9re/\nFTm+SwnJs88+q6SkJNWoUUOHDh2Sn5+f8vPzNXjwYD3yyCPXeo0AAOAqFOc+JFu2bJHNZtPq1av1\n9ddfa8aMGcrIyFB8fLxq166tt956S4sWLVKPHj20cuVKJSQkKDs7W1FRUbr33nuLLGK4NKn1hhtu\n0L///W+99dZb+vDDD3Xbbbfpvffe0xtvvOGWiwQAAFeuOHdqbd26tcaNu7AT+PHjxxUUFKSZM2cW\n3nw3Pz9fvr6+2r17txo1aiRvb2/5+/urevXq2rdvX9HX4soFp6WlqXz5C5sqBQUFKTU1VeXKlStc\njgoAAKzPbrdr2LBhmjBhgh566CGF/v+u0Lt27dKbb76p7t27KzMzUwF/uH9WmTJllJGRUeTYLrVs\n6tWrp5iYGDVo0EDff/+96tatq40bNyokJOQqLwkAAJjR5MmTlZaWpsjISG3cuFFbtmzRggULtHDh\nQgUHB8vf31+Zmf9d5ZmVlaXAwMAix3UpIRk1apQ+/vhjJSYm6pFHHlGLFi2UmJioli1bXv0VAQCA\na1Kcy343bNigpKQk9e7dW6VKlZLdbtemTZu0du1arVy5sjDpqF+/vmbNmqXc3Fzl5OQoMTFRERER\nRY7vUkKSmZmp3bt3Kzk5WdWqVdPhw4dVs2bNa7syAABgGn//+981fPhwPfHEE8rPz1dsbKyGDx+u\nypUr6/nnn5fNZtNdd92lF154QdHR0erataucTqdiYmLk6+tb5PguJSSxsbFq3ry5du7cqdDQUMXF\nxTGhFQAAgxXnvWz8/Pw0a9bFN4LdsWPHJY+NjIxUZGTkFY3v0qzU9PR0derUSd7e3mrYsKEcDkfR\nXwQAAOAilyokknTgwAFJ0qlTp+Tl5eWxgAAAgGustHW8SwnJiBEjFBcXpwMHDmjAgAEaNWqUp+MC\nAABFKM6N0TzNpZbN3r17dfbsWQUEBCglJUX9+vXzdFwAAKAEcalCsmjRIs2fP1/h4eGejgcAAJRA\nLiUkVatWVbVq1TwdCwAAuAJ263RsXEtISpcurZ49e6pu3bqFE2hiYmI8GhgAACg5XEpIWrRo4ek4\nAADAFSpxq2w6duzo6TgAAMAVKs6N0TyN2/UCAADDubwxGgAAuL5YqWVDhQQAABiOhAQAABiOlg0A\nACZlt9DW8SQkAACYFHNIAAAA3IgKCQAAJmWlfUhISAAAMCkL5SO0bAAAgPFISAAAgOFo2QAAYFJW\nmkNChQQAABiOCgkAACZlY2M0AABgNDZGAwAAcCMqJAAAmJSVJrWSkAAAYFIWykdo2QAAAOORkAAA\nAMORkAAAAMMxhwQAAJNiUisAADCclTZGo2UDAAAMR4UEAACTomUDAAAMZ6F8hJYNAAAwHgkJAAAw\nHC0bAABMirv9AgAAuBEVEgAATIpVNgAAwHAWykdo2QAAAONRIQEAwKSs1LKhQgIAAAxHQgIAAAxH\nywYAAJOy0t1+SUgAADApNkYDAABwIyokAACYlN06BRISEgAAzIqWDQAAgBuRkAAAAMPRsgEAwKSs\n1LLxaEKy/YulnhweJVBsp2lGhwALiX25k9EhwIJKh1QyOgRTokICAIBJscoGAAAYzkotGya1AgAA\nw1EhAQDApCxUIKFCAgAAjEdCAgAADEfLBgAAk7JbqGdDhQQAABiOCgkAACZlk3UqJCQkAACYlIU6\nNrRsAACA8aiQAABgUkxqBQAAcCMSEgAAYDhaNgAAmJSVbq5HQgIAgElZKB+hZQMAAIxHhQQAAJOy\nUsuGCgkAACZlt7n3cTn5+fkaMmSIunXrpscff1xbtmwp/Ny7776rLl26FD5fu3atHnvsMXXp0kWf\nfPKJS9dChQQAABTpX//6l4KDgzV16lSdPXtWHTp0UKtWrbR371698847hcelpqZq5cqVSkhIUHZ2\ntqKionTvvffKx8fnsuNTIQEAAEX6xz/+oQEDBkiSHA6HvL29lZ6erlmzZikuLq7wuN27d6tRo0by\n9vaWv7+/qlevrn379hU5PhUSAABMqjjnkPj5+UmSMjMzNWDAAA0YMEBxcXEaNmyYfH19C4/LzMxU\nQEBA4fMyZcooIyOjyPFJSAAAgEtOnjypF154QU888YRuvPFGHTlyRKNHj1ZOTo4OHDigSZMm6e67\n71ZmZmbh12RlZSkwMLDIsUlIAAAwqeJcZJOamqoePXooPj5eTZo0kXRhMqskHT9+XC+++KKGDx+u\n1NRUzZo1S7m5ucrJyVFiYqIiIiKKHJ+EBAAAkyrOm+stWLBA586d07x58zR37lzZbDYtXrz4onaN\nJIWGhio6Olpdu3aV0+lUTEzMX465FJvT6XR6KvisYwc8NTRKqPin5hsdAiwk9uVORocACwppeHex\nnev1p6e5dbwnl73k1vGuBBUSAABMio3RAAAA3IiEBAAAGI6WDQAAJmWhjg0JCQAAZsUcEgAAADei\nQgIAgElZqEBCQgIAgFkV58ZonkbLBgAAGI6EBAAAGI6EBAAAGI45JAAAmJSFppCQkAAAYFbsQwIA\nAOBGVEgAADApCxVISEgAADArWjYAAABuREICAAAMR8sGAACTslDHhgoJAAAwHhUSAABMyko31yMh\nAQDApCyUj9CyAQAAxqNCAgCASbEPCQAAgBtdtkJy8ODB//m5GjVquD0YAABQMl02IYmPj7/k6zab\nTa+//rpHAgIAAK6xUMfm8gnJypUrL/l6bm6uR4IBAACus9IcEpcmta5Zs0bLli1Tfn6+nE6nfHx8\ntGnTJk/HBgAASgiXJrWuWrVKK1euVPPmzTVp0iTVqlXL03EBAIAi2GzufRjJpYSkYsWKqlixorKy\nsnT33XcrIyPD03EBAIAi2Gw2tz6M5FJCEhAQoM2bN8tms2nNmjVKT0/3dFwAAKAEcSkhGT9+vCpX\nrqyYmBgdOnRII0aM8HRcAACgBHFpUmv//v21dOlSSdKwYcM8GpDVvf/RFq1ct142m+RXurReev5Z\nLV+9TkdPnJBNNjnl1PGTSWp8+22aMe7Sy65RMtz7yD1q+lBTOZ1OpZ1I07rp65R17verGqtsYBlF\nDeui4LBgORxOvT3zHR3ee1iS1LB1Q/0tsoWcTofysvP0z7kbdGz/cXdeCkzmwJGjmrniDWX+/ru8\nvLw0pEd3RVS7Ua+sfFNf7/5RDodDUe3+oQ6tWxkdaoln9LwPd3IpIQkMDNTmzZtVo0YN2e0Xiips\njHblDh89ptmLlmn1gldVPricvtixUy+NGq+Nq1cUHrN3368aMnaShg943sBIYbQqEVXUolNzTes1\nQ7nZuWrfu53aPN1G77yy/qrGe7R/RyXuPqgta5YqvGa4ek58RpOip6hcWDm179VWM56dqcz0LNW5\nq7aeGvOUJnSd6OYrglnk5OZq0KSXFdunp5rcXl+ff/udxsydr04PPqDjSUl6c9pkZf7+u3rHj1Xt\nGtVVt1ZNo0OGRbiUkKSlpWnFiv/+0mRjtKvj4+uj+Bf7q3xwOUlS3ZsjdPpMuvILCuTt5aW8/HzF\nT5mhwc8/qwqhIQZHCyMd339ck56aIqfDKW8fbwWFBintRJrsXna1791ONW+78MfB8d+OK2HOBuVm\n/3dvoM6DH9dv3x/Qtx99K0my2W2q2+QWvTM7QZJ0MvGkUo6lqs5dtXVs/3Gtnb5OmelZkqRjvx5T\nQLC/7Ha7HA5H8V84DLdj94+qUilMTW6vL0lq1ugOhVesoNkr31SH+1vKZrMpoGxZtW7aRJs+/5KE\nxGBGT0R1J5cSkmeeeUYtW7YsfL5x40aPBWRllcPCVDksrPD59NcWqcW9TeTt5SVJ+ufGTaoYGqIW\n9zQxKkRcR5wOp+rdU0+Pv9hJ+bn5+veyTWoV1UoF+QWa1Xe2JOkfz7RR+97ttP7/k41LKRtUVjab\n9Psf2j1nU88qKDRIP32xR+nJ/52k/vBzD2vPF3tIRkqwoydPqXxQoCYtXKL9h48ooGxZ9Y16XMlp\naQoLKV94XMWQ8jpw9JiBkUIqQS2brVu3ateuXXr//ff13XffSZIcDoc+/vhjtW3btlgCtKLz2dka\nNWWGklPTNGfyuMLX33znnxr54gADI8P1Zs+XezTqyz266x93qvfUXso6myW/sqVVu9HNkiS7t5cy\nz1xYht//1Rfk5eOl4LBg3dSglpo/1kyHfjqkzW9uueTYDoez8GOfUj6KGtpZQaFBWjhssecvDNet\n/IICffX9bs0ZOVx1a9XUZ9/s0ktTp6uUb6m/HOtlt9BvQxjusglJnTp1lJ6erlKlShXOGbHZbGrX\nrl2xBGdFJ5OSNWjkWNWqfqMWzZgsHx8fSdK+3w6owOFQw/q3Ghwhrgch4SEKKB+gQ3sOSZJ2/vsb\ndRr0mCRp/Svrte+bXyVdSCS8fS/8M57db46kS7dsJKl02dLKzsqWJAWFBuls6oXKSLmK5fTMuKeV\ndOiU5sXMV0F+QfFcJK5LocHBqlY5vLAVc1/jhpq0aImqVKyg1D9s+ZBy+owqlC//v4ZBMbFbqERy\n2WW/4eHh6tixozZu3KiOHTuqY8eO6tChg+rWrVtc8VnKuYwM9YoZqvvvu0cTYocUJiOS9O0PP+rO\nO243MDpcTwJDAhQ9opv8AvwkXVgJcyrxlL7b8p2adbxXdi+7bDabOr8UqXY9/1StdDovfupw6ucd\nP6tp+wutwPCa4Qq7saIOfJ8ovwA/9Z3xnHZ/9qNWTVpNMgI1vb2+Tqakat/BQ5Kk737+RXabXc3v\nbKT3tn6qAodDGVlZ2rz9KzW/s5GxwcJSXJpDct999xV+nJ6erqpVq+qDDz7wWFBWte5fG5Wckqqt\nn2/Xls+/lCTZZNP8aRN15PiJi+aXoGQ7+NMhfbTqYz0/4zkVFBToXNo5LYtfrowzmXro2XaKWTBI\nNrtNJ347oX+99u5FX/vWtHV/GW/97AQ9/mKkGrWOkdPp1JuTVivnfI7u79pK5SoE6bZm9VS/2YXq\nnFNOzX9poc5nni+Wa8X1pXy5IE1+cYCmLV2h8zk58vXx0aSY/rrlplo6dipJTw6NU0FBgTq0bqUG\ndWobHW6JZ6ECiWxO55/+nCrC8ePHNWfOHE2aNKnIY7OOHbjqwIBLiX9qvtEhwEJiX+5kdAiwoJCG\ndxfbuT4a+ppbx3tgynNuHe9KuLRT6x9VqVJFiYmJnogFAACUUC61bGJiYgrXOicnJyskhD0yAAAw\nWonbh6RLly6FH5cqVUq33spKEAAAjGahfMS1ls0tt9yiL774QgkJCUpKStKxY2yGAwAA3MelhCQ2\nNlZVq1bV4cOHFRoaqri4OE/HBQAAimCz29z6MJJLCUl6ero6deokb29vNWzYkG2lAQC4Dths7n0Y\nyeVVNgcOXFjCe+rUKXn9/71XAAAA3MGlhGTEiBGKi4vTzz//rAEDBmj48OGejgsAAJQgLiUke/fu\n1dmzZxUQEKCUlBT169fP03EBAIAi2Gw2tz6M5NKy30WLFmn+/PkKDw/3dDwAAKAEcikhqVq1qqpV\nq+bpWAAAwBUweiKqO7mUkJQuXVo9e/ZU3bp1C0s6MTExHg0MAABcntFtFndyKSFp0aKFp+MAAAAl\nmEsJSceOHT0dBwAAuEIWKpBc+d1+AQAA3I2EBAAAGM6llg0AALgOWahnQ0ICAIBJWWmVDS0bAABg\nOCokAACYlIUKJCQkAACYlc1unYyElg0AADAcCQkAADAcLRsAAEzKSnNIqJAAAADDUSEBAMCk2IcE\nAADAjaiQAABgUhYqkJCQAABgVrRsAAAA3IiEBAAAGI6EBAAAk7LZ3PtwxQ8//KDo6GhJ0unTp9W3\nb19FR0era9euOnr0qCRp7dq1euyxx9SlSxd98sknLo3LHBIAAOCSxYsXa8OGDSpbtqwk6eWXX9bD\nDz+sNm3aaMeOHUpMTJSfn59WrlyphIQEZWdnKyoqSvfee698fHwuOzYVEgAATMpms7n1UZRq1app\n7ty5hc937dqlU6dO6emnn9Z7772nu+++W7t371ajRo3k7e0tf39/Va9eXfv27StybBISAADMyu7m\nRxEeeOABeXl5FT4/fvy4ypUrp2XLlqlSpUpauHChMjMzFRAQUHhMmTJllJGR4dKlAAAAXLFy5cqp\nZcuWkqRWrVrpp59+UkBAgDIzMwuPycrKUmBgYJFjkZAAAGBSxd2y+bNGjRpp27ZtkqSdO3cqIiJC\nt912m7799lvl5uYqIyNDiYmJioiIKHIsJrUCAICrMnToUI0YMUKrV69WQECApk+froCAgMJVN06n\nUzExMfL19S1yLBISAADgsipVqmjNmjWSpMqVK2vp0qV/OSYyMlKRkZFXNC4JCQAAJmWhneNJSAAA\nMCvuZQMAAOBGVEgAADApCxVISEgAADAtC2UktGwAAIDhSEgAAIDhaNkAAGBSNjstGwAAALehQgIA\ngElZaE4rCQkAAGbFxmgAAABuRIUEAACTslCBhAoJAAAwHgkJAAAwHC0bAADMykI9GyokAADAcFRI\nAAAwKSvt1EpCAgCASVmoY0PLBgAAGI8KCQAAZmWhEgkVEgAAYDiPVkh8Ast5cniUQGNX9DE6BFjI\no22GGx0CLGjTT2uNDsGUaNkAAGBSFurYkJAAAGBWVlr2yxwSAABgOCokAACYlM1CPRsSEgAAzMo6\n+QgtGwAAYDwSEgAAYDhaNgAAmJSV5pBQIQEAAIajQgIAgElZqUJCQgIAgFlZqM9hoUsBAABmRYUE\nAACTslLLhgoJAAAwHAkJAAAwHC0bAABMykotGxISAADMyjr5CC0bAABgPCokAACYlM1unRIJCQkA\nAGZloTkktGwAAIDhSEgAAIDhaNkAAGBSFurYUCEBAADGo0ICAIBJWWljNCokAADAcFRIAAAwK/Yh\nAQAARqNlAwAA4EYkJAAAwHC0bAAAMCvrdGyokAAAAONRIQEAwKSsNKmVhAQAAJOyWWjZLy0bAABg\nOCokAACYFS0bAABgNCvNIaFlAwAADEdCAgAADEfLBgAAs7JOx4YKCQAAMB4VEgAATMpK+5CQkAAA\nYFassgEAAHAfKiQAAJgU+5AAAAC4EQkJAAAwHC0bAADMilU2AADAaFaaQ0JCAgAAipSfn6+hQ4fq\n+PHj8vb21rhx4+Tl5aVhw4bJbrcrIiJCo0aNuurxXUpIMjMztWjRIiUnJ6tly5aqXbu2qlWrdtUn\nBQAAblCMBZJt27bJ4XBozZo1+vLLLzVz5kzl5eUpJiZGjRs31qhRo7R582a1bt36qsZ3aVJrbGys\nqlatqsOHDys0NFRxcXFXdTIAAOA+NpvNrY/LqV69ugoKCuR0OpWRkSFvb2/t3btXjRs3liQ1b95c\n27dvv+prcSkhSU9PV6dOneTt7a2GDRvK4XBc9QkBAID5lC1bVseOHVObNm0UHx+v6OhoOZ3Oiz6f\nkZFx1eN3tZxPAAAROUlEQVS7PIfkwIEDkqRTp07Jy8vrqk8IAADMZ/ny5brvvvs0aNAgJSUlKTo6\nWnl5eYWfz8rKUmBg4FWP71KFZMSIEYqNjdXevXvVv39/DRs27KpPCAAAzCcoKEj+/v6SpICAAOXn\n5+uWW27R119/LUn69NNP1ahRo6se36UKyZEjR7R69WrZ7eyjBgDAdaMY9yF56qmnFBsbq27duik/\nP18vvfSS6tWrpxEjRigvL0+1atVSmzZtrnp8lxKS7du365VXXlGrVq3UqVMnVa1a9apPCAAA3KM4\n9yEpU6aMZs2a9ZfXV65c6ZbxXUpIRo4cqdzcXH388ccaO3as8vLytHz5crcEAAAA4HIPZvfu3fr8\n88+Vlpampk2bejImAADgCpvNvQ8DuVQhadu2rerUqaPIyEhNmDDB0zEBAAAXlLit41etWqXg4GBP\nx1JiffzJNo0YPV7bP/nI6FBgQu9/tEUr162X3WZT6dKl9NLzz+qWmyO0dsN7+ucHHyo3N1d1Impp\n1OBB8vHmbhElxcNRD6rd4w/I4XTq5NEkzRq1QOfSL94jonpEVfUd/rTK+JeRo8Ch2WMX6befD171\nOQPLBWjwxOcVVrmCChwOzR6zUD//sF+S1Kr9ferU/SE5HA7lZOfqtcnL9Nveqz8XrOeyLZv+/ftL\nkh566CE1a9bsogfc4/CRo5oxe66cchZ9MPAnh48e0+xFyzRvyni9ueBV9ejaWS+NGq8tn3+ptRve\n04Jpk/T20vnKzc3TqrcTjA4XxeSmujX06JPtNaBrnJ57dLBOHDmlp/p1vugY31I+mrggTm8t3qAX\nHh+mVfPf0ZDJ/a7pvC+M6KEfv/1ZvTu8qJeHz1Hc9Bj5+PqoSrVw9RjUTcN7j9cLjw/T6oXrFT/r\npWs6F6znsn8uzZ49W5K0bt06hYeHF77+n03ScG3OZ2crdtRYDRk0QENHXv0NiVBy+fj6KP7F/iof\nXE6SdEvtm5V25oz+uXGTnoh8VAH+ZSVJwwc+r/z8AiNDRTH67eeDeqZdfzkcTvn4+ii0YnmdPJZ0\n0TGN7rldJ46c0rdf/iBJ2rHtW506nixJ8vL2Uo9B3XRb47qy2+068MshzZu4VNnncwq//sVxz+mH\nnXu0+V+fSpLsdpvubt5Qr45bLElK3HdYxw+fVONmDfTb3kTNHDVfZ0+fkyTt35uo4JAg2b3schSw\n8/c1KcZlv5522YTk119/VVJSkqZNm6YhQ4bI6XTK4XBo+vTp2rBhQ3HFaFnjJk3V4491VMRNNY0O\nBSZVOSxMlcPCCp9Pf22h/nZPEyUePqrTZ87ohWEjlXr6jO64rZ4G9H7GwEhR3BwOp5q2bKyBY/oo\nLzdXK+a8ddHnq1QP15m0sxo45lnVrF1NmeeytGTGKklS5x4dVJBfoH6dh0uSuvfvoh4xT2juhCX/\n83yBwYGSzaaMs5mFr6Umn1aFsPLavmWnUk6lFb7+7JCntH3rNyQjuMhlE5Jz585p48aNSktL03vv\nvSfpwgSarl27FktwVrZm3Tvy9vbWI+3b6viJk0aHA5M7n52tUVNmKCUtTa9OGqcnnuuvHbu+16xx\noy5UUSZP09wlK/Ri395Gh4pitH3rN9q+tafaPNZKExfG6el/9C/8nLe3t+687w4Nfnq09u9JVJO/\nNdK414Yr+oG+urtFQ5X1L6OG99T//2O9dCbtrCRp1qrx8vbxVljlCqp/Vz11eKKt9n63T2sWXbol\n+Md7n5Uq7auXJjyv0LDyint2ogevvOQoMZNaGzdurMaNG2vPnj2qV69eccVUIvzr/Q+UnZOjx5/o\nrtzcPGVnX/h43qzpCg0NMTo8mMjJpGQNGjlWtarfqIXTJ8vHx0cVQkPUstk98vMrLUlq27qVFq1c\nbXCkKC7hVcMUHFpOe7/bJ0natH6r+o/sJf/Asso8lyVJSks+raMHj2v/nkRJ0leffKuBY2wKv6Gi\n7F52vTZ5eWE7p1RpX/n6+kiSBnYbIenSLRtJKuPvp98zz0uSQiuWV8qp05KkCpVCNGbOUB3+7agG\ndx9NC9FdLJSQXHZS69ixYwv/26VLl4seuDZvLl+s9atXau0byzXvlWkqVaqU1r6xnGQEV+RcRoZ6\nxQzV/ffdowmxQ+Tjc+GXxv3Nm2nzts+Uk5srp9OprV9sV706NxscLYpL+dByin15gAICL8whuv+h\n+3Rw/5HCZESSdn7+vcIqV1CtOtUlSbc2qiunUzp1LFnffvGDHu7aRl7eXrLZbBo09jk9PfDiyvif\np+E7HE59/ekutYt8QJJU4+YbVbVmFe3euUcBgWU1bfkYff7RDk0Z9irJCC7J5vzjvYP/JDU1VaGh\noTp+/PhfPlelSpUiB889l1bkMZBOnDypR6Oi9dUnm40O5bqXdy7d6BCuK0tWvaUFK97QTTWqF67U\nssmm+dMmak3Cu/rwk0/lcDpVN6KW4gb1Uxk/P2MDvs482ma40SF4TNvI1no4qo3y8/N1OuWM5oxf\nosDgAA0c/axeePzCDVLr3VFbvV6KVmm/0srNzdVrk5bp5x/2y8fXR71efEK331VPNrtdib8c0qzR\nCy6a1HopQeUDNWhMH1WqUlFOp0MLpr6u73f8pC69Oiq6b6QO7j9S2GJwOp0a1nPcRUmSVWz6aW2x\nnSt155duHS/0znvcOt6VuGxC8h+//PKLzp8/L7vdrhkzZqhPnz4u7dZKQgJ3IyGBO1k5IYFxSEiu\njktbx48ePVq+vr567bXXNGjQIM2ZM8fTcQEAgBLEpW0bfX19FRERoby8PDVo0EB2u8u3wAEAAJ5i\noUmtLiUkNptNQ4YMUfPmzbVx48bCiXMAAMA4JWbZ73/MnDlTP/74o1q0aKEdO3ZoxowZno4LAACU\nIC63bL766iutWrVK1atXV+3atT0dFwAAKIqFKiQuTQaJjY1V5cqVNWjQIFWpUkXDhg3zdFwAAKAI\nNrvNrQ8juVQhOXPmjKKjoyVJdevW1aZNmzwaFAAAKFlcqpDk5OQoJSVFkpSSknLRvQkAAACulUsV\nkoEDByoqKko+Pj7Ky8vTuHHjPB0XAAAoSkmbQ5KZmSmHwyEvLy85nU4VFHAfAgAA4D4uVUjmzZun\ndevWKSQkRKmpqerTp4+aNWvm6dgAAMDlWKhC4lJCUq5cOYWEXLgLbWhoqPz9/T0aFAAAKFqJ2xit\nbNmy6tGjh+68807t2bNH2dnZhZujxcTEeDRAAABgfS4lJK1bty78OCwszGPBAACAK2Dw3iHu5FJC\n0rFjR0/HAQAASjBu2wsAAAznUoUEAABcf2w269QVrHMlAADAtKiQAABgViVt2S8AALj+WGkfElo2\nAADAcFRIAAAwKwvtQ0KFBAAAGI6EBAAAGI6WDQAAJmWlSa0kJAAAmJWFEhJaNgAAwHBUSAAAMCsL\nbR1PQgIAgEnZWPYLAADgPiQkAADAcLRsAAAwK1bZAAAAuA8VEgAATIqN0QAAgPEstOzXOlcCAABM\niwoJAAAmxT4kAAAAbkRCAgAADEfLBgAAs2KVDQAAMJqVlv3SsgEAAIajQgIAgFmxDwkAAID7UCEB\nAMCs2IcEAADAfUhIAACA4WjZAABgUlZa9ktCAgCAWbHKBgAAwH2okAAAYFK0bAAAgPFo2QAAALgP\nCQkAADAcLRsAAEzKxk6tAAAA7kOFBAAAs2KVDQAAMJqNVTYAAADuQ4UEAACzslDLxuZ0Op1GBwEA\nAEo2WjYAAMBwJCQAAMBwJCQAAMBwJCQAAMBwJCQAAMBwJCQAAMBwJCQAAMBwJCTXoc2bNyslJUWp\nqakaO3as0eHAxE6ePKmtW7e6fHx0dLQOHjzowYhgRn/8WfTNN9/o119/lST179/fyLBgMSQk16EV\nK1YoMzNToaGhio+PNzocmNhXX32lXbt2GR0GTO6PP4veeecdJSUlSZJmz55tZFiwGLaOvwYJCQna\ntm2bsrOzdfToUfXq1Uu33HKLxo8fL0kqV66cJk6cKH9/f40ZM0Z79uxRSEiIjh07pgULFigrK0uT\nJ0+Ww+HQmTNnNHr0aJ09e1a//PKLhg4dqqlTp2ro0KEaO3asJkyYoNdff12S1KdPHw0cOFAZGRma\nOXOmvLy8dOONN2rs2LHy8vIy8lsCN3P1PbZ3716tWbNGM2bMkCQ1a9ZMn332mRYuXKicnBw1bNhQ\nS5cuVUhIiM6dO6fZs2drxIgRysjIUHJysrp166YuXboYeanwsISEBG3evFlZWVlKT09X37595e/v\nr1mzZqlUqVIKDg7WxIkTlZubq0GDBsnpdCo3N1ejR49WQECAYmJiFB8fr88++0x79+7VTTfdpMjI\nSL377rvq1q2bNm7cKEkaN26cmjZtqhtvvPGSPwuB/4WE5BplZmZq8eLFOnz4sPr06aOgoCBNmDBB\ntWrV0ttvv61Fixapfv36Onv2rNauXavTp0+rTZs2kqT9+/dr2LBhioiI0Hvvvaf169dr7NixqlOn\njsaNGycfHx/ZbDbVrl1bubm5OnnypLy9vZWenq46derowQcf1OrVq1W+fHm98sorWr9+vSIjIw3+\njsDdXHmP3XvvvbL96Z4WNptNvXv31sGDB9WyZUstXbpU7du3V+vWrbV3797Cj5OTkxUdHU1CUgJk\nZ2dr+fLlSktLU2RkpOx2u1avXq0KFSpo5cqVmjt3rpo0aaLg4GBNnTpV+/fv1/nz5xUQECCbzaZ6\n9erpvvvuU/v27RUeHi5JCg4OVp06dfTNN9+ofv36+vrrrxUXF6eoqChNnDjxovfpoEGDDP4O4HpG\nQnKN6tatK0kKDw9XTk6ODhw4oDFjxkiS8vPzVa1aNSUmJqpBgwaSpPLly6tGjRqSpLCwMM2dO1d+\nfn7KzMy86K+HP99iqFOnTkpISJCvr68effRRnT59WikpKRo4cKAkKScnR/fcc4/HrxfFz5X3mKv+\n894LCQnRihUr9OGHH6ps2bLKz893f+C47tx5552SLvz/L1OmjAoKClShQgVJUuPGjTVz5kwNHTpU\nhw4d0nPPPScfHx8999xzfxnnzz+fIiMjlZCQoJSUFLVq1Up2u/2a3qcomUhIrtGf/yqtWbOmpk6d\nqkqVKmnXrl1KTU1VqVKltGHDBj355JM6e/asDh06JEmaMGGCpk2bppo1a+rVV1/ViRMnJEl2u10O\nh0PSf//ht23bVt27d5fdbtfSpUvl5+en8PBwzZs3T/7+/tqyZYvKli1bfBeOYuPqeyw5OVmSdPz4\ncaWnpxd+7X/eS9KF95YkLVu2THfccYe6dOmiHTt2aNu2bcV0NTDSnj17JF2YpHr+/HnZbDalpKSo\nQoUK+vrrr1W9enXt2LFDFSpU0JIlS/T9999rxowZmjhxYuEYf35PSVLTpk318ssvKzk5uXCuyaXe\np8DlkJC4kc1m06hRozR48GAVFBTIbrdrwoQJqlatmrZt26aoqCiFhobKz89P3t7eevjhhzVgwAAF\nBQUpLCys8JfIHXfcUTh35D+/jMqUKaM6deqooKBAZcqUkSTFxcWpd+/ecjgcCggI0JQpUwy7dhSP\n//Ueu+GGGxQQEKDOnTurZs2aqlq1qiSpdu3aWrBggW655ZaLEpuWLVtq/Pjxev/99xUQECAfHx/l\n5ub+JfmBtaSkpKh79+7KzMzUmDFj5OXlpX79+slutyswMFCTJ0+WJMXExGj16tVyOBx64YUXLhrj\n9ttv1/Tp01WlSpWLXn/wwQe1ffv2wvfepd6nwOXYnH+uvcHtEhMT9csvv6ht27ZKT09X+/bttXXr\nVvn4+BgdGoASIiEhQQcPHlRMTIzRoQCXRIWkGISHh2vatGlasWKFHA6HBg8eTDICAMAfUCEBAACG\nY2M0AABgOBISAABgOBISAABgOBISAABgOBISAABguP8DowykjmvUlnsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1110bb0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test data\n",
    "\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "predicted_labels_LR2 = model_LR.predict(vocab_test_tf)\n",
    "print \"Test dataset with\", len(predicted_labels_LR2), \"sentences\"\n",
    "print \"\"\n",
    "\n",
    "print \"Data split - Negative, Neutral, Positive\"\n",
    "print \"----------------------------------------\"\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_predicted\",count_classes(0,predicted_labels_LR2), \n",
    "                                                     count_classes(1,predicted_labels_LR2),\n",
    "                                                     count_classes(2,predicted_labels_LR2))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_actual\",count_classes(0,test_labels), \n",
    "                                                     count_classes(1,test_labels),\n",
    "                                                     count_classes(2,test_labels))\n",
    "\n",
    "accuracy = model_LR.score(vocab_test_tf, test_labels)\n",
    "print \"\\nAccuracy\"\n",
    "print \"--------\"\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)\n",
    "\n",
    "print \"\\nClassification Report\"\n",
    "print \"---------------------\"\n",
    "print classification_report(test_labels, predicted_labels_LR2)\n",
    "\n",
    "\n",
    "print \"\\nConfusion matrix for test data\"\n",
    "print \"------------------------------\"\n",
    "\n",
    "array = confusion_matrix(test_labels, predicted_labels_LR2)\n",
    "df_cm = pd.DataFrame(array, index = [\"negative\", \"neutral\", \"positive\"],\n",
    "                  columns = [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "\n",
    "# Find the most confused pair\n",
    "cm3 = confusion_matrix(test_labels, predicted_labels_LR2)  # copy the cm matrix so that can modify the copy without affecting original cm\n",
    "np.fill_diagonal(cm3, 0)  # set the values in the diagonal = 0 to obtain number of confused pairs matrix\n",
    "maximum_pair_idx = np.where(cm3 == cm3.max())  # returns the indices of the max value in cm matrix\n",
    "true_interaction = maximum_pair_idx[0][0]\n",
    "predicted_interaction = maximum_pair_idx[1][0]\n",
    "max_wrong_prediction = cm3[true_interaction][predicted_interaction]\n",
    "print \"The most confused pair of classes is:\", true_interaction, \"(\", classes_dict[true_interaction],\")\",\\\n",
    "\" incorrectly predicted as\", predicted_interaction, \"(\", classes_dict[predicted_interaction],\")\"\n",
    "print \"Number of such confusion occurences:\", max_wrong_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Words with the highest weights per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 ( negative )\n",
      "1 weight: 8.383 for feature \" induced \"\n",
      "2 weight: 7.360 for feature \" hepatotoxicity \"\n",
      "3 weight: 7.242 for feature \" inhibited \"\n",
      "4 weight: 6.935 for feature \" metabolism \"\n",
      "5 weight: 6.860 for feature \" acetylneuraminic \"\n",
      "6 weight: 6.381 for feature \" inhibit \"\n",
      "7 weight: 6.363 for feature \" nicotine \"\n",
      "8 weight: 6.144 for feature \" stimulated \"\n",
      "9 weight: 6.017 for feature \" reduce \"\n",
      "10 weight: 5.950 for feature \" capsaicin \"\n",
      "Class 1 ( neutral )\n",
      "1 weight: 9.064 for feature \" study \"\n",
      "2 weight: 7.298 for feature \" on \"\n",
      "3 weight: 7.073 for feature \" investigated \"\n",
      "4 weight: 6.316 for feature \" no \"\n",
      "5 weight: 5.741 for feature \" were \"\n",
      "6 weight: 5.448 for feature \" we \"\n",
      "7 weight: 5.370 for feature \" nitrite \"\n",
      "8 weight: 5.177 for feature \" oxygen \"\n",
      "9 weight: 5.042 for feature \" mouse \"\n",
      "10 weight: 4.850 for feature \" examined \"\n",
      "Class 2 ( positive )\n",
      "1 weight: 8.692 for feature \" inhibitory \"\n",
      "2 weight: 7.158 for feature \" lovastatin \"\n",
      "3 weight: 6.737 for feature \" diabetic \"\n",
      "4 weight: 6.476 for feature \" increase \"\n",
      "5 weight: 6.444 for feature \" red \"\n",
      "6 weight: 6.426 for feature \" increased \"\n",
      "7 weight: 6.090 for feature \" increasing \"\n",
      "8 weight: 6.045 for feature \" enhanced \"\n",
      "9 weight: 5.982 for feature \" aa \"\n",
      "10 weight: 5.840 for feature \" previous \"\n",
      "\n",
      "Table of weights for each feature for each of the 3 labels:\n",
      "\n",
      "                                negative             neutral            positive\n",
      "             induced               8.383              -4.191              -5.832\n",
      "      hepatotoxicity               7.360              -4.820              -5.362\n",
      "           inhibited               7.242              -5.253              -2.373\n",
      "          metabolism               6.935              -0.977              -6.621\n",
      "    acetylneuraminic               6.860              -2.943              -4.337\n",
      "             inhibit               6.381              -7.422               0.759\n",
      "            nicotine               6.363              -2.132              -4.219\n",
      "          stimulated               6.144              -4.408              -1.951\n",
      "              reduce               6.017              -4.449              -1.307\n",
      "           capsaicin               5.950              -4.037              -2.794\n",
      "               study              -6.534               9.064              -5.261\n",
      "                  on              -1.502               7.298              -6.558\n",
      "        investigated              -2.681               7.073              -8.362\n",
      "                  no               0.357               6.316              -6.858\n",
      "                were              -4.552               5.741              -2.938\n",
      "                  we              -2.637               5.448              -4.441\n",
      "             nitrite              -1.539               5.370              -3.592\n",
      "              oxygen              -1.869               5.177              -2.554\n",
      "               mouse              -2.255               5.042              -2.770\n",
      "            examined              -2.538               4.850              -2.425\n",
      "          inhibitory              -1.004              -9.324               8.692\n",
      "          lovastatin              -2.194              -5.261               7.158\n",
      "            diabetic              -3.964              -3.502               6.737\n",
      "            increase              -2.666              -4.608               6.476\n",
      "                 red              -1.260              -5.047               6.444\n",
      "           increased               1.030              -7.752               6.426\n",
      "          increasing              -1.973              -4.655               6.090\n",
      "            enhanced               0.635              -6.639               6.045\n",
      "                  aa              -2.278              -3.641               5.982\n",
      "            previous              -2.031              -3.812               5.840\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train = vectorizer.fit_transform(train_data)\n",
    "vocab_dev = vectorizer.transform(dev_data)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "model_LR = LogisticRegression(C=50)\n",
    "model_LR.fit(vocab_train, train_labels)\n",
    "predicted_labels_LR = model_LR.predict(vocab_dev)\n",
    "\n",
    "weights = model_LR.coef_   # weight vector for each label\n",
    "top30_features_index = []  # list of 30 features (10 words with the largest weights for each label)\n",
    "class_list = ['negative', 'neutral', 'positive']\n",
    "\n",
    "for i in range(3):  # 4 labels\n",
    "    weights_label_i = list(weights[i])  # list of weights for label i\n",
    "    top10_weights_label_i = sorted(weights_label_i, reverse=True)[0:10]  # sort and filter greatest 10 weights\n",
    "    top10_features_index_i = [weights_label_i.index(weight) \\\n",
    "                             for weight in top10_weights_label_i]  # find index of top 10\n",
    "    top10_features_i = [feature_names[index] for index in top10_features_index_i]  # list of features of top 10 weights\n",
    "    top30_features_index += top10_features_index_i  # add the top 10 weigths index of label i to the list of 30\n",
    "\n",
    "    # Print top 5 features per label\n",
    "    print \"Class\", i, \"(\", class_list[i] , \")\"\n",
    "    for index, (weight, feature) in enumerate(zip(top10_weights_label_i,top10_features_i), start = 1):\n",
    "        print index, \"weight: %.3f\" %(weight), \"for feature \\\"\", feature, \"\\\"\"\n",
    "\n",
    "top30_features = [feature_names[index] for index in top30_features_index]  # list of features of top 20 weights\n",
    "\n",
    "# Formatting weights for each class for printing table of results\n",
    "top30_w_class0 = [\"%.3f\" %(list(weights[0])[index]) for index in top30_features_index]\n",
    "top30_w_class1 = [\"%.3f\" %(list(weights[1])[index]) for index in top30_features_index]\n",
    "top30_w_class2 = [\"%.3f\" %(list(weights[2])[index]) for index in top30_features_index]\n",
    "\n",
    "\n",
    "\n",
    "weights_array = np.column_stack((top30_w_class0, top30_w_class1, top30_w_class2))\n",
    "\n",
    "# Print table of weights for the 20 top features\n",
    "print \"\\nTable of weights for each feature for each of the 3 labels:\\n\"\n",
    "row_format =\"{:>20}\" * (len(class_list) + 1)\n",
    "print row_format.format(\"\", *class_list)\n",
    "for feature, weights in zip(top30_features, weights_array):\n",
    "    print row_format.format(feature, *weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Observations **  \n",
    "**BEFORE** bootstrapping:\n",
    "1. Some neutral prediction words seem promising, in particular, \"study\", \"investigated\", \"studied\"\n",
    "2. Some negative and positive prediciton words seem helpful\n",
    "3. Main weakness of the model: this is a bag of word model with feature based on tf-idf. Thus, a drug name or food compound can also result with an important weight to predict a class and this is misleading. For example, \"monoamine\" has a high weight for class \"positive\" based on the positive labels of sentences containing this word. Thus, even if we will add a sentence with a negative interaction between monoamine and a food compound, the BOW model will predict a positive label. The proportion of labels for a drug-food interaction sentences in the training will affect how the model will retain those drugs or food compounds as predictors of positive/negative/neutral. \n",
    "\n",
    "**AFTER** bootstrapping:\n",
    "similar to above but seems to have less drug and food related words with high weight for predicting label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. R-ratio analysis - look at individual sentences with highest errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R is equal to maximum predicted probability divided by predicted probability of the correct label.  \n",
    "In other words, it looks how \"far\" the prediction of a class is from the true class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 sentences where the ratio R is largest:\n",
      "\n",
      "                         ratio R     Max pred Pr      Correct Pr Predicted label      True label       Doc Index\n",
      "       Highest R          470.47           0.973           0.002             1.0             0.0           553.0\n",
      "     2nd highest          470.47           0.973           0.002             1.0             0.0          1026.0\n",
      "     3rd highest         382.687           0.786           0.002             2.0             1.0           645.0\n",
      "             4th         307.791           0.694           0.002             0.0             1.0           451.0\n",
      "             5th         166.621           0.558           0.003             2.0             1.0           450.0\n",
      "             6th         161.567           0.984           0.006             1.0             2.0           511.0\n",
      "             7th         161.567           0.984           0.006             1.0             2.0           958.0\n",
      "             8th         145.674           0.989           0.007             2.0             1.0           800.0\n",
      "             9th         110.845           0.916           0.008             2.0             1.0           735.0\n",
      "            10th          88.652           0.872            0.01             1.0             0.0           264.0\n",
      "\n",
      "Sentences:\n",
      "\n",
      "1) Sentence with ratio R = 470.470 :\n",
      "Activated carbon (AC)/CoFe2O4 nanocomposites, MAC-1 and MAC-2, were prepared by a simple pyrolytic method using a mixture of iron(III)/cobalt(II) benzoates and iron(III)/cobalt(II) oxalates, respectively, and were used as efficient adsorbents for the removal of amoxicillin (AMX) and paracetamol (PCT) of aqueous effluents.\n",
      "\n",
      "2) Sentence with ratio R = 470.470 :\n",
      "Activated carbon (AC)/CoFe2O4 nanocomposites, MAC-1 and MAC-2, were prepared by a simple pyrolytic method using a mixture of iron(III)/cobalt(II) benzoates and iron(III)/cobalt(II) oxalates, respectively, and were used as efficient adsorbents for the removal of amoxicillin (AMX) and paracetamol (PCT) of aqueous effluents.\n",
      "\n",
      "3) Sentence with ratio R = 382.687 :\n",
      "Taken together, our study showed that osthole improved survival rate and attenuated LPS-induced ALI and ACE2 may play a role in it.\"\n",
      "\n",
      "4) Sentence with ratio R = 307.791 :\n",
      "Results indicated that milk and buttermilk did not aggravate or protect against duodenal injury, while antacid and prostaglandin did significantly protect against inflammation (P less than 0.02).\n",
      "\n",
      "5) Sentence with ratio R = 166.621 :\n",
      "The results indicate that the hypolipidemic effect of garlic is probably not mediated through the thyroid.\n",
      "\n",
      "6) Sentence with ratio R = 161.567 :\n",
      "We developed a diagnostic assay based upon color transformations of polydiacetylene, a unique conjugated polymer, upon interactions with blood plasma obtained from healthy individuals, hypercholesterolemic patients, hypercholesterolemic patients treated with statin, and hypercholesterolemic patients treated with statin together with pomegranate extracts.\n",
      "\n",
      "7) Sentence with ratio R = 161.567 :\n",
      "We developed a diagnostic assay based upon color transformations of polydiacetylene, a unique conjugated polymer, upon interactions with blood plasma obtained from healthy individuals, hypercholesterolemic patients, hypercholesterolemic patients treated with statin, and hypercholesterolemic patients treated with statin together with pomegranate extracts.\n",
      "\n",
      "8) Sentence with ratio R = 145.674 :\n",
      "Our current work utilised in silico methodologies and peptide databases as tools for predicting release of ACE-I inhibitory peptides from barley proteins.\n",
      "\n",
      "9) Sentence with ratio R = 110.845 :\n",
      "Ritobegron may increase the plasma concentrations of P-glycoprotein substrates, such as digoxin, and the plasma concentration of KUC-7322 may increase when it is administered in combination with OAT inhibitors such as probenecid.\\\n",
      "\n",
      "10) Sentence with ratio R = 88.652 :\n",
      "Grapefruit juice lowered the oral bioavailability of several medications transported by OATP1A2 (acebutolol, celiprolol, fexofenadine, talinolol, L-thyroxine) while orange juice did the same for others (atenolol, celiprolol, ciprofloxacin, fexofenadine).\n",
      "\n",
      "Sentence 1 (example number 553 ):\n",
      "Influential word: were with magnitude: 0.905825902057\n",
      "Influential word: iii with magnitude: 0.89193173933\n",
      "Influential word: method with magnitude: 0.53432399211\n",
      "Influential word: using with magnitude: 0.474114982861\n",
      "Influential word: used with magnitude: 0.47368980094\n",
      "\n",
      "Sentence 2 (example number 1026 ):\n",
      "Influential word: were with magnitude: 0.905825902057\n",
      "Influential word: iii with magnitude: 0.89193173933\n",
      "Influential word: method with magnitude: 0.53432399211\n",
      "Influential word: using with magnitude: 0.474114982861\n",
      "Influential word: used with magnitude: 0.47368980094\n",
      "\n",
      "Sentence 3 (example number 645 ):\n",
      "Influential word: improved with magnitude: 1.39354280481\n",
      "Influential word: osthole with magnitude: 0.986809301663\n",
      "Influential word: showed with magnitude: 0.877836145099\n",
      "Influential word: ali with magnitude: 0.796235254639\n",
      "Influential word: play with magnitude: 0.742645831395\n",
      "\n",
      "Sentence 4 (example number 451 ):\n",
      "Influential word: protect with magnitude: 1.92768740625\n",
      "Influential word: against with magnitude: 1.86666799307\n",
      "Influential word: while with magnitude: 0.629725583599\n",
      "Influential word: significantly with magnitude: 0.472317767904\n",
      "Influential word: that with magnitude: 0.454677823641\n",
      "\n",
      "Sentence 5 (example number 450 ):\n",
      "Influential word: that with magnitude: 0.766380186537\n",
      "Influential word: the with magnitude: 0.736107462889\n",
      "Influential word: results with magnitude: 0.725104847495\n",
      "Influential word: through with magnitude: 0.660828367363\n",
      "Influential word: hypolipidemic with magnitude: 0.509254878332\n",
      "\n",
      "Sentence 6 (example number 511 ):\n",
      "Influential word: patients with magnitude: 1.47715872361\n",
      "Influential word: hypercholesterolemic with magnitude: 0.817703404898\n",
      "Influential word: assay with magnitude: 0.502077921855\n",
      "Influential word: we with magnitude: 0.45272133409\n",
      "Influential word: pomegranate with magnitude: 0.307398366888\n",
      "\n",
      "Sentence 7 (example number 958 ):\n",
      "Influential word: patients with magnitude: 1.47715872361\n",
      "Influential word: hypercholesterolemic with magnitude: 0.817703404898\n",
      "Influential word: assay with magnitude: 0.502077921855\n",
      "Influential word: we with magnitude: 0.45272133409\n",
      "Influential word: pomegranate with magnitude: 0.307398366888\n",
      "\n",
      "Sentence 8 (example number 800 ):\n",
      "Influential word: inhibitory with magnitude: 1.67410262844\n",
      "Influential word: peptides with magnitude: 1.02435117891\n",
      "Influential word: release with magnitude: 0.957130194602\n",
      "Influential word: work with magnitude: 0.879821854914\n",
      "Influential word: ace with magnitude: 0.82863606206\n",
      "\n",
      "Sentence 9 (example number 735 ):\n",
      "Influential word: increase with magnitude: 2.09232664481\n",
      "Influential word: may with magnitude: 1.03015543\n",
      "Influential word: combination with magnitude: 0.718479739808\n",
      "Influential word: as with magnitude: 0.498866950003\n",
      "Influential word: concentrations with magnitude: 0.491114434607\n",
      "\n",
      "Sentence 10 (example number 264 ):\n",
      "Influential word: fexofenadine with magnitude: 0.420020690362\n",
      "Influential word: others with magnitude: 0.40184051148\n",
      "Influential word: did with magnitude: 0.378275584616\n",
      "Influential word: several with magnitude: 0.34489190945\n",
      "Influential word: orange with magnitude: 0.247172804628\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_dev_tf = vectorizer.transform(dev_data)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Logistic regression model with C=50\n",
    "model_LR = LogisticRegression(C=50)\n",
    "model_LR.fit(vocab_train_tf, train_labels)\n",
    "predicted_labels_LR = model_LR.predict(vocab_dev_tf)\n",
    "\n",
    "#feature_names = vectorizer.get_feature_names()\n",
    "#print \"features names length:\", len(feature_names)\n",
    "\n",
    "    \n",
    "# Variables to calculate R\n",
    "probabilities = model_LR.predict_proba(vocab_dev_tf)  # Each label probability (4) for each document\n",
    "proba_max = probabilities.max(axis=1)  # Maximum predicted probability\n",
    "proba_correct_label = [probabilities[i][dev_labels[i]] \\\n",
    "                       for i in range(probabilities.shape[0])]  # Predicted prob of the correct label\n",
    "r_ratio = proba_max/proba_correct_label  # R = maximum predicted prob / predicted prob of the correct label\n",
    "sentence_index = [i for i in range(probabilities.shape[0])]  # Index of the document to retrace once sorted by R\n",
    "\n",
    "# Results array with 5 columns (R, max prob, prob of correct label, predicted labels, true labels,\n",
    "# document index)\n",
    "results = np.column_stack((r_ratio, proba_max, proba_correct_label, predicted_labels_LR, \\\n",
    "                           dev_labels, sentence_index))\n",
    "results_max3r = sorted(results, key=lambda x: x[0], reverse=True)[:10]  # top 10 sentences with highest R\n",
    "\n",
    "\n",
    "# Format and print top 3 documents with highest R:\n",
    "# 1) print top 10 sentences related info - probabilities, predicted/correct labels, etc.\n",
    "print \"\\nTop 10 sentences where the ratio R is largest:\\n\"\n",
    "column_names = [\"ratio R\", \"Max pred Pr\", \"Correct Pr\", \"Predicted label\", \"True label\", \\\n",
    "                \"Doc Index\"]\n",
    "row_format =\"{:>16}\" * (len(column_names)+1)\n",
    "print row_format.format(\"\", *column_names)\n",
    "top_10 = [\"Highest R\", \"2nd highest\", \"3rd highest\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \"10th\"]\n",
    "for index, row in zip(top_10, results_max3r):\n",
    "    row = [round(item,3) for item in row]\n",
    "    print row_format.format(index, *row)\n",
    "\n",
    "# 2) print top 3 R documents messages\n",
    "print \"\\nSentences:\"\n",
    "i = 1\n",
    "for row in results_max3r:\n",
    "    print \"\\n\" + str(i) +\") Sentence with ratio R = %.3f\" %(row[0]), \":\"\n",
    "    print dev_data[int(row[5])]\n",
    "    i +=1  \n",
    "\n",
    "\n",
    "# Diagnosis of influential words in the 3 documents with highest R\n",
    "weights = model_LR.coef_\n",
    "sentence_list = [int(result[5]) for result in results_max3r]\n",
    "j=1\n",
    "\n",
    "for example in sentence_list:\n",
    "    predicted_label = predicted_labels_LR[example]\n",
    "    indices = vocab_dev_tf[example].indices  # list of indices of non zero features of document\n",
    "    vocab_freq = vocab_dev_tf[example].data  # list of features values of document\n",
    "    weights_example = [weights[predicted_label][index] for index in indices]  # list of LR weights \n",
    "                                                                              # for non zero features of doc\n",
    "    feature_importance = vocab_freq * weights_example  # feature value x weight for total influence on prediction\n",
    "\n",
    "    features_array = np.column_stack((feature_importance, indices))\n",
    "    features_sorted = sorted(features_array, key=lambda x: x[0], reverse=True)  # Sort words by influence\n",
    "\n",
    "    # Print top 5 features (words) of the document with heaviest weight x value\n",
    "    \n",
    "    print \"\\nSentence\", j,  \"(example number\", example, \"):\"\n",
    "    for i in range(5):\n",
    "        index = int(features_sorted[i][1])\n",
    "        print \"Influential word:\", feature_names[index] ,\"with magnitude:\", features_sorted[i][0]\n",
    "    j +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 1. Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def empty_preprocessor(s):\n",
    "    return s\n",
    "\n",
    "def better_preprocessor(s):\n",
    "    #s = s.lower()  # to lowercase all letters in the string\n",
    "    #s = re.sub(\"[^a-zA-Z0-9]\", \" \", s) # to remove non-letter and non-numerical characters\n",
    "    #s = re.sub ('\\d+', \" numsequence \",s)  # replace sequences of numbers with a single token\n",
    "    \n",
    "    pronoun_list = ['you', 'he', 'she', 'we', 'they', 'me', 'him', 'his', 'her', 'hers', 'yours', 'us', 'our'\\\n",
    "                   'ours', 'their', 'theirs']  # list of pronouns as stopwords since not informative for prediciton\n",
    "    for word in pronoun_list:\n",
    "        s = re.sub(r'\\b%s\\b' % word, \" \",s)  # to remove stopwords in the list\n",
    "        \n",
    "    nothelping = ['or', 'to', 'of', 'a', 'on', 'the']\n",
    "    for word in nothelping:\n",
    "        s = re.sub(r'\\b%s\\b' % word, \" \",s)  # to remove stopwords in the list\n",
    "        \n",
    "    #s = re.sub(r'ly\\b', \"\",s)   # to remove \"ly\" from words ending by \"ly\"\n",
    "    s = re.sub(r'ing\\b', \"\",s)  # to remove \"ing\" from words ending by \"ing\"\n",
    "    #s = re.sub(r's\\b', \"\",s)    # to remove \"s\" from words ending by \"s\"\n",
    "    \n",
    "    for word in s.split():  # to shorten words longer than 15 characters (from histogram, most words < 15)\n",
    "        if len(word)>15:\n",
    "            short_word = word[:15]\n",
    "            s = s.replace(word,short_word)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary with no preprocessor: 8141\n",
      "accuracy with no custom preprocessor is: 0.884\n",
      "\n",
      "Size of vocabulary with custom preprocessor: 8727\n",
      "accuracy with custom preprocessor is: 0.880\n"
     ]
    }
   ],
   "source": [
    "# No preprocessor\n",
    "vectorizer_initial = TfidfVectorizer()\n",
    "vocab_train_initial = vectorizer_initial.fit_transform(train_data)\n",
    "vocab_test_initial = vectorizer_initial.transform(test_data)\n",
    "count_features_init = len(vectorizer_initial.get_feature_names())\n",
    "print \"Size of vocabulary with no preprocessor:\", count_features_init\n",
    "\n",
    "model_LR_initial = LogisticRegression(C=50)\n",
    "model_LR_initial.fit(vocab_train_initial, train_labels)\n",
    "predicted_labels_initial = model_LR_initial.predict(vocab_test_initial)\n",
    "accuracy_initial = model_LR_initial.score(vocab_test_initial, test_labels)\n",
    "print \"accuracy with no custom preprocessor is: %.3f\" %(accuracy_initial)\n",
    "print \"\"\n",
    "\n",
    "\n",
    "# With preprocessor\n",
    "vectorizer_better = TfidfVectorizer(preprocessor=better_preprocessor)\n",
    "vocab_train_better = vectorizer_better.fit_transform(train_data)\n",
    "vocab_test_better = vectorizer_better.transform(test_data)\n",
    "\n",
    "count_features_better = len(vectorizer_better.get_feature_names())\n",
    "print \"Size of vocabulary with custom preprocessor:\", count_features_better\n",
    "\n",
    "model_LR_better = LogisticRegression(C=50)\n",
    "model_LR_better.fit(vocab_train_better, train_labels)\n",
    "predicted_labels_better = model_LR_better.predict(vocab_test_better)\n",
    "accuracy_better = model_LR_better.score(vocab_test_better, test_labels)\n",
    "print \"accuracy with custom preprocessor is: %.3f\" %(accuracy_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. N-grams instead of unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (dev data): 0.886\n",
      "Accuracy (test data): 0.886\n"
     ]
    }
   ],
   "source": [
    "# Turn the raw training text into feature vectors based on \"td-idf\"\n",
    "vectorizer = TfidfVectorizer(analyzer='word' , ngram_range=(4,5), preprocessor=better_preprocessor)\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_dev_tf = vectorizer.transform(dev_data)\n",
    "\n",
    "# Logistic regression model with C=50\n",
    "model_LR = LogisticRegression(C=50)\n",
    "model_LR.fit(vocab_train_tf, train_labels)\n",
    "predicted_labels_LR_ngram = model_LR.predict(vocab_dev_tf)\n",
    "\n",
    "accuracy = model_LR.score(vocab_dev_tf, dev_labels)\n",
    "print \"Accuracy (dev data): %.3f\" %(accuracy)\n",
    "\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "predicted_labels_LR_ngram2 = model_LR.predict(vocab_test_tf)\n",
    "accuracy = model_LR.score(vocab_test_tf, test_labels)\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_dev_tf = vectorizer.transform(dev_data)\n",
    "vocab_test_tf = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Support Vector Machine model ...\n",
      "Performing grid search for Support Vector Machine model. It may take a few minutes ...\n",
      "Support Vector Machines grid search model fitting time = 41.158077 seconds.\n",
      "As per the grid search on the training data, the optimal value of C = 0.000100.\n",
      "Support Vector Machines prediction time for dev data = 0.632714 seconds.\n",
      "Accuracy on dev data for Support Vector Machine is = 0.336417\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       387\n",
      "          1       0.34      1.00      0.50       400\n",
      "          2       0.00      0.00      0.00       402\n",
      "\n",
      "avg / total       0.11      0.34      0.17      1189\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Support Vector Machines:\n",
    "print \"Evaluating Support Vector Machine model ...\"\n",
    "\n",
    "# Create a Support Vector Machine model. \n",
    "SVMmodel = SVC(C=1.0)\n",
    "\n",
    "# Create a grid search.\n",
    "print \"Performing grid search for Support Vector Machine model. It may take a few minutes ...\"\n",
    "Cs = {'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0]}\n",
    "CV_SVMmodel = GridSearchCV(estimator=SVMmodel, param_grid=Cs)\n",
    "\n",
    "# Fit the models using grid search and display the results.\n",
    "start_time = time.time()\n",
    "CV_SVMmodel.fit(vocab_train_tf, train_labels)\n",
    "end_time = time.time()\n",
    "print \"Support Vector Machines grid search model fitting time = %f seconds.\" % (end_time - start_time)\n",
    "\n",
    "optimal_Cs = CV_SVMmodel.best_params_['C']\n",
    "print \"As per the grid search on the training data, the optimal value of C = %f.\" % optimal_Cs\n",
    "\n",
    "# Predict labels for dev data and calculate accuracy using optimal C\n",
    "start_time = time.time()\n",
    "SVMmodel = CV_SVMmodel.predict(vocab_dev_tf)\n",
    "end_time = time.time()\n",
    "print \"Support Vector Machines prediction time for dev data = %f seconds.\" % (end_time - start_time)\n",
    "\n",
    "# Print goodness of fit measures\n",
    "print \"Accuracy on dev data for Support Vector Machine is = %f\" % CV_SVMmodel.score(vocab_dev_tf, dev_labels)\n",
    "print \"Classification Report\\n\", classification_report(dev_labels, SVMmodel)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model\n",
      "Accuracy (dev data): 0.336\n",
      "Test dataset with 1189 sentences\n",
      "Accuracy (test data): 0.326\n",
      "        dataset |       negative |        neutral |       positive\n",
      " test_predicted |       0.000000 |    1189.000000 |       0.000000\n",
      "    test_actual |     414.000000 |     388.000000 |     387.000000\n",
      "Confusion matrix for test data\n",
      "The most confused pair of classes is: 0 ( negative )  incorrectly predicted as 1 ( neutral )\n",
      "Number of such confusion occurences: 414\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGkCAYAAAABqz41AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQgIAAExHQgIAAEz3/wEQT6waPsiMsgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111425ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Turn the raw training text into feature vectors based on \"td-idf\"\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "#vocab_dev_tf = vectorizer.transform(dev_data)\n",
    "\n",
    "# SVM model\n",
    "model_SVM = SVC(C=0.0001)\n",
    "model_SVM.fit(vocab_train_tf, train_labels)\n",
    "predicted_labels_SVM = model_SVM.predict(vocab_dev_tf)\n",
    "\n",
    "# DEV\n",
    "print \"SVM model\"\n",
    "accuracy = model_SVM.score(vocab_dev_tf, dev_labels)\n",
    "print \"Accuracy (dev data): %.3f\" %(accuracy)\n",
    "\n",
    "# TEST\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "predicted_labels_SVM2 = model_SVM.predict(vocab_test_tf)\n",
    "print \"Test dataset with\", len(predicted_labels_SVM2), \"sentences\"\n",
    "accuracy = model_SVM.score(vocab_test_tf, test_labels)\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)\n",
    "\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_predicted\",count_classes(0,predicted_labels_SVM2), \n",
    "                                                     count_classes(1,predicted_labels_SVM2),\n",
    "                                                     count_classes(2,predicted_labels_SVM2))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_actual\",count_classes(0,test_labels), \n",
    "                                                     count_classes(1,test_labels),\n",
    "                                                     count_classes(2,test_labels))\n",
    "\n",
    "print \"Confusion matrix for test data\"\n",
    "\n",
    "array = confusion_matrix(test_labels, predicted_labels_SVM2)\n",
    "df_cm = pd.DataFrame(array, index = [\"negative\", \"neutral\", \"positive\"],\n",
    "                  columns = [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "\n",
    "# Find the most confused pair\n",
    "cm3 = confusion_matrix(test_labels, predicted_labels_SVM2)  # copy the cm matrix so that can modify the copy without affecting original cm\n",
    "np.fill_diagonal(cm3, 0)  # set the values in the diagonal = 0 to obtain number of confused pairs matrix\n",
    "maximum_pair_idx = np.where(cm3 == cm3.max())  # returns the indices of the max value in cm matrix\n",
    "true_interaction = maximum_pair_idx[0][0]\n",
    "predicted_interaction = maximum_pair_idx[1][0]\n",
    "max_wrong_prediction = cm3[true_interaction][predicted_interaction]\n",
    "print \"The most confused pair of classes is:\", true_interaction, \"(\", classes_dict[true_interaction],\")\",\\\n",
    "\" incorrectly predicted as\", predicted_interaction, \"(\", classes_dict[predicted_interaction],\")\"\n",
    "print \"Number of such confusion occurences:\", max_wrong_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
