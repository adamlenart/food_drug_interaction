{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import time\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_alpha</th>\n",
       "      <th>Label_num</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Food</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>pentadecanoic acid</td>\n",
       "      <td>(123)iodine labelled beta-methyl-iodophenyl pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>2-phenylethanol</td>\n",
       "      <td>2-Phenylethanol is a widely used aroma compoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>3,4-dihydroxyphenylacetic acid</td>\n",
       "      <td>3,4-dihydroxyphenylacetic acid and 4-methylcat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>arachin</td>\n",
       "      <td>A 96-well microplate format of this method was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td>diethylamine</td>\n",
       "      <td>A biochemical study was performed in order to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label_alpha  Label_num           Drug                            Food  \\\n",
       "ID                                                                          \n",
       "400     neutral          1  ACE inhibitor              pentadecanoic acid   \n",
       "333    positive          2  ACE inhibitor                 2-phenylethanol   \n",
       "77     positive          2  ACE inhibitor  3,4-dihydroxyphenylacetic acid   \n",
       "338     neutral          1  ACE inhibitor                         arachin   \n",
       "214     neutral          1  ACE inhibitor                    diethylamine   \n",
       "\n",
       "                                              sentence  \n",
       "ID                                                      \n",
       "400  (123)iodine labelled beta-methyl-iodophenyl pe...  \n",
       "333  2-Phenylethanol is a widely used aroma compoun...  \n",
       "77   3,4-dihydroxyphenylacetic acid and 4-methylcat...  \n",
       "338  A 96-well microplate format of this method was...  \n",
       "214  A biochemical study was performed in order to ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../labeled_dataAll.csv\", index_col='ID')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly shuffle the data. Use same random seed to get same results every time. \n",
    "df_shuffle = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "# Separate labels\n",
    "labels = [i for i in df_shuffle.Label_num]\n",
    "labels = np.array(labels)\n",
    "n = len(labels)\n",
    "\n",
    "# Drop unecessary columns from input data\n",
    "df_shuffle.drop('Label_alpha', axis=1, inplace=True)\n",
    "df_shuffle.drop('Label_num', axis=1, inplace=True)\n",
    "df_shuffle.drop('Drug', axis=1, inplace=True)\n",
    "df_shuffle.drop('Food', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Split the train data into training and dev datasets\n",
    "train_data =  df_shuffle[:n/2].sentence.tolist()\n",
    "dev_data = df_shuffle[n/2: 3*n/4].sentence.tolist()\n",
    "test_data = df_shuffle[3*n/4:].sentence.tolist()\n",
    "\n",
    "# Separate training and dev labels\n",
    "train_labels =  labels[:n/2]\n",
    "dev_labels = labels[n/2: 3*n/4]\n",
    "test_labels = labels[3*n/4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training label shape: (1235,)\n",
      "test label shape: (618,)\n",
      "dev label shape: (618,)\n"
     ]
    }
   ],
   "source": [
    "print 'training label shape:', train_labels.shape\n",
    "print 'test label shape:', test_labels.shape\n",
    "print 'dev label shape:', dev_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['negative', 'neutral', 'positive'] # corresponding labels = 0, 1, 2\n",
    "classes_dict = {0:'negative', 1:'neutral', 2:'positive'} # corresponding labels = 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_classes(value, labels):\n",
    "    return len([i for i in labels if i == value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split among Negative, Neutral and Positive\n",
      "        dataset |       negative |        neutral |       positive\n",
      "          train |     176.000000 |     795.000000 |     264.000000\n",
      "            dev |      79.000000 |     397.000000 |     142.000000\n",
      "           test |     104.000000 |     389.000000 |     125.000000\n"
     ]
    }
   ],
   "source": [
    "# Check number of classes per train/dev/test dataset:\n",
    "print \"Dataset split among Negative, Neutral and Positive\"\n",
    "\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"train\",count_classes(0,train_labels), \n",
    "                                                     count_classes(1,train_labels),\n",
    "                                                     count_classes(2,train_labels))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev\",count_classes(0,dev_labels), \n",
    "                                                     count_classes(1,dev_labels),\n",
    "                                                     count_classes(2,dev_labels))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test\",count_classes(0,test_labels), \n",
    "                                                     count_classes(1,test_labels),\n",
    "                                                     count_classes(2,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example 1\n",
      "Label 0 ( negative )\n",
      "Sentence:\n",
      "Muscle content of malonyl-CoA was elevated in PTU-treated rats and depressed in thyroid hormone-treated rats. \n",
      "\n",
      "\n",
      "Training example 2\n",
      "Label 0 ( negative )\n",
      "Sentence:\n",
      "Phytoremediation of selected pharmaceuticals (diclofenac, ibuprofen, and acetaminophen) using Armoracia rusticana and Linum usitatissimum cell cultures and by hydroponically cultivated Lupinus albus, Hordeum vulgaris, and Phragmites australis plants in laboratory conditions is described. \n",
      "\n",
      "\n",
      "Training example 3\n",
      "Label 1 ( neutral )\n",
      "Sentence:\n",
      "The data generated in the current work provide the basic information on the effect of bivalent cations, namely, Ca2+, Zn2+ and Mn2+, on the HPMMs' solubility and, consequently, on the performances (disintegration and drug dissolution) of acetaminophen gastroresistant tablets when exposed to fluid containing such salts. \n",
      "\n",
      "\n",
      "Training example 4\n",
      "Label 1 ( neutral )\n",
      "Sentence:\n",
      "Initial studies using different substrates (serotonin, 5-hydroxytryptophol, 4-nitrophenol, acetaminophen, and valproic acid) showed similar results with 2-fold higher glucuronidation by UGT1A6(*)2 (S7A/T181A/R184S) compared with UGT1A6(*)1 (reference), and intermediate activities for other variants. \n",
      "\n",
      "\n",
      "Training example 5\n",
      "Label 1 ( neutral )\n",
      "Sentence:\n",
      "The aim of the present study was to clarify whether waterborne exposure to a selected statin, atorvastatin, would affect gene expression in rainbow trout (Oncorhynchus mykiss) gill or liver or ion regulation in gills.\" \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check few sentences\n",
    "\n",
    "def print_examples(num_examples=5):\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        print \"Training example\", i+1\n",
    "        print \"Label\", train_labels[i], \"(\", classes_dict[train_labels[i]],\")\"\n",
    "        print \"Sentence:\\n\", train_data[i], \"\\n\\n\"\n",
    "       \n",
    "    \n",
    "print_examples(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn the raw training text into feature vectors based on \"td-idf\"\n",
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_dev_tf = vectorizer.transform(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression model ...\n",
      "Performing grid search for Logistic Regression model. It may take a few minutes ...\n",
      "Logistic Regression grid search model fitting time = 0.577730 seconds.\n",
      "As per the grid search on the training data, the optimal value of C = 100.000000.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression:\n",
    "print \"Evaluating Logistic Regression model ...\"\n",
    "\n",
    "# Create a Logistic Regression model. \n",
    "LRmodel = LogisticRegression(C=1.0)\n",
    "\n",
    "# Create a grid search.\n",
    "print \"Performing grid search for Logistic Regression model. It may take a few minutes ...\"\n",
    "Cs = {'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0]}\n",
    "CV_LRmodel = GridSearchCV(estimator=LRmodel, param_grid=Cs)\n",
    "\n",
    "# Fit the models using grid search and display the results.\n",
    "start_time = time.time()\n",
    "CV_LRmodel.fit(vocab_train_tf, train_labels)\n",
    "end_time = time.time()\n",
    "print \"Logistic Regression grid search model fitting time = %f seconds.\" % (end_time - start_time)\n",
    "\n",
    "optimal_Cs = CV_LRmodel.best_params_['C']\n",
    "print \"As per the grid search on the training data, the optimal value of C = %f.\" % optimal_Cs\n",
    "\n",
    "# Construct model with optimal C\n",
    "model_LR = LogisticRegression(C=optimal_Cs)\n",
    "model_LR.fit(vocab_train_tf, train_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev dataset with 618 sentences\n",
      "\n",
      "Data split - Negative, Neutral, Positive\n",
      "----------------------------------------\n",
      "        dataset |       negative |        neutral |       positive\n",
      "  dev_predicted |      47.000000 |     460.000000 |     111.000000\n",
      "     dev_actual |      79.000000 |     397.000000 |     142.000000\n",
      "\n",
      "Accuracy\n",
      "--------\n",
      "Accuracy (test data): 0.756\n",
      "\n",
      "Classification Report\n",
      "---------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.33      0.41        79\n",
      "          1       0.80      0.92      0.85       397\n",
      "          2       0.68      0.53      0.59       142\n",
      "\n",
      "avg / total       0.74      0.76      0.74       618\n",
      "\n",
      "\n",
      "Confusion matrix for Dev data\n",
      "-----------------------------\n",
      "The most confused pair of classes is: 2 ( positive )  incorrectly predicted as 1 ( neutral )\n",
      "Number of such confusion occurences: 58\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGkCAYAAAABqz41AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAMR0ICAAAMR0ICAAAMR0ICAAAM9/8I5D0ziSvpRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1118acfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation data\n",
    "predicted_labels_LR = model_LR.predict(vocab_dev_tf)\n",
    "\n",
    "print \"Dev dataset with\", len(predicted_labels_LR), \"sentences\"\n",
    "print \"\"\n",
    "\n",
    "print \"Data split - Negative, Neutral, Positive\"\n",
    "print \"----------------------------------------\"\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev_predicted\",count_classes(0,predicted_labels_LR), \n",
    "                                                     count_classes(1,predicted_labels_LR),\n",
    "                                                     count_classes(2,predicted_labels_LR))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"dev_actual\",count_classes(0,dev_labels), \n",
    "                                                     count_classes(1,dev_labels),\n",
    "                                                     count_classes(2,dev_labels))\n",
    "\n",
    "\n",
    "accuracy = model_LR.score(vocab_dev_tf, dev_labels)\n",
    "print \"\\nAccuracy\"\n",
    "print \"--------\"\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)\n",
    "\n",
    "print \"\\nClassification Report\"\n",
    "print \"---------------------\"\n",
    "print classification_report(dev_labels, predicted_labels_LR)\n",
    "\n",
    "print \"\\nConfusion matrix for Dev data\"\n",
    "print \"-----------------------------\"\n",
    "\n",
    "array = confusion_matrix(dev_labels, predicted_labels_LR)\n",
    "df_cm = pd.DataFrame(array, index = [\"negative\", \"neutral\", \"positive\"],\n",
    "                  columns = [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "# Find the most confused pair\n",
    "cm2 = confusion_matrix(dev_labels, predicted_labels_LR)  # copy the cm matrix so that can modify the copy without affecting original cm\n",
    "np.fill_diagonal(cm2, 0)  # set the values in the diagonal = 0 to obtain number of confused pairs matrix\n",
    "maximum_pair_idx = np.where(cm2 == cm2.max())  # returns the indices of the max value in cm matrix\n",
    "true_interaction = maximum_pair_idx[0][0]\n",
    "predicted_interaction = maximum_pair_idx[1][0]\n",
    "max_wrong_prediction = cm2[true_interaction][predicted_interaction]\n",
    "print \"The most confused pair of classes is:\", true_interaction, \"(\", classes_dict[true_interaction],\")\",\\\n",
    "\" incorrectly predicted as\", predicted_interaction, \"(\", classes_dict[predicted_interaction],\")\"\n",
    "print \"Number of such confusion occurences:\", max_wrong_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 618 sentences\n",
      "\n",
      "Data split - Negative, Neutral, Positive\n",
      "----------------------------------------\n",
      "        dataset |       negative |        neutral |       positive\n",
      " test_predicted |      59.000000 |     467.000000 |      92.000000\n",
      "    test_actual |     104.000000 |     389.000000 |     125.000000\n",
      "\n",
      "Accuracy\n",
      "--------\n",
      "Accuracy (test data): 0.727\n",
      "\n",
      "Classification Report\n",
      "---------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.39      0.50       104\n",
      "          1       0.76      0.91      0.82       389\n",
      "          2       0.60      0.44      0.51       125\n",
      "\n",
      "avg / total       0.71      0.73      0.71       618\n",
      "\n",
      "\n",
      "Confusion matrix for test data\n",
      "------------------------------\n",
      "The most confused pair of classes is: 2 ( positive )  incorrectly predicted as 1 ( neutral )\n",
      "Number of such confusion occurences: 66\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGkCAYAAAABqz41AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111d77510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test data\n",
    "\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "predicted_labels_LR2 = model_LR.predict(vocab_test_tf)\n",
    "print \"Test dataset with\", len(predicted_labels_LR2), \"sentences\"\n",
    "print \"\"\n",
    "\n",
    "print \"Data split - Negative, Neutral, Positive\"\n",
    "print \"----------------------------------------\"\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_predicted\",count_classes(0,predicted_labels_LR2), \n",
    "                                                     count_classes(1,predicted_labels_LR2),\n",
    "                                                     count_classes(2,predicted_labels_LR2))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_actual\",count_classes(0,test_labels), \n",
    "                                                     count_classes(1,test_labels),\n",
    "                                                     count_classes(2,test_labels))\n",
    "\n",
    "accuracy = model_LR.score(vocab_test_tf, test_labels)\n",
    "print \"\\nAccuracy\"\n",
    "print \"--------\"\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)\n",
    "\n",
    "print \"\\nClassification Report\"\n",
    "print \"---------------------\"\n",
    "print classification_report(test_labels, predicted_labels_LR2)\n",
    "\n",
    "\n",
    "print \"\\nConfusion matrix for test data\"\n",
    "print \"------------------------------\"\n",
    "\n",
    "array = confusion_matrix(test_labels, predicted_labels_LR2)\n",
    "df_cm = pd.DataFrame(array, index = [\"negative\", \"neutral\", \"positive\"],\n",
    "                  columns = [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "\n",
    "# Find the most confused pair\n",
    "cm3 = confusion_matrix(test_labels, predicted_labels_LR2)  # copy the cm matrix so that can modify the copy without affecting original cm\n",
    "np.fill_diagonal(cm3, 0)  # set the values in the diagonal = 0 to obtain number of confused pairs matrix\n",
    "maximum_pair_idx = np.where(cm3 == cm3.max())  # returns the indices of the max value in cm matrix\n",
    "true_interaction = maximum_pair_idx[0][0]\n",
    "predicted_interaction = maximum_pair_idx[1][0]\n",
    "max_wrong_prediction = cm3[true_interaction][predicted_interaction]\n",
    "print \"The most confused pair of classes is:\", true_interaction, \"(\", classes_dict[true_interaction],\")\",\\\n",
    "\" incorrectly predicted as\", predicted_interaction, \"(\", classes_dict[predicted_interaction],\")\"\n",
    "print \"Number of such confusion occurences:\", max_wrong_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Words with the highest weights per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 ( negative )\n",
      "1 weight: 8.548 for feature \" induced \"\n",
      "2 weight: 6.672 for feature \" exposure \"\n",
      "3 weight: 6.461 for feature \" dopa \"\n",
      "4 weight: 5.875 for feature \" acetylneuraminic \"\n",
      "5 weight: 5.853 for feature \" protect \"\n",
      "6 weight: 5.816 for feature \" elevated \"\n",
      "7 weight: 5.692 for feature \" while \"\n",
      "8 weight: 5.380 for feature \" stimulated \"\n",
      "9 weight: 5.169 for feature \" acetaminophen \"\n",
      "10 weight: 5.095 for feature \" coa \"\n",
      "Class 1 ( neutral )\n",
      "1 weight: 9.686 for feature \" study \"\n",
      "2 weight: 6.504 for feature \" total \"\n",
      "3 weight: 5.831 for feature \" on \"\n",
      "4 weight: 5.638 for feature \" investigated \"\n",
      "5 weight: 5.596 for feature \" we \"\n",
      "6 weight: 5.518 for feature \" studied \"\n",
      "7 weight: 5.417 for feature \" no \"\n",
      "8 weight: 5.292 for feature \" were \"\n",
      "9 weight: 5.096 for feature \" sodium \"\n",
      "10 weight: 5.056 for feature \" gamma \"\n",
      "Class 2 ( positive )\n",
      "1 weight: 7.277 for feature \" showed \"\n",
      "2 weight: 6.736 for feature \" red \"\n",
      "3 weight: 6.710 for feature \" enhanced \"\n",
      "4 weight: 6.293 for feature \" analgesic \"\n",
      "5 weight: 6.187 for feature \" increased \"\n",
      "6 weight: 6.148 for feature \" monoamine \"\n",
      "7 weight: 5.993 for feature \" which \"\n",
      "8 weight: 5.984 for feature \" inhibitory \"\n",
      "9 weight: 5.933 for feature \" significantly \"\n",
      "10 weight: 5.718 for feature \" inducing \"\n",
      "\n",
      "Table of weights for each feature for each of the 3 labels:\n",
      "\n",
      "                                negative             neutral            positive\n",
      "             induced               8.548              -4.093              -5.597\n",
      "            exposure               6.672              -3.513              -3.272\n",
      "                dopa               6.461              -4.035              -2.234\n",
      "    acetylneuraminic               5.875              -1.616              -3.467\n",
      "             protect               5.853              -6.150               0.589\n",
      "            elevated               5.816              -4.940              -0.410\n",
      "               while               5.692              -5.543               0.717\n",
      "          stimulated               5.380              -5.928               1.382\n",
      "       acetaminophen               5.169              -0.192              -6.917\n",
      "                 coa               5.095              -5.658               1.775\n",
      "               study              -6.352               9.686              -6.431\n",
      "               total              -1.317               6.504              -5.178\n",
      "                  on              -2.759               5.831              -4.604\n",
      "        investigated              -1.824               5.638              -6.398\n",
      "                  we              -2.669               5.596              -4.282\n",
      "             studied              -3.221               5.518              -3.577\n",
      "                  no              -0.369               5.417              -5.237\n",
      "                were              -3.057               5.292              -3.541\n",
      "              sodium              -0.557               5.096              -5.435\n",
      "               gamma              -2.205               5.056              -2.788\n",
      "              showed               0.309              -6.497               7.277\n",
      "                 red              -0.921              -5.133               6.736\n",
      "            enhanced               1.127              -7.579               6.710\n",
      "           analgesic              -1.760              -5.086               6.293\n",
      "           increased               4.304              -9.063               6.187\n",
      "           monoamine              -3.345              -2.789               6.148\n",
      "               which              -1.542              -4.196               5.993\n",
      "          inhibitory              -0.127              -7.322               5.984\n",
      "       significantly               0.697              -5.658               5.933\n",
      "            inducing              -1.177              -4.122               5.718\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train = vectorizer.fit_transform(train_data)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "model_LR = LogisticRegression(C=optimal_Cs)\n",
    "model_LR.fit(vocab_train, train_labels)\n",
    "\n",
    "weights = model_LR.coef_   # weight vector for each label\n",
    "top30_features_index = []  # list of 30 features (10 words with the largest weights for each label)\n",
    "class_list = ['negative', 'neutral', 'positive']\n",
    "\n",
    "for i in range(3):  # 4 labels\n",
    "    weights_label_i = list(weights[i])  # list of weights for label i\n",
    "    top10_weights_label_i = sorted(weights_label_i, reverse=True)[0:10]  # sort and filter greatest 10 weights\n",
    "    top10_features_index_i = [weights_label_i.index(weight) \\\n",
    "                             for weight in top10_weights_label_i]  # find index of top 10\n",
    "    top10_features_i = [feature_names[index] for index in top10_features_index_i]  # list of features of top 10 weights\n",
    "    top30_features_index += top10_features_index_i  # add the top 10 weigths index of label i to the list of 30\n",
    "\n",
    "    # Print top 5 features per label\n",
    "    print \"Class\", i, \"(\", class_list[i] , \")\"\n",
    "    for index, (weight, feature) in enumerate(zip(top10_weights_label_i,top10_features_i), start = 1):\n",
    "        print index, \"weight: %.3f\" %(weight), \"for feature \\\"\", feature, \"\\\"\"\n",
    "\n",
    "top30_features = [feature_names[index] for index in top30_features_index]  # list of features of top 20 weights\n",
    "\n",
    "# Formatting weights for each class for printing table of results\n",
    "top30_w_class0 = [\"%.3f\" %(list(weights[0])[index]) for index in top30_features_index]\n",
    "top30_w_class1 = [\"%.3f\" %(list(weights[1])[index]) for index in top30_features_index]\n",
    "top30_w_class2 = [\"%.3f\" %(list(weights[2])[index]) for index in top30_features_index]\n",
    "\n",
    "\n",
    "\n",
    "weights_array = np.column_stack((top30_w_class0, top30_w_class1, top30_w_class2))\n",
    "\n",
    "# Print table of weights for the 20 top features\n",
    "print \"\\nTable of weights for each feature for each of the 3 labels:\\n\"\n",
    "row_format =\"{:>20}\" * (len(class_list) + 1)\n",
    "print row_format.format(\"\", *class_list)\n",
    "for feature, weights in zip(top30_features, weights_array):\n",
    "    print row_format.format(feature, *weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Observations **\n",
    "1. Some neutral prediction words seem promising, in particular, \"study\", \"investigated\", \"studied\"\n",
    "2. Some negative and positive prediciton words seem helpful\n",
    "3. Main weakness of the model: this is a bag of word model with feature based on tf-idf. Thus, a drug name or food compound can also result with an important weight to predict a class and this is misleading. For example, \"monoamine\" has a high weight for class \"positive\" based on the positive labels of sentences containing this word. Thus, even if we will add a sentence with a negative interaction between monoamine and a food compound, the BOW model will predict a positive label. The proportion of labels for a drug-food interaction sentences in the training will affect how the model will retain those drugs or food compounds as predictors of positive/negative/neutral. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. R-ratio analysis - look at individual sentences with highest errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R is equal to maximum predicted probability divided by predicted probability of the correct label.  \n",
    "In other words, it looks how \"far\" the prediction of a class is from the true class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 sentences where the ratio R is largest:\n",
      "\n",
      "                         ratio R     Max pred Pr      Correct Pr Predicted label      True label       Doc Index\n",
      "       Highest R        1145.199           0.955           0.001             1.0             2.0            63.0\n",
      "     2nd highest         866.044           0.966           0.001             1.0             2.0           485.0\n",
      "     3rd highest         703.035           0.735           0.001             1.0             2.0           299.0\n",
      "             4th         582.337           0.908           0.002             1.0             0.0            91.0\n",
      "             5th          497.53            0.98           0.002             1.0             2.0           146.0\n",
      "             6th         315.515           0.988           0.003             1.0             2.0           428.0\n",
      "             7th         294.064           0.979           0.003             1.0             0.0            30.0\n",
      "             8th         282.868           0.934           0.003             2.0             0.0           337.0\n",
      "             9th         259.297           0.963           0.004             1.0             0.0           462.0\n",
      "            10th         211.585           0.753           0.004             1.0             2.0           156.0\n",
      "\n",
      "Sentences:\n",
      "\n",
      "1) Sentence with ratio R = 1145.199 :\n",
      "The independent effects of catalase and phytic acid are related to their abilities to catalyse isoniazid oxidation.\n",
      "\n",
      "2) Sentence with ratio R = 866.044 :\n",
      "The procedure is based on the product of the reaction of isoniazid with benzaldehyde.\n",
      "\n",
      "3) Sentence with ratio R = 703.035 :\n",
      "Gastric emptying as measured by paracetamol absorption was also faster (P = 0.034) after low-viscosity oat bran beverage consumption.\n",
      "\n",
      "4) Sentence with ratio R = 582.337 :\n",
      "It was found that besides sodium salicylate and high doses of aspirin, other salicylate-type drugs, such as diflunisal, 4-aminosalicylic acid, 2,4-dihydroxybenzoic acid and methyl salicylate, and several non-acidic compounds, such as proquazone, benzydamine and paracetamol, were gastroprotective.\n",
      "\n",
      "5) Sentence with ratio R = 497.530 :\n",
      "A novel colorimetric sensor, 2-hydroxy naphthaldehyde isonicotinoyl hydrazone (HINH), was easily synthesized by the condensation of isoniazid and 2-hydroxy-1-naphthaldehyde.\n",
      "\n",
      "6) Sentence with ratio R = 315.515 :\n",
      "The release of acetaminophen (AAP) from tablets containing phospholipids was examined using hydrogenated soybean phospholipid (HSL) and its main components, phosphatidylcholine (PC), phosphatidylethanolamine (PE) and phosphatidylinositol (PI), although the PI was not well purified (PI rich).\n",
      "\n",
      "7) Sentence with ratio R = 294.064 :\n",
      "Activated carbon (AC)/CoFe2O4 nanocomposites, MAC-1 and MAC-2, were prepared by a simple pyrolytic method using a mixture of iron(III)/cobalt(II) benzoates and iron(III)/cobalt(II) oxalates, respectively, and were used as efficient adsorbents for the removal of amoxicillin (AMX) and paracetamol (PCT) of aqueous effluents.\n",
      "\n",
      "8) Sentence with ratio R = 282.868 :\n",
      "The IC(50) values of the four potent flavonoids, quercitrin, isoquercitrin, rutin, and quercetin on monoamine oxidase were 19.06, 11.64, 3.89, and 10.89 microM and enzyme kinetics analysis revealed apparent inhibition constants (K(i)) of 21.01, 2.72, 1.83, and 7.95 microM, respectively, on the substrate, benzylamine.\n",
      "\n",
      "9) Sentence with ratio R = 259.297 :\n",
      "We report an unusual case of acute 'familiar' digitalis poisoning in three patients who had eaten potato dumplings flavoured with leaves of Borago officinalis L. unconsciously mixed with leaves of Digitalis purpurea L. A complicated clinical course with marked bradyarrhythmias was presented, with good evolution thanks to the use of digoxin-specific antibody Fab fragments.\\\n",
      "\n",
      "10) Sentence with ratio R = 211.585 :\n",
      "The antihistamine effect reached a plateau after approximately 2 h of exposure, and the potency of emedastine decreased in the following order by vehicle: isopropyl myristate >geraniol >glycerin.\\\n",
      "\n",
      "Sentence 1 (example number 63 ):\n",
      "Influential word: to with magnitude: 0.836470748843\n",
      "Influential word: oxidation with magnitude: 0.711643362924\n",
      "Influential word: isoniazid with magnitude: 0.676326122924\n",
      "Influential word: acid with magnitude: 0.381449683552\n",
      "Influential word: and with magnitude: 0.248305045448\n",
      "\n",
      "Sentence 2 (example number 485 ):\n",
      "Influential word: on with magnitude: 0.960855656288\n",
      "Influential word: isoniazid with magnitude: 0.715793778657\n",
      "Influential word: based with magnitude: 0.418727494782\n",
      "Influential word: of with magnitude: 0.379359393555\n",
      "Influential word: product with magnitude: 0.322960701145\n",
      "\n",
      "Sentence 3 (example number 299 ):\n",
      "Influential word: gastric with magnitude: 1.04972851007\n",
      "Influential word: measured with magnitude: 1.03205983675\n",
      "Influential word: emptying with magnitude: 0.996387562455\n",
      "Influential word: low with magnitude: 0.477437819692\n",
      "Influential word: was with magnitude: 0.346726840632\n",
      "\n",
      "Sentence 4 (example number 91 ):\n",
      "Influential word: salicylate with magnitude: 1.59260000786\n",
      "Influential word: several with magnitude: 0.858280045092\n",
      "Influential word: sodium with magnitude: 0.731153281341\n",
      "Influential word: and with magnitude: 0.554459342447\n",
      "Influential word: were with magnitude: 0.439625176646\n",
      "\n",
      "Sentence 5 (example number 146 ):\n",
      "Influential word: synthesized with magnitude: 1.02385540044\n",
      "Influential word: isoniazid with magnitude: 0.568628649963\n",
      "Influential word: hydroxy with magnitude: 0.475031646173\n",
      "Influential word: was with magnitude: 0.345296400292\n",
      "Influential word: and with magnitude: 0.208765206586\n",
      "\n",
      "Sentence 6 (example number 428 ):\n",
      "Influential word: aap with magnitude: 0.628232556443\n",
      "Influential word: phosphatidylcholine with magnitude: 0.624361716367\n",
      "Influential word: not with magnitude: 0.619054087291\n",
      "Influential word: using with magnitude: 0.551396661256\n",
      "Influential word: was with magnitude: 0.529984791376\n",
      "\n",
      "Sentence 7 (example number 30 ):\n",
      "Influential word: were with magnitude: 0.774671030988\n",
      "Influential word: and with magnitude: 0.48851113775\n",
      "Influential word: using with magnitude: 0.420319104725\n",
      "Influential word: used with magnitude: 0.2913198532\n",
      "Influential word: method with magnitude: 0.288836044604\n",
      "\n",
      "Sentence 8 (example number 337 ):\n",
      "Influential word: 89 with magnitude: 0.844459172644\n",
      "Influential word: monoamine with magnitude: 0.677516530144\n",
      "Influential word: apparent with magnitude: 0.656481844422\n",
      "Influential word: values with magnitude: 0.531957443714\n",
      "Influential word: substrate with magnitude: 0.43880091695\n",
      "\n",
      "Sentence 9 (example number 462 ):\n",
      "Influential word: acute with magnitude: 0.558524100588\n",
      "Influential word: we with magnitude: 0.533658865667\n",
      "Influential word: digitalis with magnitude: 0.433548289181\n",
      "Influential word: leaves with magnitude: 0.349971920354\n",
      "Influential word: antibody with magnitude: 0.335783519348\n",
      "\n",
      "Sentence 10 (example number 156 ):\n",
      "Influential word: order with magnitude: 0.605043659867\n",
      "Influential word: following with magnitude: 0.506104413411\n",
      "Influential word: reached with magnitude: 0.318188134138\n",
      "Influential word: of with magnitude: 0.308744632371\n",
      "Influential word: and with magnitude: 0.213877882172\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Logistic regression model with C=50\n",
    "model_LR = LogisticRegression(C=optimal_Cs)\n",
    "model_LR.fit(vocab_train_tf, train_labels)\n",
    "predicted_labels_LR = model_LR.predict(vocab_test_tf)\n",
    "\n",
    "#feature_names = vectorizer.get_feature_names()\n",
    "#print \"features names length:\", len(feature_names)\n",
    "\n",
    "    \n",
    "# Variables to calculate R\n",
    "probabilities = model_LR.predict_proba(vocab_test_tf)  # Each label probability (4) for each document\n",
    "proba_max = probabilities.max(axis=1)  # Maximum predicted probability\n",
    "proba_correct_label = [probabilities[i][test_labels[i]] \\\n",
    "                       for i in range(probabilities.shape[0])]  # Predicted prob of the correct label\n",
    "r_ratio = proba_max/proba_correct_label  # R = maximum predicted prob / predicted prob of the correct label\n",
    "sentence_index = [i for i in range(probabilities.shape[0])]  # Index of the document to retrace once sorted by R\n",
    "\n",
    "# Results array with 5 columns (R, max prob, prob of correct label, predicted labels, true labels,\n",
    "# document index)\n",
    "results = np.column_stack((r_ratio, proba_max, proba_correct_label, predicted_labels_LR, \\\n",
    "                           test_labels, sentence_index))\n",
    "results_max3r = sorted(results, key=lambda x: x[0], reverse=True)[:10]  # top 10 sentences with highest R\n",
    "\n",
    "\n",
    "# Format and print top 3 documents with highest R:\n",
    "# 1) print top 10 sentences related info - probabilities, predicted/correct labels, etc.\n",
    "print \"\\nTop 10 sentences where the ratio R is largest:\\n\"\n",
    "column_names = [\"ratio R\", \"Max pred Pr\", \"Correct Pr\", \"Predicted label\", \"True label\", \\\n",
    "                \"Doc Index\"]\n",
    "row_format =\"{:>16}\" * (len(column_names)+1)\n",
    "print row_format.format(\"\", *column_names)\n",
    "top_10 = [\"Highest R\", \"2nd highest\", \"3rd highest\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \"10th\"]\n",
    "for index, row in zip(top_10, results_max3r):\n",
    "    row = [round(item,3) for item in row]\n",
    "    print row_format.format(index, *row)\n",
    "\n",
    "# 2) print top 3 R documents messages\n",
    "print \"\\nSentences:\"\n",
    "i = 1\n",
    "for row in results_max3r:\n",
    "    print \"\\n\" + str(i) +\") Sentence with ratio R = %.3f\" %(row[0]), \":\"\n",
    "    print test_data[int(row[5])]\n",
    "    i +=1  \n",
    "\n",
    "\n",
    "# Diagnosis of influential words in the 3 documents with highest R\n",
    "weights = model_LR.coef_\n",
    "sentence_list = [int(result[5]) for result in results_max3r]\n",
    "j=1\n",
    "\n",
    "for example in sentence_list:\n",
    "    predicted_label = predicted_labels_LR[example]\n",
    "    indices = vocab_test_tf[example].indices  # list of indices of non zero features of document\n",
    "    vocab_freq = vocab_test_tf[example].data  # list of features values of document\n",
    "    weights_example = [weights[predicted_label][index] for index in indices]  # list of LR weights \n",
    "                                                                              # for non zero features of doc\n",
    "    feature_importance = vocab_freq * weights_example  # feature value x weight for total influence on prediction\n",
    "\n",
    "    features_array = np.column_stack((feature_importance, indices))\n",
    "    features_sorted = sorted(features_array, key=lambda x: x[0], reverse=True)  # Sort words by influence\n",
    "\n",
    "    # Print top 5 features (words) of the document with heaviest weight x value\n",
    "    \n",
    "    print \"\\nSentence\", j,  \"(example number\", example, \"):\"\n",
    "    for i in range(5):\n",
    "        index = int(features_sorted[i][1])\n",
    "        print \"Influential word:\", feature_names[index] ,\"with magnitude:\", features_sorted[i][0]\n",
    "    j +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create file with list of probabilities and predicted/true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total difference between 100% and probability of predicting right label 194.650667203\n",
      "Total difference between max probability and probability of predicting right label 104.33371905\n"
     ]
    }
   ],
   "source": [
    "# Items: diff_true_from_1, diff_pred_true, proba_max, proba_correct_label, predicted_label, correct_label\n",
    "proba_list = []\n",
    "\n",
    "for r_ratio, proba_max, proba_correct_label, predicted_labels_LR, test_labels, sentence_index in results:\n",
    "    diff_true_from_1 = 1.0 - proba_correct_label\n",
    "    diff_pred_true = proba_max - proba_correct_label\n",
    "    proba_list.append([diff_true_from_1, diff_pred_true, proba_max, proba_correct_label, \n",
    "                       predicted_labels_LR, test_labels])\n",
    "\n",
    "total_diff_true_from_1 = sum([item[0] for item in proba_list])\n",
    "total_diff_pred_true = sum([item[1] for item in proba_list])\n",
    "\n",
    "print \"Total difference between 100% and probability of predicting right label\", total_diff_true_from_1\n",
    "print \"Total difference between max probability and probability of predicting right label\", total_diff_pred_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_list = np.array(proba_list)\n",
    "np.savetxt(\"LR_probabilities_m1.csv\", proba_list, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194.650667203\n",
      "104.33371905\n"
     ]
    }
   ],
   "source": [
    "# If need to load it again:\n",
    "test = np.loadtxt(\"LR_probabilities_m1.csv\", delimiter=\",\")\n",
    "\n",
    "test1 = sum([i[0] for i in test])\n",
    "test2 = sum([i[1] for i in test])\n",
    "\n",
    "print test1\n",
    "print test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "vocab_dev_tf = vectorizer.transform(dev_data)\n",
    "vocab_test_tf = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Support Vector Machine model ...\n",
      "Performing grid search for Support Vector Machine model. It may take a few minutes ...\n",
      "Support Vector Machines grid search model fitting time = 8.541200 seconds.\n",
      "As per the grid search on the training data, the optimal value of C = 0.000100.\n",
      "Support Vector Machines prediction time for dev data = 0.128497 seconds.\n",
      "Accuracy on dev data for Support Vector Machine is = 0.642395\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        79\n",
      "          1       0.64      1.00      0.78       397\n",
      "          2       0.00      0.00      0.00       142\n",
      "\n",
      "avg / total       0.41      0.64      0.50       618\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Support Vector Machines:\n",
    "print \"Evaluating Support Vector Machine model ...\"\n",
    "\n",
    "# Create a Support Vector Machine model. \n",
    "SVMmodel = SVC(C=1.0)\n",
    "\n",
    "# Create a grid search.\n",
    "print \"Performing grid search for Support Vector Machine model. It may take a few minutes ...\"\n",
    "Cs = {'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0]}\n",
    "CV_SVMmodel = GridSearchCV(estimator=SVMmodel, param_grid=Cs)\n",
    "\n",
    "# Fit the models using grid search and display the results.\n",
    "start_time = time.time()\n",
    "CV_SVMmodel.fit(vocab_train_tf, train_labels)\n",
    "end_time = time.time()\n",
    "print \"Support Vector Machines grid search model fitting time = %f seconds.\" % (end_time - start_time)\n",
    "\n",
    "optimal_Cs = CV_SVMmodel.best_params_['C']\n",
    "print \"As per the grid search on the training data, the optimal value of C = %f.\" % optimal_Cs\n",
    "\n",
    "# Predict labels for dev data and calculate accuracy using optimal C\n",
    "start_time = time.time()\n",
    "SVMmodel = CV_SVMmodel.predict(vocab_dev_tf)\n",
    "end_time = time.time()\n",
    "print \"Support Vector Machines prediction time for dev data = %f seconds.\" % (end_time - start_time)\n",
    "\n",
    "# Print goodness of fit measures\n",
    "print \"Accuracy on dev data for Support Vector Machine is = %f\" % CV_SVMmodel.score(vocab_dev_tf, dev_labels)\n",
    "print \"Classification Report\\n\", classification_report(dev_labels, SVMmodel)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model\n",
      "Accuracy (dev data): 0.642\n",
      "Test dataset with 618 sentences\n",
      "Accuracy (test data): 0.629\n",
      "        dataset |       negative |        neutral |       positive\n",
      " test_predicted |       0.000000 |     618.000000 |       0.000000\n",
      "    test_actual |     104.000000 |     389.000000 |     125.000000\n",
      "Confusion matrix for test data\n",
      "The most confused pair of classes is: 2 ( positive )  incorrectly predicted as 1 ( neutral )\n",
      "Number of such confusion occurences: 125\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGkCAYAAAABqz41AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9ktjymQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115d26850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Turn the raw training text into feature vectors based on \"td-idf\"\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#vocab_train_tf = vectorizer.fit_transform(train_data)\n",
    "#vocab_dev_tf = vectorizer.transform(dev_data)\n",
    "\n",
    "# SVM model\n",
    "model_SVM = SVC(C=0.0001)\n",
    "model_SVM.fit(vocab_train_tf, train_labels)\n",
    "predicted_labels_SVM = model_SVM.predict(vocab_dev_tf)\n",
    "\n",
    "# DEV\n",
    "print \"SVM model\"\n",
    "accuracy = model_SVM.score(vocab_dev_tf, dev_labels)\n",
    "print \"Accuracy (dev data): %.3f\" %(accuracy)\n",
    "\n",
    "# TEST\n",
    "vocab_test_tf = vectorizer.transform(test_data)\n",
    "predicted_labels_SVM2 = model_SVM.predict(vocab_test_tf)\n",
    "print \"Test dataset with\", len(predicted_labels_SVM2), \"sentences\"\n",
    "accuracy = model_SVM.score(vocab_test_tf, test_labels)\n",
    "print \"Accuracy (test data): %.3f\" %(accuracy)\n",
    "\n",
    "print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(\"dataset\",\"negative\", \"neutral\", \"positive\")\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_predicted\",count_classes(0,predicted_labels_SVM2), \n",
    "                                                     count_classes(1,predicted_labels_SVM2),\n",
    "                                                     count_classes(2,predicted_labels_SVM2))\n",
    "print \"{0:>15} |{1:>15f} |{2:>15f} |{3:>15f}\".format(\"test_actual\",count_classes(0,test_labels), \n",
    "                                                     count_classes(1,test_labels),\n",
    "                                                     count_classes(2,test_labels))\n",
    "\n",
    "print \"Confusion matrix for test data\"\n",
    "\n",
    "array = confusion_matrix(test_labels, predicted_labels_SVM2)\n",
    "df_cm = pd.DataFrame(array, index = [\"negative\", \"neutral\", \"positive\"],\n",
    "                  columns = [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "\n",
    "# Find the most confused pair\n",
    "cm3 = confusion_matrix(test_labels, predicted_labels_SVM2)  # copy the cm matrix so that can modify the copy without affecting original cm\n",
    "np.fill_diagonal(cm3, 0)  # set the values in the diagonal = 0 to obtain number of confused pairs matrix\n",
    "maximum_pair_idx = np.where(cm3 == cm3.max())  # returns the indices of the max value in cm matrix\n",
    "true_interaction = maximum_pair_idx[0][0]\n",
    "predicted_interaction = maximum_pair_idx[1][0]\n",
    "max_wrong_prediction = cm3[true_interaction][predicted_interaction]\n",
    "print \"The most confused pair of classes is:\", true_interaction, \"(\", classes_dict[true_interaction],\")\",\\\n",
    "\" incorrectly predicted as\", predicted_interaction, \"(\", classes_dict[predicted_interaction],\")\"\n",
    "print \"Number of such confusion occurences:\", max_wrong_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
