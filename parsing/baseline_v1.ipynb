{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline : Food-drug Interaction Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.0.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.12 (default, Jul  2 2016 17:43:17)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "spark_home = os.environ['SPARK_HOME'] = '/Users/lisabarcelo/Downloads/spark-2.0.0-bin-hadoop2.7'\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME enviroment variable is not set')\n",
    "sys.path.insert(0,os.path.join(spark_home,'python'))\n",
    "sys.path.insert(0,os.path.join(spark_home,'python/lib/py4j-0.10.1-src.zip'))\n",
    "execfile(os.path.join(spark_home,'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load food names or compounds into a list of unique items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1 (not used): directly load csv data in Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named iteritems",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-dc921b2a5fc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named iteritems"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import codecs\n",
    "from collections import defaultdict\n",
    "import iteritems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisabarcelo/miniconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "db_food = pd.read_csv(\"data/contents copy.csv\", encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>orig_food_common_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Kiwi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Onion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Onion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cashew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id orig_food_common_name\n",
       "0   1                  Kiwi\n",
       "1   2                 Onion\n",
       "2   3                 Onion\n",
       "3   4                Chives\n",
       "4   5                Cashew"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_food.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "food = db_food[\"orig_food_common_name\"].tolist()  # somehow, converting to a set instead of list didn't work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048575"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foodlist = set()\n",
    "\n",
    "for f in food:\n",
    "    for term in str(f).lower().split(\",\"):\n",
    "        if len(term) >=3:  # in case some single letter or determinant is included?\n",
    "            foodlist.add(term.strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for f in foodlist:\n",
    "#     print f\n",
    "#     i += 1\n",
    "#     if i >20:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6143"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(foodlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"foodlist.txt\", \"w\", \"utf-8\") as fdlist:\n",
    "    for item in foodlist:\n",
    "        fdlist.write(item + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Using Adam's pickle file (food common name as sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pickling the data from foodb.ca database, see Adam's notebook **compound_food_id.ipynb**  \n",
    "\n",
    "As a first test, we will use only the food common name (not scientific name) only. Compounds names will be added once this test passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# food_common.pickle: Dictionary with common English food names as keys, compounds as values\n",
    "test = pickle.load(open( \"data/food_common.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i, item in enumerate(test.iteritems()):\n",
    "#     if i == 0:\n",
    "#         print 'food name'\n",
    "#         print '-'*10\n",
    "#     print '{0}'.format(item[0])\n",
    "#     if i == 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foodlist_test = set(test.keys())  # Will work with a set rather than a list. Faster search for later (hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"foodlist.txt\", \"w\") as fdlist:\n",
    "    for item in foodlist_test:\n",
    "        fdlist.write(item + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Problem: there are 2 words with unusual symbols (dragee, cupuacu) and have been modified in the file and renamed\n",
    "# as \"foodlisr2.txt\"\n",
    "# Any ideas how to deal with this without changing the file manually?? Looks like codecs does not work on pickle file\n",
    "\n",
    "foodlist = set()\n",
    "\n",
    "with open(\"foodlist.txt\", \"r\") as fdlist2:\n",
    "    for line in fdlist2:\n",
    "        foodlist.add(str(line).lower().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Filter sentences from abstract with drug keyword and food names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Test with only the abstracts' first json file. Once works, we can add all 100 remaining files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pyspark\n",
    "# from pyspark import SparkContext\n",
    "# sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# # UTF-8 support\n",
    "# import codecs\n",
    "\n",
    "name = \"pbabstract1.json\"\n",
    "with codecs.open(name,\"r\",\"utf-8\") as data_file:\n",
    "    data = json.load(data_file)\n",
    "abstractRDD = sc.parallelize(data.values())  # To load only the values and not the key (ID number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'To evaluate the economic outcomes that arose from the introduction of therapeutic reference pricing (TRP) into Slovenian practice in 2013, based on the first three therapeutic classes, namely proton-pump inhibitors (PPIs), angiotensin-converting-enzyme inhibitors (ACEIs), and lipid-lowering agents (LLAs).',\n",
       " u'National health claims data on prescription medicines from January 2011 to December 2015 were analyzed. Monthly medicine expenditure, medicine consumption, changes in medicine use, and market competition (Herfindahl-Hirschman index) were determined to assess the TRP impact on market dynamics. Interrupted time series analysis was used to assess the TRP cost-saving potential.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstractRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To use PubMed API\n",
    "import pubmed.utils as pb\n",
    "\n",
    "# Split abstracts to sentences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def splitSentences(abstract):\n",
    "    sentences = sent_tokenize(abstract)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drugkeyword = \"ACEI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We are working',\n",
       " 'are working hard',\n",
       " 'working hard on',\n",
       " 'hard on 266',\n",
       " 'on 266 project',\n",
       " '266 project baseline']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_ngrams(sentence, n):\n",
    "    ''' Return list of ngrams from a sentence\n",
    "    '''\n",
    "    words_list = sentence.split()\n",
    "    ngrams = zip(*[words_list[i:] for i in range(n)])\n",
    "    return [''.join([str(w)+' ' for w in ngram if type(w)==str]).strip() for ngram in ngrams]\n",
    "\n",
    "\n",
    "#example:\n",
    "string = \"We are working hard on 266 project baseline\"\n",
    "find_ngrams(string, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "\n",
    "# Method 1 - NOT USED\n",
    "# NOT USED since will return True if finds a food name within a word in the sentence\n",
    "# E.g.: \"pie\" food name and \"therapies\" word in sentence: return True since \"pie\" in \"therapies\"\n",
    "#def includeFoodCmpd(sentence, fdlist):\n",
    "#    if any(word in sentence for word in fdlist):\n",
    "#        return True\n",
    "#    else:\n",
    "#        return False\n",
    "\n",
    "# Method 2 - solution to method 2\n",
    "def includeFoodCmpd(sentence, fdlist):\n",
    "    ''' Calculates the Jaro Wrinkler distance between food name and ngrams in the sentence.\n",
    "        Returns True if distance > 0.95\n",
    "    '''\n",
    "    result = False\n",
    "    for food in fdlist:\n",
    "        n = min(3, len(food.split()))  # Assuming max as trigram        \n",
    "        try:\n",
    "            sentence = sentence.encode(\"utf-8\")\n",
    "            sentence_ngrams = find_ngrams(sentence, n)  # Note: punctuation at end of sentence will be included with\n",
    "                                                    # last word. For now ok, since the JW will still be > 0.95\n",
    "            for ngram in sentence_ngrams:\n",
    "                # Note: when using jaro_winkler, need to convert into unicode format\n",
    "                print food, ngram, jellyfish.jaro_winkler(u\"{}\".format(food.lower()), u\"{}\".format(ngram.lower()))\n",
    "                if jellyfish.jaro_winkler(u\"{}\".format(food.lower()), u\"{}\".format(ngram.lower())) > 0.95:  \n",
    "                    result = True\n",
    "                    break\n",
    "        except:\n",
    "            next\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello Panda 0.0\n",
      "hello is 0.0\n",
      "hello eating 0.455555555556\n",
      "hello a 0.0\n",
      "hello pie 0.511111111111\n",
      "pie Panda 0.511111111111\n",
      "pie is 0.0\n",
      "pie eating 0.5\n",
      "pie a 0.0\n",
      "pie pie 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing includeFoodCmpd function\n",
    "ss = u'Panda is eating a pie'\n",
    "testlist = [\"hello\",\"pie\"]\n",
    "includeFoodCmpd(ss, testlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: tried to braodcast the foodlist but got an error message when used it in below filter\n",
    "# \"TypeError: 'Broadcast' object is not iterable\".... any idea why?\n",
    "# foodlist_bcast = sc.broadcast(foodlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = abstractRDD.flatMap(splitSentences) \\\n",
    "                       .map(lambda a: pb.ace_substitutor(a, drugkeyword)) \\\n",
    "                       .filter(lambda a: drugkeyword in a)\\\n",
    "                       .filter(lambda a: includeFoodCmpd(a, foodlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'this meta-analysis of randomized parallel controlled trials was designed to compare the efficacy of atenolol with ACEI in changing pulse wave velocity (pwv), peripheral blood pressure and heart rate (hr) among patients with essential hypertension.',\n",
       " u'using the ualdo:c and a relatively stringent definition of abt, it appears that incomplete raas blockade is common in dogs with mmvd receiving an ACEI.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'this meta-analysis of randomized parallel controlled trials was designed to compare the efficacy of atenolol with ACEI in changing pulse wave velocity (pwv), peripheral blood pressure and heart rate (hr) among patients with essential hypertension.',\n",
       " u'using the ualdo:c and a relatively stringent definition of abt, it appears that incomplete raas blockade is common in dogs with mmvd receiving an ACEI.',\n",
       " u'we investigated the molecular mechanisms involved in the ACEI (ACEI) inhibition by (-)-epigallocatechin-3-gallate (egcg), a major tea catechin.',\n",
       " u'ACEI/arb use is common in patients initiating pd in the u.s. but was not associated with a lower risk of anuria.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = \"in this study, we examined the separated caseins and whey proteins of goat milk for the presence of ACEI inhibitory peptides.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findFoodItems(sentence, foods):\n",
    "    for item in foods:\n",
    "        if item in sentence:\n",
    "            print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casein\n",
      "oat\n",
      "whey\n"
     ]
    }
   ],
   "source": [
    "findFoodItems(s, foodlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casein\n",
      "oat\n",
      "whey\n"
     ]
    }
   ],
   "source": [
    "s2 = \"digestion of isolated whey proteins and caseins of goat milk by gastric pepsin generated soluble hydrolysates exhibiting significant inhibition of ACEI compared to weak inhibition by undigested proteins.\"\n",
    "findFoodItems(s2, foodlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Classify sentences as positive or negative based on a sentiment lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment lexicon used is the Harvard General Inquirer (http://www.wjh.harvard.edu/~inquirer/spreadsheet_guide.htm). It contains 1,915 positive words and 2,291 negative words and is free for research use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisabarcelo/miniconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (63,108,109,110,176) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "db_sentiment = pd.read_csv(\"data/inquirerbasic.csv\", encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Source</th>\n",
       "      <th>Positiv</th>\n",
       "      <th>Negativ</th>\n",
       "      <th>Pstv</th>\n",
       "      <th>Affil</th>\n",
       "      <th>Ngtv</th>\n",
       "      <th>Hostile</th>\n",
       "      <th>Strong</th>\n",
       "      <th>Power</th>\n",
       "      <th>...</th>\n",
       "      <th>Anomie</th>\n",
       "      <th>NegAff</th>\n",
       "      <th>PosAff</th>\n",
       "      <th>SureLw</th>\n",
       "      <th>If</th>\n",
       "      <th>NotLw</th>\n",
       "      <th>TimeSpc</th>\n",
       "      <th>FormLw</th>\n",
       "      <th>Othtags</th>\n",
       "      <th>Defined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>H4Lvd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DET ART</td>\n",
       "      <td>| article: Indefinite singular article--some o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABANDON</td>\n",
       "      <td>H4Lvd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negativ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ngtv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUPV</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABANDONMENT</td>\n",
       "      <td>H4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negativ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Noun</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABATE</td>\n",
       "      <td>H4Lvd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negativ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUPV</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABATEMENT</td>\n",
       "      <td>Lvd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Noun</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Entry Source Positiv  Negativ Pstv Affil  Ngtv Hostile Strong Power  \\\n",
       "0            A  H4Lvd     NaN      NaN  NaN   NaN   NaN     NaN    NaN   NaN   \n",
       "1      ABANDON  H4Lvd     NaN  Negativ  NaN   NaN  Ngtv     NaN    NaN   NaN   \n",
       "2  ABANDONMENT     H4     NaN  Negativ  NaN   NaN   NaN     NaN    NaN   NaN   \n",
       "3        ABATE  H4Lvd     NaN  Negativ  NaN   NaN   NaN     NaN    NaN   NaN   \n",
       "4    ABATEMENT    Lvd     NaN      NaN  NaN   NaN   NaN     NaN    NaN   NaN   \n",
       "\n",
       "                         ...                         Anomie NegAff PosAff  \\\n",
       "0                        ...                            NaN    NaN    NaN   \n",
       "1                        ...                            NaN    NaN    NaN   \n",
       "2                        ...                            NaN    NaN    NaN   \n",
       "3                        ...                            NaN    NaN    NaN   \n",
       "4                        ...                            NaN    NaN    NaN   \n",
       "\n",
       "  SureLw   If NotLw TimeSpc FormLw  Othtags  \\\n",
       "0    NaN  NaN   NaN     NaN    NaN  DET ART   \n",
       "1    NaN  NaN   NaN     NaN    NaN     SUPV   \n",
       "2    NaN  NaN   NaN     NaN    NaN     Noun   \n",
       "3    NaN  NaN   NaN     NaN    NaN     SUPV   \n",
       "4    NaN  NaN   NaN     NaN    NaN     Noun   \n",
       "\n",
       "                                             Defined  \n",
       "0  | article: Indefinite singular article--some o...  \n",
       "1                                                  |  \n",
       "2                                                  |  \n",
       "3                                                  |  \n",
       "4                                                NaN  \n",
       "\n",
       "[5 rows x 186 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Positiv</th>\n",
       "      <th>Causal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ACCOUNTABLE</td>\n",
       "      <td>Positiv</td>\n",
       "      <td>Causal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>FEASIBLE</td>\n",
       "      <td>Positiv</td>\n",
       "      <td>Causal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>FERTILE</td>\n",
       "      <td>Positiv</td>\n",
       "      <td>Causal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>IMPETUS</td>\n",
       "      <td>Positiv</td>\n",
       "      <td>Causal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>INDICATIVE</td>\n",
       "      <td>Positiv</td>\n",
       "      <td>Causal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Entry  Positiv  Causal\n",
       "95    ACCOUNTABLE  Positiv  Causal\n",
       "3973     FEASIBLE  Positiv  Causal\n",
       "4018      FERTILE  Positiv  Causal\n",
       "5290      IMPETUS  Positiv  Causal\n",
       "5412   INDICATIVE  Positiv  Causal"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To be continued... Notice that we do have some relationship words that are positive AND causaul\n",
    "db_sentiment[['Entry','Positiv','Causal']].sort_values(by=['Positiv','Causal']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of Positive Words:  Positiv    1915\n",
      "Name: Positiv, dtype: int64\n",
      "Number of Negative Words:  Negativ    2291\n",
      "Name: Negativ, dtype: int64\n",
      "Number of Causaul Words:  Causal    112\n",
      "Name: Causal, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print \"Number of Positive Words: \", db_sentiment['Positiv'].value_counts()\n",
    "print \"Number of Negative Words: \", db_sentiment['Negativ'].value_counts()\n",
    "print \"Number of Causaul Words: \", db_sentiment['Causal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Look at all data fields available\n",
    "# for column in db_sentiment.columns:\n",
    "#     print column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** some columns seem quite interesting for analysing relationship other than simply positive or negative sentiment (e.g. \"causal\", etc.). For the baseline, we will only use the \"positive\" and \"negative\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter only the words labeled positive or negative\n",
    "positive = db_sentiment[db_sentiment.Positiv == \"Positiv\"].Entry.map(lambda x: x.lower()).tolist()\n",
    "negative = db_sentiment[db_sentiment.Negativ == \"Negativ\"].Entry.map(lambda x: x.lower()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'abide', u'ability', u'able', u'abound']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'abandon', u'abandonment', u'abate', u'abdicate']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform list into sets for faster search\n",
    "positive = set(positive)\n",
    "negative = set(negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an attempt to classify whether a sentence is positive or negative.  \n",
    "Note the main weaknesses:  \n",
    "1. It is \"positively\" biased for now since looks at the positive words first and if it finds it, then it immediately returns positive. Thus, it may not look at the entire sentence in case of both positive or negative words.  \n",
    "2. Negation of a positive word is not taken into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def includeSentiment(sentence, poslist, neglist): \n",
    "    ''' Classify sentence as positive or negative based on first word found\n",
    "        in the lexicon\n",
    "    '''\n",
    "    if any(word in sentence for word in poslist):\n",
    "        return (\"positive\", sentence)\n",
    "    elif any(word in sentence for word in neglist):\n",
    "        return (\"negative\", sentence)\n",
    "    else:\n",
    "        return (\"neutral\", sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add sentiment as key in the RDD\n",
    "sentiments = sentences.map(lambda a: includeSentiment(a, positive, negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('positive',\n",
       "  u'this meta-analysis of randomized parallel controlled trials was designed to compare the efficacy of atenolol with ACEI in changing pulse wave velocity (pwv), peripheral blood pressure and heart rate (hr) among patients with essential hypertension.'),\n",
       " ('negative',\n",
       "  u'using the ualdo:c and a relatively stringent definition of abt, it appears that incomplete raas blockade is common in dogs with mmvd receiving an ACEI.')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek at 2 first lines\n",
    "sentiments.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create 2 lists of filtered sentences: one positive list and one negative list\n",
    "pos_sentiments = sentiments.lookup(\"positive\")\n",
    "neg_sentiments = sentiments.lookup(\"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'this meta-analysis of randomized parallel controlled trials was designed to compare the efficacy of atenolol with ACEI in changing pulse wave velocity (pwv), peripheral blood pressure and heart rate (hr) among patients with essential hypertension.']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples of sentences with positive sentiment lexicon\n",
    "pos_sentiments[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'using the ualdo:c and a relatively stringent definition of abt, it appears that incomplete raas blockade is common in dogs with mmvd receiving an ACEI.',\n",
       " u'we investigated the molecular mechanisms involved in the ACEI (ACEI) inhibition by (-)-epigallocatechin-3-gallate (egcg), a major tea catechin.']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples of sentences with negative sentiment lexicon\n",
    "neg_sentiments[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findSentiment(sentence, sentiment, poslist, neglist):\n",
    "    '''Print out the lexicon word that classified the sentence as positive or negative\n",
    "    '''\n",
    "    if sentiment == \"positive\":\n",
    "        lexicon = poslist\n",
    "    else:\n",
    "        lexicon = neglist\n",
    "    for word in lexicon:\n",
    "        # Note: had to use this \"try/except\" since there was an unicode ascii error... any ways\n",
    "        # to fix this without this try/except? if left the same, then we won't be able to see\n",
    "        # some sentiment word in some sentences.\n",
    "        try:\n",
    "            if word in sentence:\n",
    "                print word\n",
    "        except:\n",
    "            next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casein\n",
      "oat\n",
      "whey\n",
      "pro\n",
      "generate\n",
      "significant\n"
     ]
    }
   ],
   "source": [
    "s5 = \"digestion of isolated whey proteins and caseins of goat milk by gastric pepsin generated soluble hydrolysates exhibiting significant inhibition of ACEI compared to weak inhibition by undigested proteins\"\n",
    "findFoodItems(s5, foodlist)\n",
    "findSentiment(s5, \"positive\", positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casein\n",
      "whey\n",
      "inhibit\n",
      "inhibition\n"
     ]
    }
   ],
   "source": [
    "s6 = \"the late-eluting fraction (f4) of either whey or caseins exhibited greater ACEI inhibition\"\n",
    "findFoodItems(s6, foodlist)\n",
    "findSentiment(s6, \"negative\", positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findTags(sentence, sentiment, foods, poslist, neglist):\n",
    "    ''' Returns the tags of the sentence \n",
    "        Both lexicon word that classified the sentence as positive or negative and food name\n",
    "    '''\n",
    "    \n",
    "    sent = []\n",
    "    food = []\n",
    "    \n",
    "    if sentiment == \"positive\":\n",
    "        lexicon = poslist\n",
    "    else:\n",
    "        lexicon = neglist\n",
    "    for word in lexicon:\n",
    "        # Note: had to use this \"try/except\" since there was an unicode ascii error... any ways\n",
    "        # to fix this without this try/except? if left the same, then we won't be able to see\n",
    "        # some sentiment word in some sentences.\n",
    "        try:\n",
    "            if word in sentence:\n",
    "                sent.append(word)\n",
    "        except:\n",
    "            next\n",
    "            \n",
    "    # If using simple test of if food name \"in\" sentence method\n",
    "    #for f in foods:\n",
    "    #    if f in sentence:\n",
    "    #        food.append(f)\n",
    "    \n",
    "    # If using string distance method:\n",
    "    for f in foods:\n",
    "        n = min(3, len(f.split()))  # Assuming max as trigram        \n",
    "        try:\n",
    "            sentence = sentence.encode(\"utf-8\")\n",
    "            sentence_ngrams = find_ngrams(sentence, n)  # Note: punctuation at end of sentence will be included with\n",
    "                                                    # last word. For now ok, since the JW will still be > 0.95\n",
    "            for ngram in sentence_ngrams:\n",
    "                # Note: when using jaro_winkler, need to convert into unicode format\n",
    "                if jellyfish.jaro_winkler(u\"{}\".format(f.lower()), u\"{}\".format(ngram.lower())) > 0.95:\n",
    "                    food.append(f)\n",
    "                    \n",
    "        except:\n",
    "            next\n",
    "\n",
    "\n",
    "            \n",
    "    return [sent, food, sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save results in a text file\n",
    "# Note: this could have been also done in Spark! But felt lazy to code... feel free to try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/Positive.txt\", \"w\") as pos:\n",
    "    for sentence in pos_sentiments:\n",
    "        tags = findTags(sentence, \"positive\", foodlist, positive, negative)\n",
    "        pos.writelines(str(tags)+ \"\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/Negative.txt\", \"w\") as pos:\n",
    "    for sentence in pos_sentiments:\n",
    "        tags = findTags(sentence, \"negative\", foodlist, positive, negative)\n",
    "        pos.writelines(str(tags)+ \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Notes**  \n",
    "1. In our baseline, some words like \"date\" that appear in a sentence will be interpreted as the fruit \"date\" instead of a calendar date and thus, will be filtered as outputs sentences. This can only be solved if we take into account the context of the sentence and we will need ML to model this!  \n",
    "2. Sentiment analysis need a major improvement: only basing on the positive and negative words without how the food and drug are connected through these words is not a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## **Slight modification to sentiment analysis**\n",
    "\n",
    "I wanted to see if making tuples of the words found in the sentences would help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findFoods(sentence, foods):\n",
    "    '''Making this a generator function'''\n",
    "    for item in foods:\n",
    "        if item in sentence:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxSentiment(sentence, poslist, neglist): \n",
    "    ''' Count the number of positive and negative words in the sentence to ascertain\n",
    "    the type of sentence.\n",
    "    '''\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word in poslist:\n",
    "            pos += 1\n",
    "        elif word in neglist:\n",
    "            neg += 1\n",
    "        else:\n",
    "            next\n",
    "    if pos > neg:\n",
    "        return ('positive',sentence)\n",
    "    elif neg > pos:\n",
    "        return ('negative',sentence)\n",
    "    else:\n",
    "        return ('neutral',sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('negative', 'this is bad and terrible and also good')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxSentiment('this is bad and terrible and also good', positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casein\n",
      "oat\n",
      "whey\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('negative',\n",
       " 'digestion of isolated whey proteins and caseins of goat milk by gastric pepsin generated soluble hydrolysates exhibiting significant inhibition of ACEI compared to weak inhibition by undigested proteins')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s5 = \"digestion of isolated whey proteins and caseins of goat milk by gastric pepsin generated soluble hydrolysates exhibiting significant inhibition of ACEI compared to weak inhibition by undigested proteins\"\n",
    "findFoodItems(s5, foodlist)\n",
    "maxSentiment(s5, positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casein\n",
      "whey\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('negative',\n",
       " 'the late-eluting fraction (f4) of either whey or caseins exhibited greater ACEI inhibition')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 = \"the late-eluting fraction (f4) of either whey or caseins exhibited greater ACEI inhibition\"\n",
    "findFoodItems(s6, foodlist)\n",
    "maxSentiment(s6, positive, negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to look at pairs of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s5a = 'oat flakes are generally positively correlated with ACEI activity'\n",
    "s5b = 'this is a dummy sentence that will not even show up in the dictionary'\n",
    "s6a = 'oats and milk cause inhibition of ACEI'\n",
    "s6b = 'milk upregulates ACEI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def food_dict_maker(sentence):\n",
    "    '''Creating a dictionary of the positive and negative relationships between foods and the drug of choice'''\n",
    "    food_dict = defaultdict(list)\n",
    "\n",
    "    #Get the food item from generator function!\n",
    "    for item in list(findFoods(sentence,foodlist)):\n",
    "        try:\n",
    "            food_dict[(item, maxSentiment(sentence, positive, negative)[0])] += 1\n",
    "        except:\n",
    "            food_dict[(item, maxSentiment(sentence, positive, negative)[0])] = 1\n",
    "\n",
    "    yield food_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def food_dict_maker2(list_of_sentences):\n",
    "    '''Creating a dictionary of the positive and negative relationships between foods and the drug of choice'''\n",
    "    #food_dict = defaultdict(list)\n",
    "    food_dict = defaultdict(dict)\n",
    "\n",
    "    #Get the food item from generator function!\n",
    "    for sentence in list_of_sentences:\n",
    "        for item in list(findFoods(sentence,foodlist)):\n",
    "            try:\n",
    "                #food_dict[(item, maxSentiment(sentence, positive, negative)[0])] += 1\n",
    "                food_dict[item][maxSentiment(sentence, positive, negative)[0]] += 1\n",
    "            except:\n",
    "                #food_dict[(item, maxSentiment(sentence, positive, negative)[0])] = 1\n",
    "                food_dict[item][maxSentiment(sentence, positive, negative)[0]] = 1\n",
    "\n",
    "    yield food_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " defaultdict(<type 'dict'>, {'oat': {'neutral': 1, 'negative': 2}, 'whey': {'negative': 2}, 'casein': {'negative': 2}})\n"
     ]
    }
   ],
   "source": [
    "#The idea would be to pass in a TON of sentences here and you get a dictionary of dictionaries!\n",
    "#You're obviously still getting the error of 'oat' with 'goat' though :(\n",
    "for item in food_dict_maker2([s5a, s5b, s5, s6, s6a, s6b]):\n",
    "    print item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is what you could do with this dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_dict = {'oat': {'neutral': 1, 'negative': 2}, \n",
    "               'whey': {'negative': 2}, 'casein': {'negative': 2}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find relationships, use for viz\n",
    "sample_dict['oat']['negative']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
