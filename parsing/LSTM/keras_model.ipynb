{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing import text\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import sys,os\n",
    "\n",
    "def get_parent_dir(directory):\n",
    "    import os\n",
    "    return os.path.dirname(directory)\n",
    "\n",
    "def make_digit(word):\n",
    "    if word == 'positive':\n",
    "        return 0\n",
    "    elif word == 'neutral':\n",
    "        return 1\n",
    "    elif word == 'negative'\n",
    "        return 2\n",
    "    else:\n",
    "        '{} is neither positive, neutral or negative'.format()\n",
    "\n",
    "current_dirs_parent = get_parent_dir(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: IMPROVE!!\n",
    "\n",
    "here I just turn the vocabulary to 10,000 values, but we should rather keep the 10,000 top words (should count how many are distinct) and let the rest take value unknown, maybe?\n",
    "\n",
    "or just increase V?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_num_label = {}\n",
    "sent_hashed = list()\n",
    "sent_label = list()\n",
    "max_sentence_length = 0\n",
    "with open(current_dirs_parent + '/data/OLDFilteredSentences_labels.csv', 'rb') as labels: \n",
    "    for line in labels:\n",
    "        num, label = line.strip().split(',')\n",
    "        sent_num_label[num] = label.lower()\n",
    "with open(current_dirs_parent + '/data/OLDFilteredSentences.txt','rb') as sentences:\n",
    "    for i, line in enumerate(sentences):\n",
    "            (key, val) = line.split(\"']\")\n",
    "            # maybe Hyera updated her sentence labels and removed some of them?\n",
    "            try:\n",
    "                sent_label.append(make_digit(sent_num_label[str(i+1)]))\n",
    "                max_sentence_length = np.max([max_sentence_length, len(val.split(' '))])\n",
    "                sent_hashed.append(text.one_hot(val, V))\n",
    "            except KeyError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split e.g., on 75%-25%, and we should cross validate but we have so few sentences, that i just wanted to check whether it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 141, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 3,160,703\n",
      "Trainable params: 3,160,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "526/526 [==============================] - 4s - loss: 1.0315 - acc: 0.6540     \n",
      "Epoch 2/3\n",
      "526/526 [==============================] - 3s - loss: 0.7241 - acc: 0.7129     \n",
      "Epoch 3/3\n",
      "526/526 [==============================] - 3s - loss: 0.6166 - acc: 0.7129     \n",
      "Accuracy: 67.24%\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "ids = list(range(701))\n",
    "shuffle(ids)\n",
    "P_TRAIN = .75\n",
    "N_TRAIN = int(round(P_TRAIN * len(sent_label),0))\n",
    "train_ids = ids[:N_TRAIN]\n",
    "test_ids = ids[(N_TRAIN + 1):]\n",
    "train_sents, train_labels = zip(*[(sent_hashed[train_id], sent_label[train_id]) for train_id in train_ids])\n",
    "test_sents, test_labels = zip(*[(sent_hashed[test_id], sent_label[test_id]) for test_id in test_ids])\n",
    "\n",
    "# add padding so that all of the sentences have the same length\n",
    "train_sents = sequence.pad_sequences(train_sents, maxlen=max_sentence_length)\n",
    "test_sents = sequence.pad_sequences(test_sents, maxlen=max_sentence_length)\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "# create the model\n",
    "embedding_vecor_length = 300\n",
    "model = Sequential()\n",
    "model.add(Embedding(V, embedding_vecor_length, input_length=max_sentence_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(train_sents, train_labels, nb_epoch=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(test_sents, test_labels, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it seems that it predicts only neutral (second column has the max. value) below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17751227,  0.77461505,  0.04787262],\n",
       "       [ 0.23319693,  0.66797918,  0.09882392],\n",
       "       [ 0.24523947,  0.67335522,  0.08140534],\n",
       "       [ 0.18965013,  0.75048065,  0.05986925],\n",
       "       [ 0.12022069,  0.85089761,  0.02888172],\n",
       "       [ 0.19153422,  0.75297087,  0.05549492],\n",
       "       [ 0.09722652,  0.88207144,  0.02070205],\n",
       "       [ 0.09107928,  0.89431864,  0.01460207],\n",
       "       [ 0.0840079 ,  0.89915258,  0.01683953],\n",
       "       [ 0.22692826,  0.68821895,  0.08485274],\n",
       "       [ 0.15048903,  0.80914021,  0.04037081],\n",
       "       [ 0.0896502 ,  0.89265764,  0.01769217],\n",
       "       [ 0.1078333 ,  0.86824173,  0.02392489],\n",
       "       [ 0.13480806,  0.8295399 ,  0.03565199],\n",
       "       [ 0.24974583,  0.62930715,  0.12094695],\n",
       "       [ 0.25039676,  0.66958117,  0.08002204],\n",
       "       [ 0.13957691,  0.82589972,  0.03452346],\n",
       "       [ 0.22364967,  0.67058307,  0.1057673 ],\n",
       "       [ 0.21047632,  0.70749813,  0.08202552],\n",
       "       [ 0.21663295,  0.72615677,  0.05721035],\n",
       "       [ 0.2010127 ,  0.74366742,  0.05531988],\n",
       "       [ 0.27086285,  0.59851885,  0.13061835],\n",
       "       [ 0.1228647 ,  0.85244876,  0.02468659],\n",
       "       [ 0.31513777,  0.4869439 ,  0.19791836],\n",
       "       [ 0.14300418,  0.82240963,  0.03458616],\n",
       "       [ 0.22533113,  0.68876666,  0.08590219],\n",
       "       [ 0.16058628,  0.78973198,  0.04968174],\n",
       "       [ 0.20503484,  0.71260667,  0.08235858],\n",
       "       [ 0.37553281,  0.40929642,  0.21517077],\n",
       "       [ 0.1884937 ,  0.73988146,  0.07162486],\n",
       "       [ 0.15726942,  0.80121416,  0.04151645],\n",
       "       [ 0.18102308,  0.75563955,  0.06333736],\n",
       "       [ 0.2409602 ,  0.65136993,  0.1076699 ],\n",
       "       [ 0.21110062,  0.70034754,  0.08855187],\n",
       "       [ 0.19767068,  0.73240018,  0.06992915],\n",
       "       [ 0.19586992,  0.73602498,  0.06810511],\n",
       "       [ 0.17807378,  0.75814599,  0.06378029],\n",
       "       [ 0.25072876,  0.63818759,  0.1110837 ],\n",
       "       [ 0.18350115,  0.7597115 ,  0.05678735],\n",
       "       [ 0.25097969,  0.63522547,  0.11379483],\n",
       "       [ 0.09647418,  0.8839221 ,  0.01960381],\n",
       "       [ 0.17957929,  0.76301664,  0.05740409],\n",
       "       [ 0.26443729,  0.6251052 ,  0.11045749],\n",
       "       [ 0.15460357,  0.79969722,  0.04569913],\n",
       "       [ 0.22004879,  0.6818642 ,  0.09808696],\n",
       "       [ 0.14490665,  0.81385994,  0.04123346],\n",
       "       [ 0.15464477,  0.79433501,  0.05102025],\n",
       "       [ 0.27178517,  0.55618912,  0.17202568],\n",
       "       [ 0.24435486,  0.66750807,  0.08813705],\n",
       "       [ 0.20059752,  0.72227079,  0.07713166],\n",
       "       [ 0.27717507,  0.56485558,  0.1579694 ],\n",
       "       [ 0.22913635,  0.67836934,  0.09249434],\n",
       "       [ 0.14874467,  0.8060773 ,  0.04517798],\n",
       "       [ 0.18082142,  0.76775801,  0.05142052],\n",
       "       [ 0.28837216,  0.53842568,  0.1732021 ],\n",
       "       [ 0.14019059,  0.82878059,  0.03102881],\n",
       "       [ 0.23868263,  0.67938483,  0.08193257],\n",
       "       [ 0.2296607 ,  0.67732686,  0.09301242],\n",
       "       [ 0.12427027,  0.84579343,  0.02993626],\n",
       "       [ 0.3315827 ,  0.45284986,  0.2155675 ],\n",
       "       [ 0.29180077,  0.53569657,  0.17250265],\n",
       "       [ 0.23092368,  0.68273902,  0.08633728],\n",
       "       [ 0.16595049,  0.77406555,  0.05998394],\n",
       "       [ 0.0972558 ,  0.88285339,  0.01989086],\n",
       "       [ 0.15509102,  0.80631012,  0.03859888],\n",
       "       [ 0.1615479 ,  0.78941381,  0.04903828],\n",
       "       [ 0.1120094 ,  0.85938817,  0.02860255],\n",
       "       [ 0.13550213,  0.81886852,  0.04562926],\n",
       "       [ 0.1124035 ,  0.86661214,  0.02098433],\n",
       "       [ 0.31091517,  0.50218493,  0.18689983],\n",
       "       [ 0.13182017,  0.83572018,  0.03245965],\n",
       "       [ 0.207986  ,  0.70737141,  0.08464258],\n",
       "       [ 0.23500872,  0.68220365,  0.08278761],\n",
       "       [ 0.16296563,  0.77962685,  0.05740754],\n",
       "       [ 0.15875386,  0.79504055,  0.04620559],\n",
       "       [ 0.1450775 ,  0.80324906,  0.05167351],\n",
       "       [ 0.22390708,  0.69435716,  0.08173577],\n",
       "       [ 0.16974643,  0.78129566,  0.04895793],\n",
       "       [ 0.22657548,  0.69241196,  0.08101263],\n",
       "       [ 0.19423424,  0.75027031,  0.0554955 ],\n",
       "       [ 0.27821493,  0.5557726 ,  0.16601251],\n",
       "       [ 0.23762541,  0.6650033 ,  0.09737134],\n",
       "       [ 0.19452727,  0.72008282,  0.08538989],\n",
       "       [ 0.18211357,  0.75763851,  0.06024789],\n",
       "       [ 0.13547182,  0.82565159,  0.03887654],\n",
       "       [ 0.07276222,  0.91526669,  0.01197103],\n",
       "       [ 0.17791651,  0.76179588,  0.06028765],\n",
       "       [ 0.11775893,  0.85951334,  0.02272768],\n",
       "       [ 0.20678365,  0.73004013,  0.06317622],\n",
       "       [ 0.19718327,  0.73233116,  0.07048561],\n",
       "       [ 0.26239437,  0.63593566,  0.10167005],\n",
       "       [ 0.17660914,  0.76149595,  0.06189497],\n",
       "       [ 0.16605781,  0.78613746,  0.04780474],\n",
       "       [ 0.21446045,  0.69978917,  0.08575036],\n",
       "       [ 0.29515743,  0.56522155,  0.13962108],\n",
       "       [ 0.16902077,  0.76515335,  0.06582586],\n",
       "       [ 0.08142303,  0.9031328 ,  0.01544423],\n",
       "       [ 0.28160328,  0.56835693,  0.15003978],\n",
       "       [ 0.11364431,  0.85962963,  0.02672614],\n",
       "       [ 0.06100657,  0.9293834 ,  0.00961002],\n",
       "       [ 0.10516915,  0.87141985,  0.02341102],\n",
       "       [ 0.21151292,  0.6932373 ,  0.09524971],\n",
       "       [ 0.16391882,  0.76607794,  0.07000322],\n",
       "       [ 0.12661737,  0.83967346,  0.03370923],\n",
       "       [ 0.18966246,  0.74880528,  0.06153225],\n",
       "       [ 0.17346202,  0.76458675,  0.06195121],\n",
       "       [ 0.09959664,  0.87878495,  0.02161836],\n",
       "       [ 0.25223687,  0.64448166,  0.10328145],\n",
       "       [ 0.18310598,  0.75688756,  0.06000655],\n",
       "       [ 0.28026173,  0.58135927,  0.13837899],\n",
       "       [ 0.10325061,  0.87718189,  0.01956754],\n",
       "       [ 0.18703966,  0.74715286,  0.06580745],\n",
       "       [ 0.25805563,  0.60396504,  0.13797937],\n",
       "       [ 0.20569746,  0.70845658,  0.08584601],\n",
       "       [ 0.22643036,  0.67396903,  0.09960062],\n",
       "       [ 0.17965476,  0.74968332,  0.07066192],\n",
       "       [ 0.20456275,  0.71142328,  0.08401396],\n",
       "       [ 0.18992977,  0.74164945,  0.06842078],\n",
       "       [ 0.17263466,  0.77341211,  0.05395324],\n",
       "       [ 0.31311491,  0.54275143,  0.14413364],\n",
       "       [ 0.12338027,  0.84257615,  0.03404365],\n",
       "       [ 0.10783257,  0.86668116,  0.02548616],\n",
       "       [ 0.15673888,  0.79994363,  0.04331754],\n",
       "       [ 0.21832502,  0.69999415,  0.08168088],\n",
       "       [ 0.28326559,  0.54697669,  0.1697578 ],\n",
       "       [ 0.12985142,  0.84067953,  0.0294691 ],\n",
       "       [ 0.16126066,  0.77180755,  0.06693176],\n",
       "       [ 0.26119202,  0.58543098,  0.15337697],\n",
       "       [ 0.25887689,  0.63897592,  0.10214718],\n",
       "       [ 0.25124645,  0.62692678,  0.12182679],\n",
       "       [ 0.26469883,  0.64025301,  0.09504814],\n",
       "       [ 0.2585429 ,  0.60549653,  0.13596061],\n",
       "       [ 0.19277638,  0.73554432,  0.07167934],\n",
       "       [ 0.24741809,  0.65075225,  0.10182961],\n",
       "       [ 0.31025997,  0.57552826,  0.11421173],\n",
       "       [ 0.25107613,  0.64500707,  0.10391681],\n",
       "       [ 0.13718349,  0.81355351,  0.04926302],\n",
       "       [ 0.17862664,  0.76073647,  0.06063692],\n",
       "       [ 0.25936821,  0.63569057,  0.10494132],\n",
       "       [ 0.10148409,  0.87630403,  0.02221192],\n",
       "       [ 0.17102207,  0.76964456,  0.05933331],\n",
       "       [ 0.08975686,  0.89208573,  0.01815733],\n",
       "       [ 0.1791306 ,  0.76527661,  0.05559275],\n",
       "       [ 0.31267047,  0.49768829,  0.18964124],\n",
       "       [ 0.19316767,  0.73181146,  0.07502083],\n",
       "       [ 0.35600314,  0.43510875,  0.20888814],\n",
       "       [ 0.11709512,  0.85342509,  0.02947975],\n",
       "       [ 0.15983915,  0.78770059,  0.05246024],\n",
       "       [ 0.1839525 ,  0.74909455,  0.06695289],\n",
       "       [ 0.29452181,  0.54218197,  0.16329625],\n",
       "       [ 0.19081418,  0.71537548,  0.0938103 ],\n",
       "       [ 0.08809916,  0.89659613,  0.0153047 ],\n",
       "       [ 0.17585936,  0.76481289,  0.05932772],\n",
       "       [ 0.24364844,  0.63123339,  0.12511823],\n",
       "       [ 0.07492384,  0.91081291,  0.01426327],\n",
       "       [ 0.13620156,  0.83131427,  0.03248413],\n",
       "       [ 0.10672314,  0.86861503,  0.02466176],\n",
       "       [ 0.14261989,  0.81663549,  0.0407446 ],\n",
       "       [ 0.18159418,  0.75637364,  0.06203223],\n",
       "       [ 0.15862516,  0.79774761,  0.04362725],\n",
       "       [ 0.16928023,  0.77458453,  0.0561352 ],\n",
       "       [ 0.11606593,  0.85675961,  0.02717439],\n",
       "       [ 0.14307784,  0.81969345,  0.0372288 ],\n",
       "       [ 0.06164447,  0.92931873,  0.00903688],\n",
       "       [ 0.1468709 ,  0.80225402,  0.05087507],\n",
       "       [ 0.28938171,  0.55569315,  0.15492512],\n",
       "       [ 0.18567845,  0.75306368,  0.06125798],\n",
       "       [ 0.0897793 ,  0.89377022,  0.01645057],\n",
       "       [ 0.25023252,  0.63590884,  0.11385864],\n",
       "       [ 0.32150659,  0.47137222,  0.20712118],\n",
       "       [ 0.17498669,  0.77219844,  0.05281476],\n",
       "       [ 0.13513857,  0.83364826,  0.03121315],\n",
       "       [ 0.15391023,  0.79416937,  0.0519204 ],\n",
       "       [ 0.13685538,  0.82814884,  0.03499571]], dtype=float32)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
