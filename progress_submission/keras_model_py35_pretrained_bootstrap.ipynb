{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from random import shuffle\n",
    "import sys,os, pickle, jellyfish\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing import text\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "# ------------------------ helper functions -------------------------- #\n",
    "\n",
    "def get_parent_dir(directory):\n",
    "    '''Returns the parent directory of the current one'''\n",
    "    return os.path.dirname(directory)\n",
    "\n",
    "\n",
    "# ------------------------ functions for processing the text ---------- #\n",
    "def make_digit(word):\n",
    "    '''Transforms string labels to digits'''\n",
    "    if word == 'negative':\n",
    "        return int(0)\n",
    "    elif word == 'neutral':\n",
    "        return int(1)\n",
    "    elif word == 'positive':\n",
    "        return int(2)\n",
    "    else:\n",
    "        '{} is neither positive, neutral or negative'.format(word)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def get_word_ids(sentence, vocabulary):\n",
    "    '''Returns index in the vocabulary for each word of the sentence.'''\n",
    "    words = text.text_to_word_sequence(sentence)\n",
    "    return [vocabulary.index(x) if x in vocabulary else len(vocabulary) for x in words]\n",
    "\n",
    "current_dirs_parent = get_parent_dir(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in vocabulary and word-vector files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4929266\n"
     ]
    }
   ],
   "source": [
    "vocabulary = []\n",
    "occurrences = {}\n",
    "\n",
    "with open('/media/adam/Data/BioNLP/ri-3gram-400-tsv/vocab.tsv') as vocabulary_file:\n",
    "    for line in vocabulary_file:\n",
    "        word, occurrence = line.strip().split('\\t')\n",
    "        vocabulary.append(word)\n",
    "        occurrences[word] = occurrence\n",
    "\n",
    "\n",
    "\n",
    "print(len(vocabulary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open('/media/adam/Data/BioNLP/ri-3gram-400-tsv/vectors.tsv') as embedding_file:\n",
    "    for i, line in enumerate(embedding_file):\n",
    "        values = line.strip().split('\\t')\n",
    "        vector = np.asarray(values, dtype='float32')\n",
    "        embeddings_index[vocabulary[i]] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pickle.dump(embeddings_index, open('/media/adam/Data/BioNLP/embeddings_index.pickle','wb'))\n",
    "embeddings_index = pickle.load(open('/media/adam/Data/BioNLP/embeddings_index.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read-in compounds in order to add them to vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compounds = Counter()\n",
    "\n",
    "       \n",
    "with open(current_dirs_parent + '/data/labeled_dataAll.tsv', 'r') as labelled_sents: \n",
    "    for num, line in enumerate(labelled_sents):\n",
    "        _,label,_,_,compound, sent = line.strip().split('\\t')\n",
    "        compounds[compound] += 1\n",
    "        # here we could canonicalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pectin', 17), ('l-dopa', 16), ('styrene', 15), ('glycyrrhizin', 14), ('genistein', 14), ('potato', 13), ('rainbow trout', 13), ('procyanidin', 12), ('lard', 12), ('thiamine', 12)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(compounds.most_common(10))\n",
    "len(compounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-trained embeddings for the compounds\n",
    "\n",
    "If there is more than one alternative (alternative specified by JW distance > .95), than take weighted average of the word vectors, weighted by number of occurences of the compound in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "compound_index = {}\n",
    "for compound in compounds:\n",
    "    # the word vectors are 400 long\n",
    "    compound_embedding = np.zeros(400)\n",
    "    num_alternatives = 0\n",
    "    occurrence_total = 0\n",
    "    for i, word in enumerate(vocabulary):\n",
    "        # take weighted average (element-wise) of the word vectors, weighted by the occurrences of the compound in corpus\n",
    "        if jellyfish.jaro_winkler(compound, word) > 0.95:\n",
    "            compound_embedding += embeddings_index[word]*int(occurrences[word])\n",
    "            num_alternatives += 1\n",
    "            occurrence_total += int(occurrences[word])\n",
    "            \n",
    "    compound_index[compound] = compound_embedding/(num_alternatives*occurrence_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pickle.dump(compound_index, open('/media/adam/Data/BioNLP/compound_index.pickle','wb'))\n",
    "compound_index = pickle.load(open('/media/adam/Data/BioNLP/compound_index.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should have paid more attention to zero division above, rewrite the vectors to 0s if they are np.nans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "693"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_compounds = {}\n",
    "for k,v in compound_index.items():\n",
    "    if any(np.isnan(v)):\n",
    "        continue\n",
    "    temp_compounds[k] = v\n",
    "len(temp_compounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before finding alternative spellings, there were 581 compounds found of our 886, after JW distance alternatives, we have 693. As it doesn't take much time and improves visibility, in another step, let's take out those compounds which are in the top 20k of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V = 30000\n",
    "j = 0\n",
    "final_compounds = {}\n",
    "for compound, vector in temp_compounds.items():\n",
    "    if compound not in vocabulary[:V]:\n",
    "        final_compounds[compound] = vector\n",
    "# top 20k words, remaining compounds not in the top 20k, and one extra line for the unknown words        \n",
    "V_total = V + len(final_compounds) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim = 400\n",
    "\n",
    "vocab_final = []\n",
    "embedding_matrix = np.zeros((V, dim))\n",
    "for i, word in enumerate(vocabulary[:V]):\n",
    "    embedding_matrix[i] = embeddings_index[word]\n",
    "    vocab_final.append(word)\n",
    "\n",
    "    \n",
    "final_compound_matrix = np.zeros((len(final_compounds), dim))\n",
    "for i, item in enumerate(final_compounds.items()):\n",
    "    compound, vector = item\n",
    "    final_compound_matrix[i] = vector\n",
    "    vocab_final.append(compound)\n",
    "\n",
    "# stack top 20k words, compounds not found among the 20k words and a\n",
    "# vector of zeros for the words not in the vocabulary    \n",
    "embedding_matrix = np.vstack([embedding_matrix, final_compound_matrix, np.zeros(dim)])\n",
    "assert embedding_matrix.shape == (V_total, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'honey' in temp_compounds.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare sentences for analysis\n",
    "Most importantly, change the words in the sentences to indeces corresponding to the rows of the embedding matrix.\n",
    "\n",
    "Bootstrap positive and negative sentences to balance the label distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACE inhibitor' 'Antacid' 'GLP-1' 'Thyroxine' 'Statin' 'Acetaminophen'\n",
      " 'Digoxin' 'Isoniazid' 'Antihistamine' 'MOAI' 'Analgesics'\n",
      " 'Bronchodialators']\n"
     ]
    }
   ],
   "source": [
    "drugs = df.Drug.unique()\n",
    "print(drugs)x\n",
    "add_dict = {}\n",
    "\n",
    "for drug in drugs:\n",
    "    \n",
    "    count_list = []\n",
    "    for i in range(3):\n",
    "        count = len(df[(df.Drug == drug) & (df.Label_num == i)])\n",
    "        count_list.append(count)\n",
    "        \n",
    "    max_count = max(count_list)\n",
    "    add_list = [max(0,max_count-c) for c in count_list]\n",
    "    add_dict[drug] = add_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4755\n"
     ]
    }
   ],
   "source": [
    "for drug in drugs:\n",
    "    for i in range(3):\n",
    "        temp = df[(df.Drug == drug) & (df.Label_num == i)].sample(add_dict[drug][i], replace=True)\n",
    "        df = df.append(temp)\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = defaultdict(list)\n",
    "sent_classified = list()\n",
    "sentences = defaultdict(list)\n",
    "sent_label = list()\n",
    "max_sentence_length = 0\n",
    "num = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sentence = row['sentence']\n",
    "    # include only those compounds that are found in the corpus\n",
    "    if row['Food'] in temp_compounds.keys():\n",
    "        labels[num] = row['Label_alpha']\n",
    "        sentences[num] = sentence.lower()\n",
    "        num += 1\n",
    "        sent = text.text_to_word_sequence(sentence)          \n",
    "        try:\n",
    "            sent_label.append(row['Label_num'])\n",
    "            max_sentence_length = np.max([max_sentence_length, len(sent)])\n",
    "            sent_classified.append(get_word_ids(sentence, vocab_final))\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3702"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.5/site-packages/statsmodels/nonparametric/kdetools.py:20: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  y = X[:m/2+1] + np.r_[0,X[m/2+1:],0]*1j\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbd8734a780>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh0AAAFoCAYAAADzZ0kIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBaGgQ0RERBaEgg4RERFZEP8HMkMFmnE9gBwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd873fb320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "sentence_length = []\n",
    "for sentence in sentences.values():\n",
    "    sentence_length.append(len(sentence.split(' ')))\n",
    "sns.distplot(sentence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainable parameters/settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_UNITS = 300\n",
    "NUM_EPOCHS = 100\n",
    "DROPOUT_RATE = 0.2\n",
    "MAX_SENTENCE_LENGTH = 100\n",
    "optim = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "#optim = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "# change vocabulary size? maybe 20k is too much?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model\n",
    "\n",
    "Here I pad the sentences to max sentence length but maybe we could truncate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 400)          12199600  \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 100, 300)          841200    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 903       \n",
      "=================================================================\n",
      "Total params: 13,762,903\n",
      "Trainable params: 13,762,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2776/2776 [==============================] - 118s - loss: 1.0810 - categorical_accuracy: 0.4096   \n",
      "Epoch 2/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.9708 - categorical_accuracy: 0.5177   \n",
      "Epoch 3/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.9266 - categorical_accuracy: 0.5447   \n",
      "Epoch 4/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.8772 - categorical_accuracy: 0.5854   \n",
      "Epoch 5/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.8585 - categorical_accuracy: 0.6081   \n",
      "Epoch 6/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.8159 - categorical_accuracy: 0.6272   \n",
      "Epoch 7/100\n",
      "2776/2776 [==============================] - 115s - loss: 0.7870 - categorical_accuracy: 0.6445   \n",
      "Epoch 8/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.7556 - categorical_accuracy: 0.6686   \n",
      "Epoch 9/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.7326 - categorical_accuracy: 0.6805   \n",
      "Epoch 10/100\n",
      "2776/2776 [==============================] - 117s - loss: 0.7263 - categorical_accuracy: 0.6707   \n",
      "Epoch 11/100\n",
      "2776/2776 [==============================] - 120s - loss: 0.6936 - categorical_accuracy: 0.6992   \n",
      "Epoch 12/100\n",
      "2776/2776 [==============================] - 118s - loss: 0.6552 - categorical_accuracy: 0.7215   \n",
      "Epoch 13/100\n",
      "2776/2776 [==============================] - 119s - loss: 0.6084 - categorical_accuracy: 0.7392   \n",
      "Epoch 14/100\n",
      "2776/2776 [==============================] - 119s - loss: 0.5908 - categorical_accuracy: 0.7576   \n",
      "Epoch 15/100\n",
      "2776/2776 [==============================] - 122s - loss: 0.5433 - categorical_accuracy: 0.7770   \n",
      "Epoch 16/100\n",
      "2776/2776 [==============================] - 123s - loss: 0.5375 - categorical_accuracy: 0.7727   \n",
      "Epoch 17/100\n",
      "2776/2776 [==============================] - 129s - loss: 0.4718 - categorical_accuracy: 0.8120   \n",
      "Epoch 18/100\n",
      "2776/2776 [==============================] - 120s - loss: 0.4378 - categorical_accuracy: 0.8321   \n",
      "Epoch 19/100\n",
      "2776/2776 [==============================] - 119s - loss: 0.4260 - categorical_accuracy: 0.8206   \n",
      "Epoch 20/100\n",
      "2776/2776 [==============================] - 119s - loss: 0.4388 - categorical_accuracy: 0.8332   \n",
      "Epoch 21/100\n",
      "2776/2776 [==============================] - 124s - loss: 0.4185 - categorical_accuracy: 0.8293   \n",
      "Epoch 22/100\n",
      "2776/2776 [==============================] - 121s - loss: 0.5233 - categorical_accuracy: 0.7867   \n",
      "Epoch 23/100\n",
      "2776/2776 [==============================] - 122s - loss: 0.4232 - categorical_accuracy: 0.8354   \n",
      "Epoch 24/100\n",
      "2776/2776 [==============================] - 117s - loss: 0.3858 - categorical_accuracy: 0.8509   \n",
      "Epoch 25/100\n",
      "2776/2776 [==============================] - 122s - loss: 0.3632 - categorical_accuracy: 0.8548   \n",
      "Epoch 26/100\n",
      "2776/2776 [==============================] - 120s - loss: 0.3206 - categorical_accuracy: 0.8721   \n",
      "Epoch 27/100\n",
      "2776/2776 [==============================] - 122s - loss: 0.2959 - categorical_accuracy: 0.8847   \n",
      "Epoch 28/100\n",
      "2776/2776 [==============================] - 120s - loss: 0.2867 - categorical_accuracy: 0.8930   \n",
      "Epoch 29/100\n",
      "2776/2776 [==============================] - 117s - loss: 0.2672 - categorical_accuracy: 0.8959   \n",
      "Epoch 30/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.2515 - categorical_accuracy: 0.9049   \n",
      "Epoch 31/100\n",
      "2776/2776 [==============================] - 112s - loss: 0.2553 - categorical_accuracy: 0.9060   \n",
      "Epoch 32/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.2160 - categorical_accuracy: 0.9207   \n",
      "Epoch 33/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.2024 - categorical_accuracy: 0.9323   \n",
      "Epoch 34/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.1832 - categorical_accuracy: 0.9334   \n",
      "Epoch 35/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.1920 - categorical_accuracy: 0.9262   \n",
      "Epoch 36/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.1697 - categorical_accuracy: 0.9391   \n",
      "Epoch 37/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.1796 - categorical_accuracy: 0.9330   \n",
      "Epoch 38/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.1508 - categorical_accuracy: 0.9474   \n",
      "Epoch 39/100\n",
      "2776/2776 [==============================] - 115s - loss: 0.1562 - categorical_accuracy: 0.9434   \n",
      "Epoch 40/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.1429 - categorical_accuracy: 0.9539   \n",
      "Epoch 41/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.1364 - categorical_accuracy: 0.9564   \n",
      "Epoch 42/100\n",
      "2776/2776 [==============================] - 110s - loss: 0.1173 - categorical_accuracy: 0.9593   \n",
      "Epoch 43/100\n",
      "2776/2776 [==============================] - 116s - loss: 0.1157 - categorical_accuracy: 0.9568   \n",
      "Epoch 44/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.1101 - categorical_accuracy: 0.9589   \n",
      "Epoch 45/100\n",
      "2776/2776 [==============================] - 118s - loss: 0.1573 - categorical_accuracy: 0.9488   \n",
      "Epoch 46/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.1370 - categorical_accuracy: 0.9517   \n",
      "Epoch 47/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.1425 - categorical_accuracy: 0.9481   \n",
      "Epoch 48/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.1307 - categorical_accuracy: 0.9517   \n",
      "Epoch 49/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.1295 - categorical_accuracy: 0.9550   \n",
      "Epoch 50/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.1438 - categorical_accuracy: 0.9514   \n",
      "Epoch 51/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.1177 - categorical_accuracy: 0.9539   \n",
      "Epoch 52/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.1230 - categorical_accuracy: 0.9586   \n",
      "Epoch 53/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.1066 - categorical_accuracy: 0.9661   \n",
      "Epoch 54/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0833 - categorical_accuracy: 0.9694   \n",
      "Epoch 55/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0972 - categorical_accuracy: 0.9669   \n",
      "Epoch 56/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0842 - categorical_accuracy: 0.9719   \n",
      "Epoch 57/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0881 - categorical_accuracy: 0.9712   \n",
      "Epoch 58/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.0861 - categorical_accuracy: 0.9701   \n",
      "Epoch 59/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0811 - categorical_accuracy: 0.9730   \n",
      "Epoch 60/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0848 - categorical_accuracy: 0.9737   \n",
      "Epoch 61/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.0787 - categorical_accuracy: 0.9719   \n",
      "Epoch 62/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.0659 - categorical_accuracy: 0.9816   \n",
      "Epoch 63/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0778 - categorical_accuracy: 0.9762   \n",
      "Epoch 64/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.0799 - categorical_accuracy: 0.9712   \n",
      "Epoch 65/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.0835 - categorical_accuracy: 0.9744   \n",
      "Epoch 66/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.0795 - categorical_accuracy: 0.9726   \n",
      "Epoch 67/100\n",
      "2776/2776 [==============================] - 112s - loss: 0.0803 - categorical_accuracy: 0.9715   \n",
      "Epoch 68/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.0905 - categorical_accuracy: 0.9726   \n",
      "Epoch 69/100\n",
      "2776/2776 [==============================] - 117s - loss: 0.0596 - categorical_accuracy: 0.9809   \n",
      "Epoch 70/100\n",
      "2776/2776 [==============================] - 116s - loss: 0.0642 - categorical_accuracy: 0.9780   \n",
      "Epoch 71/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.0629 - categorical_accuracy: 0.9777   \n",
      "Epoch 72/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.0657 - categorical_accuracy: 0.9780   \n",
      "Epoch 73/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.0718 - categorical_accuracy: 0.9773   \n",
      "Epoch 74/100\n",
      "2776/2776 [==============================] - 112s - loss: 0.0732 - categorical_accuracy: 0.9744   \n",
      "Epoch 75/100\n",
      "2776/2776 [==============================] - 117s - loss: 0.0524 - categorical_accuracy: 0.9820   \n",
      "Epoch 76/100\n",
      "2776/2776 [==============================] - 115s - loss: 0.0568 - categorical_accuracy: 0.9809   \n",
      "Epoch 77/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0801 - categorical_accuracy: 0.9744   \n",
      "Epoch 78/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0596 - categorical_accuracy: 0.9809   \n",
      "Epoch 79/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0678 - categorical_accuracy: 0.9759   \n",
      "Epoch 80/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0659 - categorical_accuracy: 0.9769   \n",
      "Epoch 81/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0875 - categorical_accuracy: 0.9705   \n",
      "Epoch 82/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0778 - categorical_accuracy: 0.9762   \n",
      "Epoch 83/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0761 - categorical_accuracy: 0.9748   \n",
      "Epoch 84/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0754 - categorical_accuracy: 0.9741   \n",
      "Epoch 85/100\n",
      "2776/2776 [==============================] - 115s - loss: 0.0657 - categorical_accuracy: 0.9780   \n",
      "Epoch 86/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.0809 - categorical_accuracy: 0.9733   \n",
      "Epoch 87/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0642 - categorical_accuracy: 0.9791   \n",
      "Epoch 88/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0609 - categorical_accuracy: 0.9787   \n",
      "Epoch 89/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0563 - categorical_accuracy: 0.9820   \n",
      "Epoch 90/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.0633 - categorical_accuracy: 0.9802   \n",
      "Epoch 91/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.0607 - categorical_accuracy: 0.9820   \n",
      "Epoch 92/100\n",
      "2776/2776 [==============================] - 114s - loss: 0.0733 - categorical_accuracy: 0.9769   \n",
      "Epoch 93/100\n",
      "2776/2776 [==============================] - 113s - loss: 0.0667 - categorical_accuracy: 0.9777   \n",
      "Epoch 94/100\n",
      "2776/2776 [==============================] - 116s - loss: 0.0615 - categorical_accuracy: 0.9802   \n",
      "Epoch 95/100\n",
      "2776/2776 [==============================] - 112s - loss: 0.0457 - categorical_accuracy: 0.9874   \n",
      "Epoch 96/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.0392 - categorical_accuracy: 0.9870   \n",
      "Epoch 97/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.0493 - categorical_accuracy: 0.9834   \n",
      "Epoch 98/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.0656 - categorical_accuracy: 0.9777   \n",
      "Epoch 99/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.0522 - categorical_accuracy: 0.9841   \n",
      "Epoch 100/100\n",
      "2776/2776 [==============================] - 111s - loss: 0.0676 - categorical_accuracy: 0.9798   \n",
      "Test accuracy: 86.70270272847769\n"
     ]
    }
   ],
   "source": [
    "ids = list(range(len(sentences)))\n",
    "shuffle(ids)\n",
    "P_TRAIN = .75\n",
    "N_TRAIN = int(round(P_TRAIN * len(sent_label),0))\n",
    "train_ids = ids[:N_TRAIN]\n",
    "test_ids = ids[(N_TRAIN + 1):]\n",
    "train_sents, train_labels = zip(*[(sent_classified[train_id], sent_label[train_id]) for train_id in train_ids])\n",
    "test_sents, test_labels = zip(*[(sent_classified[test_id], sent_label[test_id]) for test_id in test_ids])\n",
    "\n",
    "# add padding so that all of the sentences have the same length\n",
    "train_sents = sequence.pad_sequences(train_sents, maxlen=MAX_SENTENCE_LENGTH)\n",
    "test_sents = sequence.pad_sequences(test_sents, maxlen=MAX_SENTENCE_LENGTH)\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(V_total, dim, weights=[embedding_matrix],\n",
    "                    input_length=MAX_SENTENCE_LENGTH, trainable=True))\n",
    "model.add(LSTM(LSTM_UNITS, return_sequences = True))\n",
    "model.add(Dropout(DROPOUT_RATE))\n",
    "model.add(LSTM(LSTM_UNITS))\n",
    "model.add(Dropout(DROPOUT_RATE))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['categorical_accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Final evaluation of the model\n",
    "model.fit(train_sents, train_labels, epochs=NUM_EPOCHS, batch_size=32)\n",
    "scores = model.evaluate(test_sents, test_labels, verbose=0)\n",
    "print(\"Test accuracy: {}\".format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 86.70270272847769\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_sents, test_labels, verbose=0)\n",
    "print(\"Test accuracy: {}\".format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_prediction = model.predict(test_sents)\n",
    "training_prediction = model.predict(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(testing_prediction, open('lstm_2x_300_dropout_02_lr_001_epoch_100_testing_V_30k_trainable_embed.pickle','wb'))\n",
    "pickle.dump(training_prediction, open('lstm_2x_300_dropout_02_lr_001_epoch_100_training_V_30k_trainable_embed.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_classes = np.argmax(testing_prediction, axis = 1)\n",
    "p = 0\n",
    "neu = 0\n",
    "neg = 0\n",
    "for i in pred_classes:\n",
    "    if i == 0:\n",
    "        neg += 1\n",
    "    elif i == 1:\n",
    "        neu += 1\n",
    "    else:\n",
    "        p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[340, 262, 323]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p,neu,neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_classes = np.argmax(test_labels, axis=1)\n",
    "p = 0\n",
    "neu = 0\n",
    "neg = 0\n",
    "for i in true_classes:\n",
    "    if i == 0:\n",
    "        neg += 1\n",
    "    elif i == 1:\n",
    "        neu += 1\n",
    "    else:\n",
    "        p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[330, 304, 291]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p, neu, neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pred_true_final.csv','w') as outfile:\n",
    "    for i in range(len(true_classes)):\n",
    "        if i == 0:\n",
    "            print('true,predicted', file=outfile)\n",
    "        print('{0},{1}'.format(true_classes[i],pred_classes[i]), file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adam/Documents/MIDS/W266/Project/parsing/LSTM\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
